{
  "original": [
    "In this paper, we propose several novel deep learning methods for object\nsaliency detection based on the powerful convolutional neural networks. In our\napproach, we use a gradient descent method to iteratively modify an input image\nbased on the pixel-wise gradients to reduce a cost function measuring the\nclass-specific objectness of the image. The pixel-wise gradients can be\nefficiently computed using the back-propagation algorithm. The discrepancy\nbetween the modified image and the original one may be used as a saliency map\nfor the image. Moreover, we have further proposed several new training methods\nto learn saliency-specific convolutional nets for object saliency detection, in\norder to leverage the available pixel-wise segmentation information. Our\nmethods are extremely computationally efficient (processing 20-40 images per\nsecond in one GPU). In this work, we use the computed saliency maps for image\nsegmentation. Experimental results on two benchmark tasks, namely Microsoft\nCOCO and Pascal VOC 2012, have shown that our proposed methods can generate\nhigh-quality salience maps, clearly outperforming many existing methods. In\nparticular, our approaches excel in handling many difficult images, which\ncontain complex background, highly-variable salient objects, multiple objects,\nand/or very small salient objects.",
    "  We consider crossovers with respect to the weak convergence theorems from a\ndiscrete-time quantum walk (DTQW). We show that a continuous-time quantum walk\n(CTQW) and discrete- and continuous-time random walks can be expressed as DTQWs\nin some limit. At first we generalize our previous study [Phys. Rev. A\n\\textbf{81}, 062129 (2010)] on the DTQW with position measurements. We show\nthat the position measurements per each step with probability $p \\sim\n1/n^\\beta$ can be evaluated, where $n$ is the final time and $0<\\beta<1$. We\nalso give a corresponding continuous-time case. As a consequence, crossovers\nfrom the diffusive spreading (random walk) to the ballistic spreading (quantum\nwalk) can be seen as the parameter $\\beta$ shifts from 0 to 1 in both discrete-\nand continuous-time cases of the weak convergence theorems. Secondly, we\nintroduce a new class of the DTQW, in which the absolute value of the diagonal\nparts of the quantum coin is proportional to a power of the inverse of the\nfinal time $n$. This is called a final-time-dependent DTQW (FTD-DTQW). The CTQW\nis obtained in a limit of the FTD-DTQW. We also obtain the weak convergence\ntheorem for the FTD-DTQW which shows a variety of spreading properties.\nFinally, we consider the FTD-DTQW with periodic position measurements. This\nweak convergence theorem gives a phase diagram which maps sufficiently\nlong-time behaviors of the discrete- and continuous-time quantum and random\nwalks.\n",
    "  Little is known about the global topology of the Fatou set $U(f)$ for\nholomorphic endomorphisms $f: \\mathbb{CP}^k \\to \\mathbb{CP}^k$, when $k >1$.\nClassical theory describes $U(f)$ as the complement in $ \\mathbb{CP}^k$ of the\nsupport of a dynamically-defined closed positive $(1,1)$ current. Given any\nclosed positive $(1,1)$ current $S$ on $ \\mathbb{CP}^k$, we give a definition\nof linking number between closed loops in $\\mathbb{CP}^k \\setminus \\supp S$ and\nthe current $S$. It has the property that if $lk(\\gamma,S) \\neq 0$, then\n$\\gamma$ represents a non-trivial homology element in $H_1(\\mathbb{CP}^k\n\\setminus \\supp S)$.\n  As an application, we use these linking numbers to establish that many\nclasses of endomorphisms of $\\mathbb{CP}^2$ have Fatou components with\ninfinitely generated first homology. For example, we prove that the Fatou set\nhas infinitely generated first homology for any polynomial endomorphism of\n$\\mathbb{CP}^2$ for which the restriction to the line at infinity is hyperbolic\nand has disconnected Julia set. In addition we show that a polynomial skew\nproduct of $\\mathbb{CP}^2$ has Fatou set with infinitely generated first\nhomology if some vertical Julia set is disconnected. We then conclude with a\nsection of concrete examples and questions for further study.\n",
    "The Voronoi diagram-based dual-front active contour models are known as a\npowerful and efficient way for addressing the image segmentation and domain\npartitioning problems. In the basic formulation of the dual-front models, the\nevolving contours can be considered as the interfaces of adjacent Voronoi\nregions. Among these dual-front models, a crucial ingredient is regarded as the\ngeodesic metrics by which the geodesic distances and the corresponding Voronoi\ndiagram can be estimated. In this paper, we introduce a type of asymmetric\nquadratic metrics dual-front model. The metrics considered are built by the\nintegration of the image features and a vector field derived from the evolving\ncontours. The use of the asymmetry enhancement can reduce the risk of contour\nshortcut or leakage problems especially when the initial contours are far away\nfrom the target boundaries or the images have complicated intensity\ndistributions. Moreover, the proposed dual-front model can be applied for image\nsegmentation in conjunction with various region-based homogeneity terms. The\nnumerical experiments on both synthetic and real images show that the proposed\ndual-front model indeed achieves encouraging results.",
    "Semantic segmentation is a critical method in the field of autonomous\ndriving. When performing semantic image segmentation, a wider field of view\n(FoV) helps to obtain more information about the surrounding environment,\nmaking automatic driving safer and more reliable, which could be offered by\nfisheye cameras. However, large public fisheye datasets are not available, and\nthe fisheye images captured by the fisheye camera with large FoV comes with\nlarge distortion, so commonly-used semantic segmentation model cannot be\ndirectly utilized. In this paper, a seven degrees of freedom (DoF) augmentation\nmethod is proposed to transform rectilinear image to fisheye image in a more\ncomprehensive way. In the training process, rectilinear images are transformed\ninto fisheye images in seven DoF, which simulates the fisheye images taken by\ncameras of different positions, orientations and focal lengths. The result\nshows that training with the seven-DoF augmentation can improve the model's\naccuracy and robustness against different distorted fisheye data. This\nseven-DoF augmentation provides a universal semantic segmentation solution for\nfisheye cameras in different autonomous driving applications. Also, we provide\nspecific parameter settings of the augmentation for autonomous driving. At\nlast, we tested our universal semantic segmentation model on real fisheye\nimages and obtained satisfactory results. The code and configurations are\nreleased at https://github.com/Yaozhuwa/FisheyeSeg.",
    "The standard petrography test method for measuring air voids in concrete\n(ASTM C457) requires a meticulous and long examination of sample phase\ncomposition under a stereomicroscope. The high expertise and specialized\nequipment discourage this test for routine concrete quality control. Though the\ntask can be alleviated with the aid of color-based image segmentation,\nadditional surface color treatment is required. Recently, deep learning\nalgorithms using convolutional neural networks (CNN) have achieved\nunprecedented segmentation performance on image testing benchmarks. In this\nstudy, we investigated the feasibility of using CNN to conduct concrete\nsegmentation without the use of color treatment. The CNN demonstrated a strong\npotential to process a wide range of concretes, including those not involved in\nmodel training. The experimental results showed that CNN outperforms the\ncolor-based segmentation by a considerable margin, and has comparable accuracy\nto human experts. Furthermore, the segmentation time is reduced to mere\nseconds.",
    "Image segmentation is a primary task in many medical applications. Recently,\nmany deep networks derived from U-Net have been extensively used in various\nmedical image segmentation tasks. However, in most of the cases, networks\nsimilar to U-net produce coarse and non-smooth segmentations with lots of\ndiscontinuities. To improve and refine the performance of U-Net like networks,\nwe propose the use of parallel decoders which along with performing the mask\npredictions also perform contour prediction and distance map estimation. The\ncontour and distance map aid in ensuring smoothness in the segmentation\npredictions. To facilitate joint training of three tasks, we propose a novel\narchitecture called Psi-Net with a single encoder and three parallel decoders\n(thus having a shape of $\\Psi$), one decoder to learns the segmentation mask\nprediction and other two decoders to learn the auxiliary tasks of contour\ndetection and distance map estimation. The learning of these auxiliary tasks\nhelps in capturing the shape and the boundary information. We also propose a\nnew joint loss function for the proposed architecture. The loss function\nconsists of a weighted combination of Negative Log likelihood and Mean Square\nError loss. We have used two publicly available datasets: 1) Origa dataset for\nthe task of optic cup and disc segmentation and 2) Endovis segment dataset for\nthe task of polyp segmentation to evaluate our model. We have conducted\nextensive experiments using our network to show our model gives better results\nin terms of segmentation, boundary and shape metrics.",
    "While improving prediction accuracy has been the focus of machine learning in\nrecent years, this alone does not suffice for reliable decision-making.\nDeploying learning systems in consequential settings also requires calibrating\nand communicating the uncertainty of predictions. To convey instance-wise\nuncertainty for prediction tasks, we show how to generate set-valued\npredictions from a black-box predictor that control the expected loss on future\ntest points at a user-specified level. Our approach provides explicit\nfinite-sample guarantees for any dataset by using a holdout set to calibrate\nthe size of the prediction sets. This framework enables simple,\ndistribution-free, rigorous error control for many tasks, and we demonstrate it\nin five large-scale machine learning problems: (1) classification problems\nwhere some mistakes are more costly than others; (2) multi-label\nclassification, where each observation has multiple associated labels; (3)\nclassification problems where the labels have a hierarchical structure; (4)\nimage segmentation, where we wish to predict a set of pixels containing an\nobject of interest; and (5) protein structure prediction. Lastly, we discuss\nextensions to uncertainty quantification for ranking, metric learning and\ndistributionally robust learning.",
    "  We undertook a mutually complementary analytic and computational study of the\nfull-fledged spherical (3D) quantum rotor subject to combined orienting and\naligning interactions characterized, respectively, by dimensionless parameters\n$\\eta$ and $\\zeta$. By making use of supersymmetric quantum mechanics (SUSY\nQM), we found two sets of conditions under which the problem of a spherical\nquantum pendulum becomes analytically solvable. These conditions coincide with\nthe loci $\\zeta=\\frac{\\eta^2}{4k^2}$ of the intersections of the eigenenergy\nsurfaces spanned by the $\\eta$ and $\\zeta$ parameters. The integer topological\nindex $k$ is independent of the eigenstate and thus of the projection quantum\nnumber $m$. These findings have repercussions for rotational spectra and\ndynamics of molecules subject to combined permanent and induced dipole\ninteractions.\n",
    "  We obtain the existence and the structure of the weak uniform (with respect\nto the initial time) global attractor and construct a trajectory attractor for\nthe 3D Navier-Stokes equations (NSE) with a fixed time-dependent force\nsatisfying a translation boundedness condition. Moreover, we show that if the\nforce is normal and every complete bounded solution is strongly continuous,\nthen the uniform global attractor is strong, strongly compact, and solutions\nconverge strongly toward the trajectory attractor. Our method is based on\ntaking a closure of the autonomous evolutionary system without uniqueness,\nwhose trajectories are solutions to the nonautonomous 3D NSE. The established\nframework is general and can also be applied to other nonautonomous dissipative\npartial differential equations for which the uniqueness of solutions might not\nhold. It is not known whether previous frameworks can also be applied in such\ncases as we indicate in open problems related to the question of uniqueness of\nthe Leray-Hopf weak solutions.\n",
    "One of the most challenging tasks in microarray image analysis is spot\nsegmentation. A solution to this problem is to provide an algorithm than can be\nused to find any spot within the microarray image. Circular Hough\nTransformation (CHT) is a powerful feature extraction technique used in image\nanalysis, computer vision, and digital image processing. CHT algorithm is\napplied on the cDNA microarray images to develop the accuracy and the\nefficiency of the spots localization, addressing and segmentation process. The\npurpose of the applied technique is to find imperfect instances of spots within\na certain class of circles by applying a voting procedure on the cDNA\nmicroarray images for spots localization, addressing and characterizing the\npixels of each spot into foreground pixels and background simultaneously.\nIntensive experiments on the University of North Carolina (UNC) microarray\ndatabase indicate that the proposed method is superior to the K-means method\nand the Support vector machine (SVM). Keywords: Hough circle transformation,\ncDNA microarray image analysis, cDNA microarray image segmentation, spots\nlocalization and addressing, spots segmentation",
    "  We present XMM-Newton and Chandra observations of two low-metallicity\ncometary blue compact dwarf (BCD) galaxies, Mrk 59 and Mrk 71. The first BCD,\nMrk 59, contains two ultraluminous X-ray (ULX) sources, IXO 72 and IXO 73, both\nassociated with bright massive stars and H II complexes, as well as one fainter\nextended source associated with a massive H II complex at the head of the\ncometary structure. The low-metallicity of Mrk 59 appears to be responsible for\nthe presence of the two ULXs. IXO 72 has varied little over the last 10 yr,\nwhile IXO 73 has demonstrated a variability factor of ~4 over the same period.\nThe second BCD, Mrk 71, contains two faint X-ray point sources and two faint\nextended sources. One point source is likely a background AGN, while the other\nappears to be coincident with a very luminous star and a compact H II region at\nthe \"head\" of the cometary structure. The two faint extended sources are also\nassociated with massive H II complexes. Although both BCDs have the same\nmetallicity, the three sources in Mrk 71 have X-ray luminosities ~1-2 orders of\nmagnitude fainter than those in Mrk 59. The age of the starburst may play a\nrole.\n",
    "Deep Learning is considered to be a quite young in the area of machine\nlearning research, found its effectiveness in dealing complex yet high\ndimensional dataset that includes but limited to images, text and speech etc.\nwith multiple levels of representation and abstraction. As there are a plethora\nof research on these datasets by various researchers , a win over them needs\nlots of attention. Careful setting of Deep learning parameters is of paramount\nimportance in order to avoid the overfitting unlike conventional methods with\nlimited parameter settings. Deep Convolutional neural network (DCNN) with\nmultiple layers of compositions and appropriate settings might be is an\nefficient machine learning method that can outperform the conventional methods\nin a great way. However, due to its slow adoption in learning, there are also\nalways a chance of overfitting during feature selection process, which can be\naddressed by employing a regularization method called dropout. Fast Random\nForest (FRF) is a powerful ensemble classifier especially when the datasets are\nnoisy and when the number of attributes is large in comparison to the number of\ninstances, as is the case of Bioinformatics datasets. Several publicly\navailable Bioinformatics dataset, Handwritten digits recognition and Image\nsegmentation dataset are considered for evaluation of the proposed approach.\nThe excellent performance obtained by the proposed DCNN based feature selection\nwith FRF classifier on high dimensional datasets makes it a fast and accurate\nclassifier in comparison the state-of-the-art.",
    "  We present the construction of a dense, quasicrystalline packing of regular\ntetrahedra with icosahedral symmetry. This quasicrystalline packing was\nachieved through two independent approaches. The first approach originates in\nthe Elser-Sloane 4D quasicrystal. A 3D slice of the quasicrystal contains a few\ntypes of prototiles. An initial structure is obtained by decorating these\nprototiles with tetrahedra. This initial structure is then modified using the\nElser-Sloane quasicrystal itself as a guide. The second approach proceeds by\ndecorating the prolate and oblate rhombohedra in a 3-dimensional Ammann tiling.\nThe resulting quasicrystal has a packing density of 59.783%. We also show a\nvariant of the quasicrystal that has just 10 \"plane classes\" (compared with the\n190 of the original), defined as the total number of distinct orientations of\nthe planes in which the faces of the tetrahedra are contained. This small\nnumber of plane classes was achieved by a certain \"golden rotation\" of the\ntetrahedra.\n",
    "Despite the success of deep learning methods in medical image segmentation\ntasks, the human-level performance relies on massive training data with\nhigh-quality annotations, which are expensive and time-consuming to collect.\nThe fact is that there exist low-quality annotations with label noise, which\nleads to suboptimal performance of learned models. Two prominent directions for\nsegmentation learning with noisy labels include pixel-wise noise robust\ntraining and image-level noise robust training. In this work, we propose a\nnovel framework to address segmenting with noisy labels by distilling effective\nsupervision information from both pixel and image levels. In particular, we\nexplicitly estimate the uncertainty of every pixel as pixel-wise noise\nestimation, and propose pixel-wise robust learning by using both the original\nlabels and pseudo labels. Furthermore, we present an image-level robust\nlearning method to accommodate more information as the complements to\npixel-level learning. We conduct extensive experiments on both simulated and\nreal-world noisy datasets. The results demonstrate the advantageous performance\nof our method compared to state-of-the-art baselines for medical image\nsegmentation with noisy labels.",
    "From the autonomous car driving to medical diagnosis, the requirement of the\ntask of image segmentation is everywhere. Segmentation of an image is one of\nthe indispensable tasks in computer vision. This task is comparatively\ncomplicated than other vision tasks as it needs low-level spatial information.\nBasically, image segmentation can be of two types: semantic segmentation and\ninstance segmentation. The combined version of these two basic tasks is known\nas panoptic segmentation. In the recent era, the success of deep convolutional\nneural networks (CNN) has influenced the field of segmentation greatly and gave\nus various successful models to date. In this survey, we are going to take a\nglance at the evolution of both semantic and instance segmentation work based\non CNN. We have also specified comparative architectural details of some\nstate-of-the-art models and discuss their training details to present a lucid\nunderstanding of hyper-parameter tuning of those models. We have also drawn a\ncomparison among the performance of those models on different datasets. Lastly,\nwe have given a glimpse of some state-of-the-art panoptic segmentation models.",
    "Preparation of high-quality datasets for the urban scene understanding is a\nlabor-intensive task, especially, for datasets designed for the autonomous\ndriving applications. The application of the coarse ground truth (GT)\nannotations of these datasets without detriment to the accuracy of semantic\nimage segmentation (by the mean intersection over union - mIoU) could simplify\nand speedup the dataset preparation and model fine tuning before its practical\napplication. Here the results of the comparative analysis for semantic\nsegmentation accuracy obtained by PSPNet deep learning architecture are\npresented for fine and coarse annotated images from Cityscapes dataset. Two\nscenarios were investigated: scenario 1 - the fine GT images for training and\nprediction, and scenario 2 - the fine GT images for training and the coarse GT\nimages for prediction. The obtained results demonstrated that for the most\nimportant classes the mean accuracy values of semantic image segmentation for\ncoarse GT annotations are higher than for the fine GT ones, and the standard\ndeviation values are vice versa. It means that for some applications some\nunimportant classes can be excluded and the model can be tuned further for some\nclasses and specific regions on the coarse GT dataset without loss of the\naccuracy even. Moreover, this opens the perspectives to use deep neural\nnetworks for the preparation of such coarse GT datasets.",
    "Most existing deep learning-based frameworks for image segmentation assume\nthat a unique ground truth is known and can be used for performance evaluation.\nThis is true for many applications, but not all. Myocardial segmentation of\nMyocardial Contrast Echocardiography (MCE), a critical task in automatic\nmyocardial perfusion analysis, is an example. Due to the low resolution and\nserious artifacts in MCE data, annotations from different cardiologists can\nvary significantly, and it is hard to tell which one is the best. In this case,\nhow can we find a good way to evaluate segmentation performance and how do we\ntrain the neural network? In this paper, we address the first problem by\nproposing a new extended Dice to effectively evaluate the segmentation\nperformance when multiple accepted ground truth is available. Then based on our\nproposed metric, we solve the second problem by further incorporating the new\nmetric into a loss function that enables neural networks to flexibly learn\ngeneral features of myocardium. Experiment results on our clinical MCE data set\ndemonstrate that the neural network trained with the proposed loss function\noutperforms those existing ones that try to obtain a unique ground truth from\nmultiple annotations, both quantitatively and qualitatively. Finally, our\ngrading study shows that using extended Dice as an evaluation metric can better\nidentify segmentation results that need manual correction compared with using\nDice.",
    "Image co-segmentation is important for its advantage of alleviating the\nill-pose nature of image segmentation through exploring the correlation between\nrelated images. Many automatic image co-segmentation algorithms have been\ndeveloped in the last decade, which are investigated comprehensively in this\npaper. We firstly analyze visual/semantic cues for guiding image\nco-segmentation, including object cues and correlation cues. Then we describe\nthe traditional methods in three categories of object elements based, object\nregions/contours based, common object model based. In the next part, deep\nlearning based methods are reviewed. Furthermore, widely used test datasets and\nevaluation criteria are introduced and the reported performances of the\nsurveyed algorithms are compared with each other. Finally, we discuss the\ncurrent challenges and possible future directions and conclude the paper.\nHopefully, this comprehensive investigation will be helpful for the development\nof image co-segmentation technique.",
    "  We consider the wave equation on a manifold $(\\Omega,g)$ of dimension $d\\geq\n2$ with smooth strictly convex boundary $\\partial\\Omega\\neq\\emptyset$, with\nDirichlet boundary conditions. We construct a sharp local in time parametrix\nand then proceed to obtain dispersion estimates: our fixed time decay rate for\nthe Green function exhibits a $t^{1/4}$ loss with respect to the boundary less\ncase. We precisely describe where and when these losses occur and relate them\nto swallowtail type singularities in the wave front set, proving that our decay\nis optimal. Moreover, we derive better than expected Strichartz estimates,\nbalancing lossy long time estimates at a given incidence with short time ones\nwith no loss: for $d=3$, it heuristically means that, on average the decay loss\nis only $t^{1/6}$.\n",
    "Quantitative bone single-photon emission computed tomography (QBSPECT) has\nthe potential to provide a better quantitative assessment of bone metastasis\nthan planar bone scintigraphy due to its ability to better quantify activity in\noverlapping structures. An important element of assessing response of bone\nmetastasis is accurate image segmentation. However, limited by the properties\nof QBSPECT images, the segmentation of anatomical regions-of-interests (ROIs)\nstill relies heavily on the manual delineation by experts. This work proposes a\nfast and robust automated segmentation method for partitioning a QBSPECT image\ninto lesion, bone, and background. We present a new unsupervised segmentation\nloss function and its semi- and supervised variants for training a\nconvolutional neural network (ConvNet). The loss functions were developed based\non the objective function of the classical Fuzzy C-means (FCM) algorithm. We\nconducted a comprehensive study to compare our proposed methods with ConvNets\ntrained using supervised loss functions and conventional clustering methods.\nThe Dice similarity coefficient (DSC) and several other metrics were used as\nfigures of merit as applied to the task of delineating lesion and bone in both\nsimulated and clinical SPECT/CT images. We experimentally demonstrated that the\nproposed methods yielded good segmentation results on a clinical dataset even\nthough the training was done using realistic simulated images. A ConvNet-based\nimage segmentation method that uses novel loss functions was developed and\nevaluated. The method can operate in unsupervised, semi-supervised, or\nfully-supervised modes depending on the availability of annotated training\ndata. The results demonstrated that the proposed method provides fast and\nrobust lesion and bone segmentation for QBSPECT/CT. The method can potentially\nbe applied to other medical image segmentation applications.",
    "Medical image annotations are prohibitively time-consuming and expensive to\nobtain. To alleviate annotation scarcity, many approaches have been developed\nto efficiently utilize extra information, e.g.,semi-supervised learning further\nexploring plentiful unlabeled data, domain adaptation including multi-modality\nlearning and unsupervised domain adaptation resorting to the prior knowledge\nfrom additional modality. In this paper, we aim to investigate the feasibility\nof simultaneously leveraging abundant unlabeled data and well-established\ncross-modality data for annotation-efficient medical image segmentation. To\nthis end, we propose a novel semi-supervised domain adaptation approach, namely\nDual-Teacher, where the student model not only learns from labeled target data\n(e.g., CT), but also explores unlabeled target data and labeled source data\n(e.g., MR) by two teacher models. Specifically, the student model learns the\nknowledge of unlabeled target data from intra-domain teacher by encouraging\nprediction consistency, as well as the shape priors embedded in labeled source\ndata from inter-domain teacher via knowledge distillation. Consequently, the\nstudent model can effectively exploit the information from all three data\nresources and comprehensively integrate them to achieve improved performance.\nWe conduct extensive experiments on MM-WHS 2017 dataset and demonstrate that\nour approach is able to concurrently utilize unlabeled data and cross-modality\ndata with superior performance, outperforming semi-supervised learning and\ndomain adaptation methods with a large margin.",
    "3D image segmentation is one of the most important and ubiquitous problems in\nmedical image processing. It provides detailed quantitative analysis for\naccurate disease diagnosis, abnormal detection, and classification. Currently\ndeep learning algorithms are widely used in medical image segmentation, most\nalgorithms trained models with full annotated datasets. However, obtaining\nmedical image datasets is very difficult and expensive, and full annotation of\n3D medical image is a monotonous and time-consuming work. Partially labelling\ninformative slices in 3D images will be a great relief of manual annotation.\nSample selection strategies based on active learning have been proposed in the\nfield of 2D image, but few strategies focus on 3D images. In this paper, we\npropose a sparse annotation strategy based on attention-guided active learning\nfor 3D medical image segmentation. Attention mechanism is used to improve\nsegmentation accuracy and estimate the segmentation accuracy of each slice. The\ncomparative experiments with three different strategies using datasets from the\ndeveloping human connectome project (dHCP) show that, our strategy only needs\n15% to 20% annotated slices in brain extraction task and 30% to 35% annotated\nslices in tissue segmentation task to achieve comparative results as full\nannotation.",
    "  The relevance of anisotropic interactions in colloidal systems has recently\nemerged in the context of the rational design of new soft materials. Patchy\ncolloids of different shapes, patterns and functionalities are considered the\nnew building blocks of a bottom-up approach toward the realization of\nselfassembled bulk materials with predefined properties. The ability to tune\nthe interaction anisotropy will make it possible to recreate molecular\nstructures at the nano- and microscales (a case with tremendous technological\napplications), as well as to generate new unconventional phases, both ordered\nand disordered. Recent theoretical studies suggest that the phase diagram of\npatchy colloids can be significantly altered by limiting the particle\ncoordination number (that is, valence). New concepts such as empty\nliquids-liquid states with vanishing density-and equilibrium gels arrested\nnetworks of bonded particles, which do not require an underlying phase\nseparation to form-have been formulated. Yet no experimental evidence of these\npredictions has been provided. Here we report the first observation of empty\nliquids and equilibrium gels in a complex colloidal clay, and support the\nexperimental findings with numerical simulations.\n",
    "  We report the design and implementation of a complete electronics platform\nfor conducting a quantum optics experiment that will be operated on board a 1U\nCubeSat (a 10 x 10 x 10 cm satellite). The quantum optics experiment is\ndesigned to produce polarization-entangled photon pairs using non-linear\noptical crystals and requires opto-electronic components such as a pump laser,\nsingle photon detectors and liquid crystal based polarization rotators in\naddition to passive optical elements. The platform provides mechanical support\nfor the optical assembly. It also communicates autonomously with the host\nsatellite to provide experiment data for transmission to a ground station. A\nlimited number of commands can be transmitted from ground to the platform\nenabling it to switch experimental modes. This platform requires less than 1.5W\nfor all operations, and is space qualified. The implementation of this\nelectronics platform is a major step on the road to operating quantum\ncommunication experiments using nanosatellites.\n",
    "  Let $A$ be a subset of positive relative upper density of $\\PP^d$, the\n$d$-tuples of primes. We prove that $A$ contains an affine copy of any finite\nset $F\\subs\\Z^d$, which provides a natural multi-dimensional extension of the\ntheorem of Green and Tao on the existence of long arithmetic progressions in\nthe primes. The proof uses the hypergraph approach by assigning a pseudo-random\nweight system to the pattern $F$ on a $d+1$-partite hypergraph; a novel feature\nbeing that the hypergraph is no longer uniform with weights attached to lower\ndimensional edges. Then, instead of using a transference principle, we proceed\nby extending the proof of the so-called hypergraph removal lemma to our\nsettings, relying only on the linear forms condition of Green and Tao.\n",
    "In this paper, we propose a novel deep learning framework for anatomy\nsegmentation and automatic landmark- ing. Specifically, we focus on the\nchallenging problem of mandible segmentation from cone-beam computed tomography\n(CBCT) scans and identification of 9 anatomical landmarks of the mandible on\nthe geodesic space. The overall approach employs three inter-related steps. In\nstep 1, we propose a deep neu- ral network architecture with carefully designed\nregularization, and network hyper-parameters to perform image segmentation\nwithout the need for data augmentation and complex post- processing refinement.\nIn step 2, we formulate the landmark localization problem directly on the\ngeodesic space for sparsely- spaced anatomical landmarks. In step 3, we propose\nto use a long short-term memory (LSTM) network to identify closely- spaced\nlandmarks, which is rather difficult to obtain using other standard detection\nnetworks. The proposed fully automated method showed superior efficacy compared\nto the state-of-the- art mandible segmentation and landmarking approaches in\ncraniofacial anomalies and diseased states. We used a very challenging CBCT\ndataset of 50 patients with a high-degree of craniomaxillofacial (CMF)\nvariability that is realistic in clinical practice. Complementary to the\nquantitative analysis, the qualitative visual inspection was conducted for\ndistinct CBCT scans from 250 patients with high anatomical variability. We have\nalso shown feasibility of the proposed work in an independent dataset from\nMICCAI Head-Neck Challenge (2015) achieving the state-of-the-art performance.\nLastly, we present an in-depth analysis of the proposed deep networks with\nrespect to the choice of hyper-parameters such as pooling and activation\nfunctions.",
    "This work examines the use of a fully convolutional net (FCN) to find an\nimage segment, given a pixel within this segment region. The net receives an\nimage, a point in the image and a region of interest (RoI ) mask. The net\noutput is a binary mask of the segment in which the point is located. The\nregion where the segment can be found is contained within the input RoI mask.\nFull image segmentation can be achieved by running this net sequentially,\nregion-by-region on the image, and stitching the output segments into a single\nsegmentation map. This simple method addresses two major challenges of image\nsegmentation: 1) Segmentation of unknown categories that were not included in\nthe training set. 2) Segmentation of both individual object instances (things)\nand non-objects (stuff), such as sky and vegetation. Hence, if the pointer\npixel is located within a person in a group, the net will output a mask that\ncovers that individual person; if the pointer point is located within the sky\nregion, the net returns the region of the sky in the image. This is true even\nif no example for sky or person appeared in the training set. The net was\ntested and trained on the COCO panoptic dataset and achieved 67% IOU for\nsegmentation of familiar classes (that were part of the net training set) and\n53% IOU for segmentation of unfamiliar classes (that were not included in the\ntraining).",
    "  In this paper, we develop a loop group description of harmonic maps\n$\\mathcal{F}: M \\rightarrow G/K$ ``of finite uniton type\", from a Riemann\nsurface $M$ into inner symmetric spaces of compact or non-compact type. This\ndevelops work of Uhlenbeck, Segal, and Burstall-Guest to non-compact inner\nsymmetric spaces. To be more concrete, we prove that every harmonic map of\nfinite uniton type from any Riemann surface into any compact or non-compact\ninner symmetric space has a normalized potential taking values in some\nnilpotent Lie subalgebra, as well as a normalized frame with initial condition\nidentity. This provides a straightforward way to construct all such harmonic\nmaps. We also illustrate the above results exclusively by Willmore surfaces,\nsince this problem is motivated by the study of Willmore two-spheres in\nspheres.\n",
    "Clustering is an unsupervised machine learning method grouping data samples\ninto clusters of similar objects. In practice, clustering has been used in\nnumerous applications such as banking customers profiling, document retrieval,\nimage segmentation, and e-commerce recommendation engines. However, the\nexisting clustering techniques present significant limitations, from which is\nthe dependability of their stability on the initialization parameters (e.g.\nnumber of clusters, centroids). Different solutions were presented in the\nliterature to overcome this limitation (i.e. internal and external validation\nmetrics). However, these solutions require high computational complexity and\nmemory consumption, especially when dealing with big data. In this paper, we\napply the recent object detection Deep Learning (DL) model, named YOLO-v5, to\ndetect the initial clustering parameters such as the number of clusters with\ntheir sizes and centroids. Mainly, the proposed solution consists of adding a\nDL-based initialization phase making the clustering algorithms free of\ninitialization. Two model solutions are provided in this work, one for isolated\nclusters and the other one for overlapping clusters. The features of the\nincoming dataset determine which model to use. Moreover, The results show that\nthe proposed solution can provide near-optimal clusters initialization\nparameters with low computational and resources overhead compared to existing\nsolutions.",
    "Deep neural networks have achieved satisfactory performance in piles of\nmedical image analysis tasks. However the training of deep neural network\nrequires a large amount of samples with high-quality annotations. In medical\nimage segmentation, it is very laborious and expensive to acquire precise\npixel-level annotations. Aiming at training deep segmentation models on\ndatasets with probably corrupted annotations, we propose a novel Meta Corrupted\nPixels Mining (MCPM) method based on a simple meta mask network. Our method is\ntargeted at automatically estimate a weighting map to evaluate the importance\nof every pixel in the learning of segmentation network. The meta mask network\nwhich regards the loss value map of the predicted segmentation results as\ninput, is capable of identifying out corrupted layers and allocating small\nweights to them. An alternative algorithm is adopted to train the segmentation\nnetwork and the meta mask network, simultaneously. Extensive experimental\nresults on LIDC-IDRI and LiTS datasets show that our method outperforms\nstate-of-the-art approaches which are devised for coping with corrupted\nannotations.",
    "  Modern mobile devices have access to a wealth of data suitable for learning\nmodels, which in turn can greatly improve the user experience on the device.\nFor example, language models can improve speech recognition and text entry, and\nimage models can automatically select good photos. However, this rich data is\noften privacy sensitive, large in quantity, or both, which may preclude logging\nto the data center and training there using conventional approaches. We\nadvocate an alternative that leaves the training data distributed on the mobile\ndevices, and learns a shared model by aggregating locally-computed updates. We\nterm this decentralized approach Federated Learning.\n  We present a practical method for the federated learning of deep networks\nbased on iterative model averaging, and conduct an extensive empirical\nevaluation, considering five different model architectures and four datasets.\nThese experiments demonstrate the approach is robust to the unbalanced and\nnon-IID data distributions that are a defining characteristic of this setting.\nCommunication costs are the principal constraint, and we show a reduction in\nrequired communication rounds by 10-100x as compared to synchronized stochastic\ngradient descent.\n",
    "  Let $R$ be an artin algebra and $\\mathcal{C}$ an additive subcategory of\n$\\operatorname{mod}(R)$. We construct a $t$-structure on the homotopy category\n$\\operatorname{K}^{-}(\\mathcal{C})$ whose heart $\\mathcal{H}_{\\mathcal{C}}$ is\na natural domain for higher Auslander-Reiten (AR) theory. The abelian\ncategories $\\mathcal{H}_{\\operatorname{mod}(R)}$ (which is the natural domain\nfor classical AR theory) and $\\mathcal{H}_{\\mathcal{C}}$ interact via various\nfunctors. If $\\mathcal{C}$ is functorially finite then\n$\\mathcal{H}_{\\mathcal{C}}$ is a quotient category of\n$\\mathcal{H}_{\\operatorname{mod}(R)}$. We illustrate the theory with two\nexamples:\n  Iyama developed a higher AR theory when $\\mathcal{C}$ is a maximal\n$n$-orthogonal subcategory, see \\cite{I}. In this case we show that the simple\nobjects of $\\mathcal{H}_{\\mathcal{C}}$ correspond to Iyama's higher AR\nsequences and derive his higher AR duality from the existence of a Serre\nfunctor on the derived category\n$\\operatorname{D}^b(\\mathcal{H}_{\\mathcal{C}})$.\n  The category $\\mathcal{O}$ of a complex semi-simple Lie algebra\n$\\mathfrak{g}$ fits into higher AR theory by considering $R$ to be the\ncoinvariant algebra of the Weyl group of $\\mathfrak{g}$.\n",
    "  We investigate periodicities in mean heliographic latitudes of sunspot\ngroups, called active latitudes, for the last six complete solar cycles\n(1945-2008). For this purpose, the Multi Taper Method and Morlet Wavelet\nanalysis methods were used. We found the following: 1) Solar rotation\nperiodicities (26-38 days) are present in active latitudes of both hemispheres\nfor all the investigated cycles (18 to 23). 2) Both in the northern and\nsouthern hemispheres, active latitudes drifted towards the equator starting\nfrom the beginning to the end of each cycle by following an oscillating path.\nThese motions are well described by a second order polynomial. 3) There are no\nmeaningful periods between 55 and about 300 days in either hemisphere for all\ncycles. 4) A 300 to 370 day periodicity appears in both hemispheres for Cycle\n23, in the northern hemisphere for Cycle 20, and in the southern hemisphere for\nCycle 18.\n",
    "Advances in computing technology have allowed researchers across many fields\nof endeavor to collect and maintain vast amounts of observational statistical\ndata such as clinical data,biological patient data,data regarding access of web\nsites,financial data,and the like.Brain Magnetic Resonance\nImaging(MRI)segmentation is a complex problem in the field of medical imaging\ndespite various presented methods.MR image of human brain can be divided into\nseveral sub regions especially soft tissues such as gray matter,white matter\nand cerebrospinal fluid.Although edge information is the main clue in image\nsegmentation,it can not get a better result in analysis the content of images\nwithout combining other information.The segmentation of brain tissue in the\nmagnetic resonance imaging(MRI)is very important for detecting the existence\nand outlines of tumors.In this paper,an algorithm about segmentation based on\nthe symmetry character of brain MRI image is presented.Our goal is to detect\nthe position and boundary of tumors automatically.Experiments were conducted on\nreal pictures,and the results show that the algorithm is flexible and\nconvenient.",
    "  We study the problem of scheduling $n$ independent moldable tasks on $m$\nprocessors that arises in large-scale parallel computations. When tasks are\nmonotonic, the best known result is a $(\\frac{3}{2}+\\epsilon)$-approximation\nalgorithm for makespan minimization with a complexity linear in $n$ and\npolynomial in $\\log{m}$ and $\\frac{1}{\\epsilon}$ where $\\epsilon$ is\narbitrarily small. We propose a new perspective of the existing speedup models:\nthe speedup of a task $T_{j}$ is linear when the number $p$ of assigned\nprocessors is small (up to a threshold $\\delta_{j}$) while it presents\nmonotonicity when $p$ ranges in $[\\delta_{j}, k_{j}]$; the bound $k_{j}$\nindicates an unacceptable overhead when parallelizing on too many processors.\nThe generality of this model is proved to be between the classic monotonic and\nlinear-speedup models. For any given integer $\\delta\\geq 5$, let $u=\\left\\lceil\n\\sqrt[2]{\\delta} \\right\\rceil-1\\geq 2$. In this paper, we propose a\n$\\frac{1}{\\theta(\\delta)} (1+\\epsilon)$-approximation algorithm for makespan\nminimization where $\\theta(\\delta) = \\frac{u+1}{u+2}\\left( 1- \\frac{k}{m}\n\\right)$ ($m\\gg k$). As a by-product, we also propose a\n$\\theta(\\delta)$-approximation algorithm for throughput maximization with a\ncommon deadline.\n",
    "We propose a segmentation framework that uses deep neural networks and\nintroduce two innovations. First, we describe a biophysics-based domain\nadaptation method. Second, we propose an automatic method to segment white and\ngray matter, and cerebrospinal fluid, in addition to tumorous tissue. Regarding\nour first innovation, we use a domain adaptation framework that combines a\nnovel multispecies biophysical tumor growth model with a generative adversarial\nmodel to create realistic looking synthetic multimodal MR images with known\nsegmentation. Regarding our second innovation, we propose an automatic approach\nto enrich available segmentation data by computing the segmentation for healthy\ntissues. This segmentation, which is done using diffeomorphic image\nregistration between the BraTS training data and a set of prelabeled atlases,\nprovides more information for training and reduces the class imbalance problem.\nOur overall approach is not specific to any particular neural network and can\nbe used in conjunction with existing solutions. We demonstrate the performance\nimprovement using a 2D U-Net for the BraTS'18 segmentation challenge. Our\nbiophysics based domain adaptation achieves better results, as compared to the\nexisting state-of-the-art GAN model used to create synthetic data for training.",
    "  In the regime of weak nonlinearity we present two general feasible schemes.\nOne is an entangler for generating any one of the $n$-photon\nGreenberger-Horne-Zeilinge (GHZ) states and Bell states. After the interactions\nwith cross-Kerr nonlinear media, a phase gate followed by a measurement on the\nprobe beam, and appropriate local operations via classical feed-forward, one\ncan obtain the desired states in a nearly deterministic way. Another scheme is\nan analyzer for multiphoton maximally entangled states, which is taken as a\nfurther application of the above entangler. In this scheme, all of the $2^n$\n$n$-photon GHZ states can, nearly deterministically, be discriminated.\nFurthermore, an efficient two-step nondestructive Bell-state analyzer is\ndesigned.\n",
    "  It is an important task to faithfully evaluate the perceptual quality of\noutput images in many applications such as image compression, image restoration\nand multimedia streaming. A good image quality assessment (IQA) model should\nnot only deliver high quality prediction accuracy but also be computationally\nefficient. The efficiency of IQA metrics is becoming particularly important due\nto the increasing proliferation of high-volume visual data in high-speed\nnetworks. We present a new effective and efficient IQA model, called gradient\nmagnitude similarity deviation (GMSD). The image gradients are sensitive to\nimage distortions, while different local structures in a distorted image suffer\ndifferent degrees of degradations. This motivates us to explore the use of\nglobal variation of gradient based local quality map for overall image quality\nprediction. We find that the pixel-wise gradient magnitude similarity (GMS)\nbetween the reference and distorted images combined with a novel pooling\nstrategy the standard deviation of the GMS map can predict accurately\nperceptual image quality. The resulting GMSD algorithm is much faster than most\nstate-of-the-art IQA methods, and delivers highly competitive prediction\naccuracy.\n",
    "Image segmentation refers to the separation of objects from the background,\nand has been one of the most challenging aspects of digital image processing.\nPractically it is impossible to design a segmentation algorithm which has 100%\naccuracy, and therefore numerous segmentation techniques have been proposed in\nthe literature, each with certain limitations. In this paper, a novel\nFalling-Ball algorithm is presented, which is a region-based segmentation\nalgorithm, and an alternative to watershed transform (based on waterfall\nmodel). The proposed algorithm detects the catchment basins by assuming that a\nball falling from hilly terrains will stop in a catchment basin. Once catchment\nbasins are identified, the association of each pixel with one of the catchment\nbasin is obtained using multi-criterion fuzzy logic. Edges are constructed by\ndividing image into different catchment basins with the help of a membership\nfunction. Finally closed contour algorithm is applied to find closed regions\nand objects within closed regions are segmented using intensity information.\nThe performance of the proposed algorithm is evaluated both objectively as well\nas subjectively. Simulation results show that the proposed algorithms gives\nsuperior performance over conventional Sobel edge detection methods and the\nwatershed segmentation algorithm. For comparative analysis, various comparison\nmethods are used for demonstrating the superiority of proposed methods over\nexisting segmentation methods.",
    "  The effects of residual amplitude modulation (RAM) in laser interferometers\nusing heterodyne sensing can be substantial and difficult to mitigate. In this\nwork, we analyze the effects of RAM on a complex laser interferometer used for\ngravitational wave detection. The RAM introduces unwanted offsets in the cavity\nlength signals and thereby shifts the operating point of the optical cavities\nfrom the nominal point via feedback control. This shift causes variations in\nthe sensing matrix, and leads to degradation in the performance of the\nprecision noise subtraction scheme of the multiple-degree-of-freedom control\nsystem. In addition, such detuned optical cavities produce an opto-mechanical\nspring, which also varies the sensing matrix. We use our simulations to derive\nrequirements on RAM for the Advanced LIGO detectors, and show that the RAM\nexpected in Advanced LIGO will not limit its sensitivity.\n",
    "Recent years have witnessed the great progress of deep neural networks on\nsemantic segmentation, particularly in medical imaging. Nevertheless, training\nhigh-performing models require large amounts of pixel-level ground truth masks,\nwhich can be prohibitive to obtain in the medical domain. Furthermore, training\nsuch models in a low-data regime highly increases the risk of overfitting.\nRecent attempts to alleviate the need for large annotated datasets have\ndeveloped training strategies under the few-shot learning paradigm, which\naddresses this shortcoming by learning a novel class from only a few labeled\nexamples. In this context, a segmentation model is trained on episodes, which\nrepresent different segmentation problems, each of them trained with a very\nsmall labeled dataset. In this work, we propose a novel few-shot learning\nframework for semantic segmentation, where unlabeled images are also made\navailable at each episode. To handle this new learning paradigm, we propose to\ninclude surrogate tasks that can leverage very powerful supervisory signals\n--derived from the data itself-- for semantic feature learning. We show that\nincluding unlabeled surrogate tasks in the episodic training leads to more\npowerful feature representations, which ultimately results in better\ngenerability to unseen tasks. We demonstrate the efficiency of our method in\nthe task of skin lesion segmentation in two publicly available datasets.\nFurthermore, our approach is general and model-agnostic, which can be combined\nwith different deep architectures.",
    "Convolutional Neural Network (CNN) based image segmentation has made great\nprogress in recent years. However, video object segmentation remains a\nchallenging task due to its high computational complexity. Most of the previous\nmethods employ a two-stream CNN framework to handle spatial and motion features\nseparately. In this paper, we propose an end-to-end encoder-decoder style 3D\nCNN to aggregate spatial and temporal information simultaneously for video\nobject segmentation. To efficiently process video, we propose 3D separable\nconvolution for the pyramid pooling module and decoder, which dramatically\nreduces the number of operations while maintaining the performance. Moreover,\nwe also extend our framework to video action segmentation by adding an extra\nclassifier to predict the action label for actors in videos. Extensive\nexperiments on several video datasets demonstrate the superior performance of\nthe proposed approach for action and object segmentation compared to the\nstate-of-the-art.",
    "Image-to-image translation is a long-established and a difficult problem in\ncomputer vision. In this paper we propose an adversarial based model for\nimage-to-image translation. The regular deep neural-network based methods\nperform the task of image-to-image translation by comparing gram matrices and\nusing image segmentation which requires human intervention. Our generative\nadversarial network based model works on a conditional probability approach.\nThis approach makes the image translation independent of any local, global and\ncontent or style features. In our approach we use a bidirectional\nreconstruction model appended with the affine transform factor that helps in\nconserving the content and photorealism as compared to other models. The\nadvantage of using such an approach is that the image-to-image translation is\nsemi-supervised, independant of image segmentation and inherits the properties\nof generative adversarial networks tending to produce realistic. This method\nhas proven to produce better results than Multimodal Unsupervised\nImage-to-image translation.",
    "  In this paper we introduce and study a new family of combinatorial simplicial\ncomplexes, which we call immediate snapshot complexes. Our construction and\nterminology is strongly motivated by theoretical distributed computing, as\nthese complexes are combinatorial models of the standard protocol complexes\nassociated to immediate snapshot read/write shared memory communication model.\nIn order to define the immediate snapshot complexes we need a new combinatorial\nobject, which we call a witness structure. These objects are indexing the\nsimplices in the immediate snapshot complexes, while a special operation on\nthem, called ghosting, describes the combinatorics of taking simplicial\nboundary. In general, we develop the theory of witness structures and use it to\nprove several combinatorial as well as topological properties of the immediate\nsnapshot complexes.\n",
    "Scene labeling is the problem of assigning an object label to each pixel. It\nunifies the image segmentation and object recognition problems. The importance\nof using contextual information in scene labeling frameworks has been widely\nrealized in the field. We propose a contextual framework, called contextual\nhierarchical model (CHM), which learns contextual information in a hierarchical\nframework for scene labeling. At each level of the hierarchy, a classifier is\ntrained based on downsampled input images and outputs of previous levels. Our\nmodel then incorporates the resulting multi-resolution contextual information\ninto a classifier to segment the input image at original resolution. This\ntraining strategy allows for optimization of a joint posterior probability at\nmultiple resolutions through the hierarchy. Contextual hierarchical model is\npurely based on the input image patches and does not make use of any fragments\nor shape examples. Hence, it is applicable to a variety of problems such as\nobject segmentation and edge detection. We demonstrate that CHM outperforms\nstate-of-the-art on Stanford background and Weizmann horse datasets. It also\noutperforms state-of-the-art edge detection methods on NYU depth dataset and\nachieves state-of-the-art on Berkeley segmentation dataset (BSDS 500).",
    "Current state-of-the-art methods for image segmentation form a dense image\nrepresentation where the color, shape and texture information are all processed\ntogether inside a deep CNN. This however may not be ideal as they contain very\ndifferent type of information relevant for recognition. Here, we propose a new\ntwo-stream CNN architecture for semantic segmentation that explicitly wires\nshape information as a separate processing branch, i.e. shape stream, that\nprocesses information in parallel to the classical stream. Key to this\narchitecture is a new type of gates that connect the intermediate layers of the\ntwo streams. Specifically, we use the higher-level activations in the classical\nstream to gate the lower-level activations in the shape stream, effectively\nremoving noise and helping the shape stream to only focus on processing the\nrelevant boundary-related information. This enables us to use a very shallow\narchitecture for the shape stream that operates on the image-level resolution.\nOur experiments show that this leads to a highly effective architecture that\nproduces sharper predictions around object boundaries and significantly boosts\nperformance on thinner and smaller objects. Our method achieves\nstate-of-the-art performance on the Cityscapes benchmark, in terms of both mask\n(mIoU) and boundary (F-score) quality, improving by 2% and 4% over strong\nbaselines.",
    "  The Ott-Antonsen (OA) ansatz [Chaos 18, 037113 (2008), Chaos 19, 023117\n(2009)] has been widely used to describe large systems of coupled phase\noscillators. If the coupling is sinusoidal and if the phase dynamics does not\ndepend on the specific oscillator, then the macroscopic behavior of the systems\ncan be fully described by a low-dimensional dynamics. Does the corresponding\nmanifold remain attractive when introducing an intrinsic dependence between an\noscillator's phase and its dynamics by additional, oscillator specific\nparameters? To answer this we extended the OA ansatz and proved that\nparameter-dependent oscillatory systems converge to the OA manifold given\ncertain conditions. Our proof confirms recent numerical findings that already\nhinted at this convergence. Furthermore we offer a thorough mathematical\nunderpinning for networks of so-called theta neurons, where the OA ansatz has\njust been applied. In a final step we extend our proof by allowing for\ntime-dependent and multi-dimensional parameters as well as for network\ntopologies other than global coupling. This renders the OA ansatz an excellent\nstarting point for the analysis of a broad class of realistic settings.\n",
    "Magnetic resonance imaging (MRI) is the non-invasive modality of choice for\nbody tissue composition analysis due to its excellent soft tissue contrast and\nlack of ionizing radiation. However, quantification of body composition\nrequires an accurate segmentation of fat, muscle and other tissues from MR\nimages, which remains a challenging goal due to the intensity overlap between\nthem. In this study, we propose a fully automated, data-driven image\nsegmentation platform that addresses multiple difficulties in segmenting MR\nimages such as varying inhomogeneity, non-standardness, and noise, while\nproducing high-quality definition of different tissues. In contrast to most\napproaches in the literature, we perform segmentation operation by combining\nthree different MRI contrasts and a novel segmentation tool which takes into\naccount variability in the data. The proposed system, based on a novel affinity\ndefinition within the fuzzy connectivity (FC) image segmentation family,\nprevents the need for user intervention and reparametrization of the\nsegmentation algorithms. In order to make the whole system fully automated, we\nadapt an affinity propagation clustering algorithm to roughly identify tissue\nregions and image background. We perform a thorough evaluation of the proposed\nalgorithm's individual steps as well as comparison with several approaches from\nthe literature for the main application of muscle/fat separation. Furthermore,\nwhole-body tissue composition and brain tissue delineation were conducted to\nshow the generalization ability of the proposed system. This new automated\nplatform outperforms other state-of-the-art segmentation approaches both in\naccuracy and efficiency.",
    "  This document presents a (mostly) chronologically-ordered bibliography of\nscientific publications on the superiorization methodology and perturbation\nresilience of algorithms which is compiled and continuously updated by us at:\nhttp://math.haifa.ac.il/yair/bib-superiorization-censor.html. Since the\nbeginnings of this topic we try to trace the work that has been published about\nit since its inception. To the best of our knowledge this bibliography\nrepresents all available publications on this topic to date, and while the URL\nis continuously updated we will revise this document and bring it up to date on\narXiv approximately once a year. Abstracts of the cited works, and some links\nand downloadable files of preprints or reprints are available on the above\nmentioned Internet page. If you know of a related scientific work in any form\nthat should be included here kindly write to me on: yair@math.haifa.ac.il with\nfull bibliographic details, a DOI if available, and a PDF copy of the work if\npossible. The Internet page was initiated on March 7, 2015, and has been last\nupdated on January 31, 2023. Comment: Some of the items have on the above\nmentioned Internet page more information and links than in this report.\nAcknowledgment: The compilation of this report was supported by the ISF-NSFC\njoint research program grant No. 2874/19 and by the U.S. National Institutes of\nHealth grant No. R01CA266467.\n",
    "Many deep learning architectures for semantic segmentation involve a Fully\nConvolutional Neural Network (FCN) followed by a Conditional Random Field (CRF)\nto carry out inference over an image. These models typically involve unary\npotentials based on local appearance features computed by FCNs, and binary\npotentials based on the displacement between pixels. We show that while current\nmethods succeed in segmenting whole objects, they perform poorly in situations\ninvolving a large number of object parts. We therefore suggest incorporating\ninto the inference algorithm additional higher-order potentials inspired by the\nway humans identify and localize parts. We incorporate two relations that were\nshown to be useful to human object identification - containment and attachment\n- into the energy term of the CRF and evaluate their performance on the Pascal\nVOC Parts dataset. Our experimental results show that the segmentation of fine\nparts is positively affected by the addition of these two relations, and that\nthe segmentation of fine parts can be further influenced by complex structural\nfeatures.",
    "Deep learning based medical image segmentation models usually require large\ndatasets with high-quality dense segmentations to train, which are very\ntime-consuming and expensive to prepare. One way to tackle this challenge is by\nusing the mixed-supervised learning framework, in which only a part of data is\ndensely annotated with segmentation label and the rest is weakly labeled with\nbounding boxes. The model is trained jointly in a multi-task learning setting.\nIn this paper, we propose Mixed-Supervised Dual-Network (MSDN), a novel\narchitecture which consists of two separate networks for the detection and\nsegmentation tasks respectively, and a series of connection modules between the\nlayers of the two networks. These connection modules are used to transfer\nuseful information from the auxiliary detection task to help the segmentation\ntask. We propose to use a recent technique called \"Squeeze and Excitation\" in\nthe connection module to boost the transfer. We conduct experiments on two\nmedical image segmentation datasets. The proposed MSDN model outperforms\nmultiple baselines.",
    "Image segmentation is still an open problem especially when intensities of\nthe interested objects are overlapped due to the presence of intensity\ninhomogeneity (also known as bias field). To segment images with intensity\ninhomogeneities, a bias correction embedded level set model is proposed where\nInhomogeneities are Estimated by Orthogonal Primary Functions (IEOPF). In the\nproposed model, the smoothly varying bias is estimated by a linear combination\nof a given set of orthogonal primary functions. An inhomogeneous intensity\nclustering energy is then defined and membership functions of the clusters\ndescribed by the level set function are introduced to rewrite the energy as a\ndata term of the proposed model. Similar to popular level set methods, a\nregularization term and an arc length term are also included to regularize and\nsmooth the level set function, respectively. The proposed model is then\nextended to multichannel and multiphase patterns to segment colourful images\nand images with multiple objects, respectively. It has been extensively tested\non both synthetic and real images that are widely used in the literature and\npublic BrainWeb and IBSR datasets. Experimental results and comparison with\nstate-of-the-art methods demonstrate that advantages of the proposed model in\nterms of bias correction and segmentation accuracy.",
    "  We introduce a high-level graphical framework for designing and analysing\nquantum error correcting codes, centred on what we term the coherent parity\ncheck (CPC). The graphical formulation is based on the diagrammatic tools of\nthe zx-calculus of quantum observables. The resulting framework leads to a\nconstruction for stabilizer codes that allows us to design and verify a broad\nrange of quantum codes based on classical ones, and that gives a means of\ndiscovering large classes of codes using both analytical and numerical methods.\nWe focus in particular on the smaller codes that will be the first used by\nnear-term devices. We show how CSS codes form a subset of CPC codes and, more\ngenerally, how to compute stabilizers for a CPC code. As an explicit example of\nthis framework, we give a method for turning almost any pair of classical\n[n,k,3] codes into a [[2n - k + 2, k, 3]] CPC code. Further, we give a simple\ntechnique for machine search which yields thousands of potential codes, and\ndemonstrate its operation for distance 3 and 5 codes. Finally, we use the\ngraphical tools to demonstrate how Clifford computation can be performed within\nCPC codes. As our framework gives a new tool for constructing small- to\nmedium-sized codes with relatively high code rates, it provides a new source\nfor codes that could be suitable for emerging devices, while its zx-calculus\nfoundations enable natural integration of error correction with graphical\ncompiler toolchains. It also provides a powerful framework for reasoning about\nall stabilizer quantum error correction codes of any size.\n",
    "Most current semantic segmentation methods rely on fully convolutional\nnetworks (FCNs). However, their use of large receptive fields and many pooling\nlayers cause low spatial resolution inside the deep layers. This leads to\npredictions with poor localization around the boundaries. Prior work has\nattempted to address this issue by post-processing predictions with CRFs or\nMRFs. But such models often fail to capture semantic relationships between\nobjects, which causes spatially disjoint predictions. To overcome these\nproblems, recent methods integrated CRFs or MRFs into an FCN framework. The\ndownside of these new models is that they have much higher complexity than\ntraditional FCNs, which renders training and testing more challenging.\n  In this work we introduce a simple, yet effective Convolutional Random Walk\nNetwork (RWN) that addresses the issues of poor boundary localization and\nspatially fragmented predictions with very little increase in model complexity.\nOur proposed RWN jointly optimizes the objectives of pixelwise affinity and\nsemantic segmentation. It combines these two objectives via a novel random walk\nlayer that enforces consistent spatial grouping in the deep layers of the\nnetwork. Our RWN is implemented using standard convolution and matrix\nmultiplication. This allows an easy integration into existing FCN frameworks\nand it enables end-to-end training of the whole network via standard\nback-propagation. Our implementation of RWN requires just $131$ additional\nparameters compared to the traditional FCNs, and yet it consistently produces\nan improvement over the FCNs on semantic segmentation and scene labeling.",
    "We address the problem of segmenting 3D multi-modal medical images in\nscenarios where very few labeled examples are available for training.\nLeveraging the recent success of adversarial learning for semi-supervised\nsegmentation, we propose a novel method based on Generative Adversarial\nNetworks (GANs) to train a segmentation model with both labeled and unlabeled\nimages. The proposed method prevents over-fitting by learning to discriminate\nbetween true and fake patches obtained by a generator network. Our work extends\ncurrent adversarial learning approaches, which focus on 2D single-modality\nimages, to the more challenging context of 3D volumes of multiple modalities.\nThe proposed method is evaluated on the problem of segmenting brain MRI from\nthe iSEG-2017 and MRBrainS 2013 datasets. Significant performance improvement\nis reported, compared to state-of-art segmentation networks trained in a\nfully-supervised manner. In addition, our work presents a comprehensive\nanalysis of different GAN architectures for semi-supervised segmentation,\nshowing recent techniques like feature matching to yield a higher performance\nthan conventional adversarial training approaches. Our code is publicly\navailable at https://github.com/arnab39/FewShot_GAN-Unet3D",
    "  In part I, using the theory of $\\infty$-categories, we constructed a natural\n``continuous action'' of $\\operatorname {Ham} (M, \\omega) $ on the Fukaya\ncategory of a closed monotone symplectic manifold. Here we show that this\naction is generally homotopically non-trivial, i.e implicitly the main part of\na conjecture of Teleman. We use this to give various applications. For example\nwe find new curvature constraint phenomena for smooth and singular\n$\\mathcal{G}$-connections on principal $\\mathcal{G}$-bundles over $S ^{4}$,\nwhere $\\mathcal{G}$ is $\\operatorname {PU} (2)$ or $\\operatorname {Ham} (S ^{2}\n)$. Even for the classical group $\\operatorname {PU} (2)$, these phenomena are\ninvisible to Chern-Weil theory, and are inaccessible to known Yang-Mills theory\nand quantum characteristic classes techniques. So this can be understood as one\napplication of Floer theory and the theory of $\\infty$-categories in basic\ndifferential geometry. We also develop, based on this $\\infty$-categorical\nFukaya theory, some basic new integer valued invariants of smooth manifolds,\ncalled quantum obstruction. On the way we also construct what we call quantum\nMaslov classes, which are higher degree variants of the relative Seidel\nmorphism. This also leads to new applications in Hofer geometry of the space of\nLagrangian equators in $S^2$.\n",
    "  Let $\\mathbf{G}$ be a reductive group defined over $\\mathbb{Q}$ and let\n$\\mathfrak{S}$ be a Siegel set in $\\mathbf{G}(\\mathbb{R})$. The Siegel property\ntells us that there are only finitely many $\\gamma \\in \\mathbf{G}(\\mathbb{Q})$\nof bounded determinant and denominator for which the translate\n$\\gamma.\\mathfrak{S}$ intersects $\\mathfrak{S}$. We prove a bound for the\nheight of these $\\gamma$ which is polynomial with respect to the determinant\nand denominator. The bound generalises a result of Habegger and Pila dealing\nwith the case of $\\mathbf{GL}_2$, and has applications to the Zilber--Pink\nconjecture on unlikely intersections in Shimura varieties.\n  In addition we prove that if $\\mathbf{H}$ is a subgroup of $\\mathbf{G}$, then\nevery Siegel set for $\\mathbf{H}$ is contained in a finite union of\n$\\mathbf{G}(\\mathbb{Q})$-translates of a Siegel set for $\\mathbf{G}$).\n",
    "Most progress in semantic segmentation reports on daytime images taken under\nfavorable illumination conditions. We instead address the problem of semantic\nsegmentation of nighttime images and improve the state-of-the-art, by adapting\ndaytime models to nighttime without using nighttime annotations. Moreover, we\ndesign a new evaluation framework to address the substantial uncertainty of\nsemantics in nighttime images. Our central contributions are: 1) a curriculum\nframework to gradually adapt semantic segmentation models from day to night via\nlabeled synthetic images and unlabeled real images, both for progressively\ndarker times of day, which exploits cross-time-of-day correspondences for the\nreal images to guide the inference of their labels; 2) a novel\nuncertainty-aware annotation and evaluation framework and metric for semantic\nsegmentation, designed for adverse conditions and including image regions\nbeyond human recognition capability in the evaluation in a principled fashion;\n3) the Dark Zurich dataset, which comprises 2416 unlabeled nighttime and 2920\nunlabeled twilight images with correspondences to their daytime counterparts\nplus a set of 151 nighttime images with fine pixel-level annotations created\nwith our protocol, which serves as a first benchmark to perform our novel\nevaluation. Experiments show that our guided curriculum adaptation\nsignificantly outperforms state-of-the-art methods on real nighttime sets both\nfor standard metrics and our uncertainty-aware metric. Furthermore, our\nuncertainty-aware evaluation reveals that selective invalidation of predictions\ncan lead to better results on data with ambiguous content such as our nighttime\nbenchmark and profit safety-oriented applications which involve invalid inputs.",
    "  Granular materials do not flow homogeneously like fluids when submitted to\nexternal stress,but often form rigid regions that are separated by narrow shear\nbands where the material yields and flows. This shear localization impacts\ntheir apparent rheology, which makes it difficult to infer a constitutive\nbehaviour from conventional rheometric measurements. Moreover, they present a\ndilatant behaviour, which makes their study in classical fixedvolume geometries\ndifficult. These features led to perform extensive studies with inclined plane\nflows, which were of crucial importance for the development and the validation\nof the $\\mu(I)$ rheology. Our aim is to develop a method to characterize\ngranular materials with rheometrical tools. Using unusual rheometry\nmeasurements in an annular shear cell adapted from Boyer et al. (2011), dense\ngranular flows are studied. A focus is placed on the comparison between the\npresent results and the $\\mu(I)$-rheology.\n",
    "  A Time to Digital Converter (TDC) based system, to be used for most\nsub-detectors in the high-flux rare-decay experiment NA62 at CERN SPS, was\nbuilt as part of the NA62 fully digital Trigger and Data AcQuisition system\n(TDAQ), in which the TDC Board (TDCB) and a general-purpose motherboard (TEL62)\nwill play a fundamental role. While TDCBs, housing four High Performance Time\nto Digital Converters (HPTDC), measure hit times from sub-detectors, the\nmotherboard processes and stores them in a buffer, produces trigger primitives\nfrom different detectors and extracts only data related to the lowest trigger\nlevel decision, once this is taken on the basis of the trigger primitives\nthemselves. The features of the TDCB board developed by the Pisa NA62 group are\nextensively discussed and performance data is presented in order to show its\ncompliance with the experiment requirements.\n",
    "We present the first method to handle curvature regularity in region-based\nimage segmentation and inpainting that is independent of initialization.\n  To this end we start from a new formulation of length-based optimization\nschemes, based on surface continuation constraints, and discuss the connections\nto existing schemes. The formulation is based on a \\emph{cell complex} and\nconsiders basic regions and boundary elements. The corresponding optimization\nproblem is cast as an integer linear program.\n  We then show how the method can be extended to include curvature regularity,\nagain cast as an integer linear program. Here, we are considering pairs of\nboundary elements to reflect curvature. Moreover, a constraint set is derived\nto ensure that the boundary variables indeed reflect the boundary of the\nregions described by the region variables.\n  We show that by solving the linear programming relaxation one gets quite\nclose to the global optimum, and that curvature regularity is indeed much\nbetter suited in the presence of long and thin objects compared to standard\nlength regularity.",
    "  The \"bag-of-frames\" approach (BOF), which encodes audio signals as the\nlong-term statistical distribution of short-term spectral features, is commonly\nregarded as an effective and sufficient way to represent environmental sound\nrecordings (soundscapes) since its introduction in an influential 2007 article.\nThe present paper describes a concep-tual replication of this seminal article\nusing several new soundscape datasets, with results strongly questioning the\nadequacy of the BOF approach for the task. We show that the good accuracy\noriginally re-ported with BOF likely result from a particularly thankful\ndataset with low within-class variability, and that for more realistic\ndatasets, BOF in fact does not perform significantly better than a mere\none-point av-erage of the signal's features. Soundscape modeling, therefore,\nmay not be the closed case it was once thought to be. Progress, we ar-gue,\ncould lie in reconsidering the problem of considering individual acoustical\nevents within each soundscape.\n",
    "Random fields have remained a topic of great interest over past decades for\nthe purpose of structured inference, especially for problems such as image\nsegmentation. The local nodal interactions commonly used in such models often\nsuffer the short-boundary bias problem, which are tackled primarily through the\nincorporation of long-range nodal interactions. However, the issue of\ncomputational tractability becomes a significant issue when incorporating such\nlong-range nodal interactions, particularly when a large number of long-range\nnodal interactions (e.g., fully-connected random fields) are modeled.\n  In this work, we introduce a generalized random field framework based around\nthe concept of stochastic cliques, which addresses the issue of computational\ntractability when using fully-connected random fields by stochastically forming\na sparse representation of the random field. The proposed framework allows for\nefficient structured inference using fully-connected random fields without any\nrestrictions on the potential functions that can be utilized. Several\nrealizations of the proposed framework using graph cuts are presented and\nevaluated, and experimental results demonstrate that the proposed framework can\nprovide competitive performance for the purpose of image segmentation when\ncompared to existing fully-connected and principled deep random field\nframeworks.",
    "State-of-the-art image segmentation algorithms generally consist of at least\ntwo successive and distinct computations: a boundary detection process that\nuses local image information to classify image locations as boundaries between\nobjects, followed by a pixel grouping step such as watershed or connected\ncomponents that clusters pixels into segments. Prior work has varied the\ncomplexity and approach employed in these two steps, including the\nincorporation of multi-layer neural networks to perform boundary prediction,\nand the use of global optimizations during pixel clustering. We propose a\nunified and end-to-end trainable machine learning approach, flood-filling\nnetworks, in which a recurrent 3d convolutional network directly produces\nindividual segments from a raw image. The proposed approach robustly segments\nimages with an unknown and variable number of objects as well as highly\nvariable object sizes. We demonstrate the approach on a challenging 3d image\nsegmentation task, connectomic reconstruction from volume electron microscopy\ndata, on which flood-filling neural networks substantially improve accuracy\nover other state-of-the-art methods. The proposed approach can replace complex\nmulti-step segmentation pipelines with a single neural network that is learned\nend-to-end.",
    "  In this announcement we consider the following problem. Let $n,m\\geq 1$,\n$U\\subset\\mathbb R^n$ open. In this paper we provide a sharp solution to the\nfollowing Whitney distortion extension problems: (a) Let $\\phi:U\\to \\mathbb\nR^n$ be a $C^m$ map. If $E\\subset U$ is compact (with some geometry) and the\nrestriction of $\\phi$ to $E$ is an almost isometry with small distortion, how\nto decide when there exists a $C^m(\\mathbb R^n)$ one-to-one and onto almost\nisometry $\\Phi:\\mathbb R^n\\to \\mathbb R^n$ with small distortion which agrees\nwith $\\phi$ in a neighborhood of $E$ and a Euclidean motion $A:\\mathbb R^n\\to\n\\mathbb R^n$ away from $E$. (b) Let $\\phi:U\\to \\mathbb R^n$ be $C^{\\infty}$\nmap. If $E\\subset U$ is compact (with some geometry) and the restriction of\n$\\phi$ to $E$ is an almost isometry with small distortion, how to decide when\nthere exists a $C^{\\infty}(\\mathbb R^n)$ one-to-one and onto almost isometry\n$\\Phi:\\mathbb R^n\\to \\mathbb R^n$ with small distortion which agrees with\n$\\phi$ in a neighborhood of $E$ and a Euclidean motion $A:\\mathbb R^n\\to\n\\mathbb R^n$ away from $E$. Our results complement those of [14,15,20] where\nthere, $E$ is a finite set. In this case, the problem above is also a problem\nof interpolation and alignment of data in $\\mathbb R^n$.\n",
    "Medical image analysis, especially segmenting a specific organ, has an\nimportant role in developing clinical decision support systems. In cardiac\nmagnetic resonance (MR) imaging, segmenting the left and right ventricles helps\nphysicians diagnose different heart abnormalities. There are challenges for\nthis task, including the intensity and shape similarity between left ventricle\nand other organs, inaccurate boundaries and presence of noise in most of the\nimages. In this paper we propose an automated method for segmenting the left\nventricle in cardiac MR images. We first automatically extract the region of\ninterest, and then employ it as an input of a fully convolutional network. We\ntrain the network accurately despite the small number of left ventricle pixels\nin comparison with the whole image. Thresholding on the output map of the fully\nconvolutional network and selection of regions based on their roundness are\nperformed in our proposed post-processing phase. The Dice score of our method\nreaches 87.24% by applying this algorithm on the York dataset of heart images.",
    "This review presents an in-depth study of the literature on segmentation\nmethods applied in dental imaging. Ten segmentation methods were studied and\ncategorized according to the type of the segmentation method (region-based,\nthreshold-based, cluster-based, boundary-based or watershed-based), type of\nX-ray images used (intra-oral or extra-oral) and characteristics of the dataset\nused to evaluate the methods in the state-of-the-art works. We found that the\nliterature has primarily focused on threshold-based segmentation methods (54%).\n80% of the reviewed papers have used intra-oral X-ray images in their\nexperiments, demonstrating preference to perform segmentation on images of\nalready isolated parts of the teeth, rather than using extra-oral X-rays, which\nshow tooth structure of the mouth and bones of the face. To fill a scientific\ngap in the field, a novel data set based on extra-oral X-ray images are\nproposed here. A statistical comparison of the results found with the 10 image\nsegmentation methods over our proposed data set comprised of 1,500 images is\nalso carried out, providing a more comprehensive source of performance\nassessment. Discussion on limitations of the methods conceived over the past\nyear as well as future perspectives on exploiting learning-based segmentation\nmethods to improve performance are also provided.",
    "  Following the recent theoretical predictions given in a paper [PRA 88, 013810\n(2013)], we reported on an experimental realization of an image cloning beyond\nusual diffraction through coherent population trapping (CPT) effect in a hot\nrubidium vapor. In our experiment, an alphabet image was transferred from a\ncoupling field to a probe field based on the CPT effect. Furthermore, we\ndemonstrated that the cloned probe field carrying the image transmitted without\nusual diffraction. To our best knowledge, there is no any such an experimental\nreport about images cloning beyond diffraction. We believe this mechanism based\non CPT definitely has important applications in image metrology, image\nprocessing and biological imaging.\n",
    "In this work, we revisit atrous convolution, a powerful tool to explicitly\nadjust filter's field-of-view as well as control the resolution of feature\nresponses computed by Deep Convolutional Neural Networks, in the application of\nsemantic image segmentation. To handle the problem of segmenting objects at\nmultiple scales, we design modules which employ atrous convolution in cascade\nor in parallel to capture multi-scale context by adopting multiple atrous\nrates. Furthermore, we propose to augment our previously proposed Atrous\nSpatial Pyramid Pooling module, which probes convolutional features at multiple\nscales, with image-level features encoding global context and further boost\nperformance. We also elaborate on implementation details and share our\nexperience on training our system. The proposed `DeepLabv3' system\nsignificantly improves over our previous DeepLab versions without DenseCRF\npost-processing and attains comparable performance with other state-of-art\nmodels on the PASCAL VOC 2012 semantic image segmentation benchmark.",
    "We present a generalized and scalable method, called Gen-LaneNet, to detect\n3D lanes from a single image. The method, inspired by the latest\nstate-of-the-art 3D-LaneNet, is a unified framework solving image encoding,\nspatial transform of features and 3D lane prediction in a single network.\nHowever, we propose unique designs for Gen-LaneNet in two folds. First, we\nintroduce a new geometry-guided lane anchor representation in a new coordinate\nframe and apply a specific geometric transformation to directly calculate real\n3D lane points from the network output. We demonstrate that aligning the lane\npoints with the underlying top-view features in the new coordinate frame is\ncritical towards a generalized method in handling unfamiliar scenes. Second, we\npresent a scalable two-stage framework that decouples the learning of image\nsegmentation subnetwork and geometry encoding subnetwork. Compared to\n3D-LaneNet, the proposed Gen-LaneNet drastically reduces the amount of 3D lane\nlabels required to achieve a robust solution in real-world application.\nMoreover, we release a new synthetic dataset and its construction strategy to\nencourage the development and evaluation of 3D lane detection methods. In\nexperiments, we conduct extensive ablation study to substantiate the proposed\nGen-LaneNet significantly outperforms 3D-LaneNet in average precision(AP) and\nF-score.",
    "Referring image segmentation aims to segment the objects referred by a\nnatural language expression. Previous methods usually focus on designing an\nimplicit and recurrent feature interaction mechanism to fuse the\nvisual-linguistic features to directly generate the final segmentation mask\nwithout explicitly modeling the localization information of the referent\ninstances. To tackle these problems, we view this task from another perspective\nby decoupling it into a \"Locate-Then-Segment\" (LTS) scheme. Given a language\nexpression, people generally first perform attention to the corresponding\ntarget image regions, then generate a fine segmentation mask about the object\nbased on its context. The LTS first extracts and fuses both visual and textual\nfeatures to get a cross-modal representation, then applies a cross-model\ninteraction on the visual-textual features to locate the referred object with\nposition prior, and finally generates the segmentation result with a\nlight-weight segmentation network. Our LTS is simple but surprisingly\neffective. On three popular benchmark datasets, the LTS outperforms all the\nprevious state-of-the-art methods by a large margin (e.g., +3.2% on RefCOCO+\nand +3.4% on RefCOCOg). In addition, our model is more interpretable with\nexplicitly locating the object, which is also proved by visualization\nexperiments. We believe this framework is promising to serve as a strong\nbaseline for referring image segmentation.",
    "Accurate medical image segmentation is essential for diagnosis, surgical\nplanning and many other applications. Convolutional Neural Networks (CNNs) have\nbecome the state-of-the-art automatic segmentation methods. However, fully\nautomatic results may still need to be refined to become accurate and robust\nenough for clinical use. We propose a deep learning-based interactive\nsegmentation method to improve the results obtained by an automatic CNN and to\nreduce user interactions during refinement for higher accuracy. We use one CNN\nto obtain an initial automatic segmentation, on which user interactions are\nadded to indicate mis-segmentations. Another CNN takes as input the user\ninteractions with the initial segmentation and gives a refined result. We\npropose to combine user interactions with CNNs through geodesic distance\ntransforms, and propose a resolution-preserving network that gives a better\ndense prediction. In addition, we integrate user interactions as hard\nconstraints into a back-propagatable Conditional Random Field. We validated the\nproposed framework in the context of 2D placenta segmentation from fetal MRI\nand 3D brain tumor segmentation from FLAIR images. Experimental results show\nour method achieves a large improvement from automatic CNNs, and obtains\ncomparable and even higher accuracy with fewer user interventions and less time\ncompared with traditional interactive methods.",
    "This paper reports a CPU-level real-time stereo matching method for surgical\nimages (10 Hz on 640 * 480 image with a single core of i5-9400). The proposed\nmethod is built on the fast ''dense inverse searching'' algorithm, which\nestimates the disparity of the stereo images. The overlapping image patches\n(arbitrary squared image segment) from the images at different scales are\naligned based on the photometric consistency presumption. We propose a Bayesian\nframework to evaluate the probability of the optimized patch disparity at\ndifferent scales. Moreover, we introduce a spatial Gaussian mixed probability\ndistribution to address the pixel-wise probability within the patch. In-vivo\nand synthetic experiments show that our method can handle ambiguities resulted\nfrom the textureless surfaces and the photometric inconsistency caused by the\nLambertian reflectance. Our Bayesian method correctly balances the probability\nof the patch for stereo images at different scales. Experiments indicate that\nthe estimated depth has higher accuracy and fewer outliers than the baseline\nmethods in the surgical scenario.",
    "  In this paper we analyze the Cardy-Lewellen equation in general diagonal\nmodel. We show that in these models it takes simple form due to some general\nproperties of conformal field theories, like pentagon equations and OPE\nassociativity. This implies, that the Cardy-Lewellen equation has simple form\nalso in non-rational diagonal models. We specialize our finding to the\nLiouville and Toda field theories. In particular we prove, that conjectured\nrecently defects in Toda field theory indeed satisfy the cluster equation. We\nalso derive the Cardy-Lewellen equation in all $sl(n)$ Toda field theories and\nprove that the forms of boundary states found recently in $sl(3)$ Toda field\ntheory hold in all $sl(n)$ theories as well.\n",
    "Over the past decades, state-of-the-art medical image segmentation has\nheavily rested on signal processing paradigms, most notably registration-based\nlabel propagation and pair-wise patch comparison, which are generally slow\ndespite a high segmentation accuracy. In recent years, deep learning has\nrevolutionalized computer vision with many practices outperforming prior art,\nin particular the convolutional neural network (CNN) studies on image\nclassification. Deep CNN has also started being applied to medical image\nsegmentation lately, but generally involves long training and demanding memory\nrequirements, achieving limited success. We propose a patch-based deep learning\nframework based on a revisit to the classic neural network model with\nsubstantial modernization, including the use of Rectified Linear Unit (ReLU)\nactivation, dropout layers, 2.5D tri-planar patch multi-pathway settings. In a\ntest application to hippocampus segmentation using 100 brain MR images from the\nADNI database, our approach significantly outperformed prior art in terms of\nboth segmentation accuracy and speed: scoring a median Dice score up to 90.98%\non a near real-time performance (<1s).",
    "Semantic segmentation of medical images is an essential first step in\ncomputer-aided diagnosis systems for many applications. However, given many\ndisparate imaging modalities and inherent variations in the patient data, it is\ndifficult to consistently achieve high accuracy using modern deep neural\nnetworks (DNNs). This has led researchers to propose interactive image\nsegmentation techniques where a medical expert can interactively correct the\noutput of a DNN to the desired accuracy. However, these techniques often need\nseparate training data with the associated human interactions, and do not\ngeneralize to various diseases, and types of medical images. In this paper, we\nsuggest a novel conditional inference technique for DNNs which takes the\nintervention by a medical expert as test time constraints and performs\ninference conditioned upon these constraints. Our technique is generic can be\nused for medical images from any modality. Unlike other methods, our approach\ncan correct multiple structures simultaneously and add structures missed at\ninitial segmentation. We report an improvement of 13.3, 12.5, 17.8, 10.2, and\n12.4 times in user annotation time than full human annotation for the nucleus,\nmultiple cells, liver and tumor, organ, and brain segmentation respectively. We\nreport a time saving of 2.8, 3.0, 1.9, 4.4, and 8.6 fold compared to other\ninteractive segmentation techniques. Our method can be useful to clinicians for\ndiagnosis and post-surgical follow-up with minimal intervention from the\nmedical expert. The source-code and the detailed results are available here\n[1].",
    "  We prove lower bounds for energy in the Gaussian core model, in which point\nparticles interact via a Gaussian potential. Under the potential function $t\n\\mapsto e^{-\\alpha t^2}$ with $0 < \\alpha < 4\\pi/e$, we show that no point\nconfiguration in $\\mathbf{R}^n$ of density $\\rho$ can have energy less than\n$(\\rho+o(1))(\\pi/\\alpha)^{n/2}$ as $n \\to \\infty$ with $\\alpha$ and $\\rho$\nfixed. This lower bound asymptotically matches the upper bound of $\\rho\n(\\pi/\\alpha)^{n/2}$ obtained as the expectation in the Siegel mean value\ntheorem, and it is attained by random lattices. The proof is based on the\nlinear programming bound, and it uses an interpolation construction analogous\nto those used for the Beurling-Selberg extremal problem in analytic number\ntheory. In the other direction, we prove that the upper bound of $\\rho\n(\\pi/\\alpha)^{n/2}$ is no longer asymptotically sharp when $\\alpha > \\pi e$. As\na consequence of our results, we obtain bounds in $\\mathbf{R}^n$ for the\nminimal energy under inverse power laws $t \\mapsto 1/t^{n+s}$ with $s>0$, and\nthese bounds are sharp to within a constant factor as $n \\to \\infty$ with $s$\nfixed.\n",
    "Active contours Model (ACM) has been extensively used in computer vision and\nimage processing. In recent studies, Convolutional Neural Networks (CNNs) have\nbeen combined with active contours replacing the user in the process of contour\nevolution and image segmentation to eliminate limitations associated with ACM's\ndependence on parameters of the energy functional and initialization. However,\nprior works did not aim for automatic initialization which is addressed here.\nIn addition to manual initialization, current methods are highly sensitive to\ninitial location and fail to delineate borders accurately. We propose a fully\nautomatic image segmentation method to address problems of manual\ninitialization, insufficient capture range, and poor convergence to boundaries,\nin addition to the problem of assignment of energy functional parameters. We\ntrain two CNNs, which predict active contour weighting parameters and generate\na ground truth mask to extract Distance Transform (DT) and an initialization\ncircle. Distance transform is used to form a vector field pointing from each\npixel of the image towards the closest point on the boundary, the size of which\nis equal to the Euclidean distance map. We evaluate our method on four publicly\navailable datasets including two building instance segmentation datasets,\nVaihingen and Bing huts, and two mammography image datasets, INBreast and\nDDSM-BCRP. Our approach outperforms latest research by 0.59 ans 2.39 percent in\nmean Intersection-over-Union (mIoU), 7.38 and 8.62 percent in Boundary F-score\n(BoundF) for Vaihingen and Bing huts datasets, respectively. Dice similarity\ncoefficient for the INBreast and DDSM-BCRP datasets is 94.23% and 90.89%,\nrespectively indicating our method is comparable to state-of-the-art\nframeworks.",
    "Semantic image segmentation is one of fastest growing areas in computer\nvision with a variety of applications. In many areas, such as robotics and\nautonomous vehicles, semantic image segmentation is crucial, since it provides\nthe necessary context for actions to be taken based on a scene understanding at\nthe pixel level. Moreover, the success of medical diagnosis and treatment\nrelies on the extremely accurate understanding of the data under consideration\nand semantic image segmentation is one of the important tools in many cases.\nRecent developments in deep learning have provided a host of tools to tackle\nthis problem efficiently and with increased accuracy. This work provides a\ncomprehensive analysis of state-of-the-art deep learning architectures in image\nsegmentation and, more importantly, an extensive list of techniques to achieve\nfast inference and computational efficiency. The origins of these techniques as\nwell as their strengths and trade-offs are discussed with an in-depth analysis\nof their impact in the area. The best-performing architectures are summarized\nwith a list of methods used to achieve these state-of-the-art results.",
    "Convolutional neural networks (CNNs) show outstanding performance in many\nimage processing problems, such as image recognition, object detection and\nimage segmentation. Semantic segmentation is a very challenging task that\nrequires recognizing, understanding what's in the image in pixel level. Though\nthe state of the art has been greatly improved by CNNs, there is no explicit\nconnections between prediction of neighbouring pixels. That is, spatial\nregularity of the segmented objects is still a problem for CNNs. In this paper,\nwe propose a method to add spatial regularization to the segmented objects. In\nour method, the spatial regularization such as total variation (TV) can be\neasily integrated into CNN network. It can help CNN find a better local optimum\nand make the segmentation results more robust to noise. We apply our proposed\nmethod to Unet and Segnet, which are well established CNNs for image\nsegmentation, and test them on WBC, CamVid and SUN-RGBD datasets, respectively.\nThe results show that the regularized networks not only could provide better\nsegmentation results with regularization effect than the original ones but also\nhave certain robustness to noise.",
    "Biofilm is a formation of microbial material on tooth substrata. Several\nmethods to quantify dental biofilm coverage have recently been reported in the\nliterature, but at best they provide a semi-automated approach to\nquantification with significant input from a human grader that comes with the\ngraders bias of what are foreground, background, biofilm, and tooth.\nAdditionally, human assessment indices limit the resolution of the\nquantification scale; most commercial scales use five levels of quantification\nfor biofilm coverage (0%, 25%, 50%, 75%, and 100%). On the other hand, current\nstate-of-the-art techniques in automatic plaque quantification fail to make\ntheir way into practical applications owing to their inability to incorporate\nhuman input to handle misclassifications. This paper proposes a new interactive\nmethod for biofilm quantification in Quantitative light-induced fluorescence\n(QLF) images of canine teeth that is independent of the perceptual bias of the\ngrader. The method partitions a QLF image into segments of uniform texture and\nintensity called superpixels; every superpixel is statistically modeled as a\nrealization of a single 2D Gaussian Markov random field (GMRF) whose parameters\nare estimated; the superpixel is then assigned to one of three classes\n(background, biofilm, tooth substratum) based on the training set of data. The\nquantification results show a high degree of consistency and precision. At the\nsame time, the proposed method gives pathologists full control to post-process\nthe automatic quantification by flipping misclassified superpixels to a\ndifferent state (background, tooth, biofilm) with a single click, providing\ngreater usability than simply marking the boundaries of biofilm and tooth as\ndone by current state-of-the-art methods.",
    "  In microscopic mechanical systems interactions between elastic structures are\noften mediated by the hydrodynamics of a solvent fluid. At microscopic scales\nthe elastic structures are also subject to thermal fluctuations. Stochastic\nnumerical methods are developed based on multigrid which allow for the\nefficient computation of both the hydrodynamic interactions in the presence of\nwalls and the thermal fluctuations. The presented stochastic multigrid approach\nprovides efficient real-space numerical methods for generating the required\nstochastic driving fields with long-range correlations consistent with\nstatistical mechanics. The presented approach also allows for the use of\nspatially adaptive meshes in resolving the hydrodynamic interactions. Numerical\nresults are presented which show the methods perform in practice with a\ncomputational complexity of O(N log(N)).\n",
    "  We present a new calculation of neutrino emissivities and energy spectra from\na massive star going through the advanced stages of nuclear burning\n(presupernova) in the months before becoming a supernova. The contributions\nfrom beta decay and electron capture, pair annihilation, plasmon decay, and the\nphotoneutrino process are modeled in detail, using updated tabulated nuclear\nrates. We also use realistic conditions of temperature, density, electron\nfraction and nuclear isotopic composition of the star from the state of the art\nstellar evolution code MESA. Results are presented for a set of progenitor\nstars with mass between 15 $M_\\odot$ and 30 $M_\\odot$. It is found that beta\nprocesses contribute substantially to the neutrino emissivity above realistic\ndetection thresholds of few MeV, at selected positions and times in the\nevolution of the star.\n",
    "Convolutional neural networks (CNNs) for biomedical image analysis are often\nof very large size, resulting in high memory requirement and high latency of\noperations. Searching for an acceptable compressed representation of the base\nCNN for a specific imaging application typically involves a series of\ntime-consuming training/validation experiments to achieve a good compromise\nbetween network size and accuracy. To address this challenge, we propose\nCC-Net, a new image complexity-guided CNN compression scheme for biomedical\nimage segmentation. Given a CNN model, CC-Net predicts the final accuracy of\nnetworks of different sizes based on the average image complexity computed from\nthe training data. It then selects a multiplicative factor for producing a\ndesired network with acceptable network accuracy and size. Experiments show\nthat CC-Net is effective for generating compressed segmentation networks,\nretaining up to 95% of the base network segmentation accuracy and utilizing\nonly 0.1% of trainable parameters of the full-sized networks in the best case.",
    "In computer vision, image segmentation is always selected as a major research\ntopic by researchers. Due to its vital rule in image processing, there always\narises the need of a better image segmentation method. Clustering is an\nunsupervised study with its application in almost every field of science and\nengineering. Many researchers used clustering in image segmentation process.\nBut still there requires improvement of such approaches. In this paper, a novel\napproach for clustering based image segmentation is proposed. Here, we give\nimportance on color space and choose lab for this task. The famous hard\nclustering algorithm K-means is used, but as its performance is dependent on\nchoosing a proper distance measure, so, we go for cosine distance measure. Then\nthe segmented image is filtered with sobel filter. The filtered image is\nanalyzed with marker watershed algorithm to have the final segmented result of\nour original image. The MSE and PSNR values are evaluated to observe the\nperformance.",
    "Class imbalance has emerged as one of the major challenges for medical image\nsegmentation. The model cascade (MC) strategy significantly alleviates the\nclass imbalance issue via running a set of individual deep models for\ncoarse-to-fine segmentation. Despite its outstanding performance, however, this\nmethod leads to undesired system complexity and also ignores the correlation\namong the models. To handle these flaws, we propose a light-weight deep model,\ni.e., the One-pass Multi-task Network (OM-Net) to solve class imbalance better\nthan MC does, while requiring only one-pass computation. First, OM-Net\nintegrates the separate segmentation tasks into one deep model, which consists\nof shared parameters to learn joint features, as well as task-specific\nparameters to learn discriminative features. Second, to more effectively\noptimize OM-Net, we take advantage of the correlation among tasks to design\nboth an online training data transfer strategy and a curriculum learning-based\ntraining strategy. Third, we further propose sharing prediction results between\ntasks and design a cross-task guided attention (CGA) module which can\nadaptively recalibrate channel-wise feature responses based on the\ncategory-specific statistics. Finally, a simple yet effective post-processing\nmethod is introduced to refine the segmentation results. Extensive experiments\nare conducted to demonstrate the effectiveness of the proposed techniques. Most\nimpressively, we achieve state-of-the-art performance on the BraTS 2015 testing\nset and BraTS 2017 online validation set. Using these proposed approaches, we\nalso won joint third place in the BraTS 2018 challenge among 64 participating\nteams. The code is publicly available at\nhttps://github.com/chenhong-zhou/OM-Net.",
    "Deep convolutional neural networks have driven substantial advancements in\nthe automatic understanding of images. Requiring a large collection of images\nand their associated annotations is one of the main bottlenecks limiting the\nadoption of deep networks. In the task of medical image segmentation, requiring\npixel-level semantic annotations performed by human experts exacerbate this\ndifficulty. This paper proposes a new framework to train a fully convolutional\nsegmentation network from a large set of cheap unreliable annotations and a\nsmall set of expert-level clean annotations. We propose a spatially adaptive\nreweighting approach to treat clean and noisy pixel-level annotations\ncommensurately in the loss function. We deploy a meta-learning approach to\nassign higher importance to pixels whose loss gradient direction is closer to\nthose of clean data. Our experiments on training the network using segmentation\nground truth corrupted with different levels of annotation noise show how\nspatial reweighting improves the robustness of deep networks to noisy\nannotations.",
    "Machine learning methods have achieved good performance and been widely\napplied in various real-world applications. They can learn the model adaptively\nand be better fit for special requirements of different tasks. Generally, a\ngood machine learning system is composed of plentiful training data, a good\nmodel training process, and an accurate inference. Many factors can affect the\nperformance of the machine learning process, among which the diversity of the\nmachine learning process is an important one. The diversity can help each\nprocedure to guarantee a total good machine learning: diversity of the training\ndata ensures that the training data can provide more discriminative information\nfor the model, diversity of the learned model (diversity in parameters of each\nmodel or diversity among different base models) makes each parameter/model\ncapture unique or complement information and the diversity in inference can\nprovide multiple choices each of which corresponds to a specific plausible\nlocal optimal result. Even though the diversity plays an important role in\nmachine learning process, there is no systematical analysis of the\ndiversification in machine learning system. In this paper, we systematically\nsummarize the methods to make data diversification, model diversification, and\ninference diversification in the machine learning process, respectively. In\naddition, the typical applications where the diversity technology improved the\nmachine learning performance have been surveyed, including the remote sensing\nimaging tasks, machine translation, camera relocalization, image segmentation,\nobject detection, topic modeling, and others. Finally, we discuss some\nchallenges of the diversity technology in machine learning and point out some\ndirections in future work.",
    "Image segmentation is the process of partitioning a image into different\nregions or groups based on some characteristics like color, texture, motion or\nshape etc. Active contours is a popular variational method for object\nsegmentation in images, in which the user initializes a contour which evolves\nin order to optimize an objective function designed such that the desired\nobject boundary is the optimal solution. Recently, imaging modalities that\nproduce Manifold valued images have come up, for example, DT-MRI images, vector\nfields. The traditional active contour model does not work on such images. In\nthis paper, we generalize the active contour model to work on Manifold valued\nimages. As expected, our algorithm detects regions with similar Manifold values\nin the image. Our algorithm also produces expected results on usual gray-scale\nimages, since these are nothing but trivial examples of Manifold valued images.\nAs another application of our general active contour model, we perform texture\nsegmentation on gray-scale images by first creating an appropriate Manifold\nvalued image. We demonstrate segmentation results for manifold valued images\nand texture images.",
    "Brain extraction is a fundamental step for most brain imaging studies. In\nthis paper, we investigate the problem of skull stripping and propose\ncomplementary segmentation networks (CompNets) to accurately extract the brain\nfrom T1-weighted MRI scans, for both normal and pathological brain images. The\nproposed networks are designed in the framework of encoder-decoder networks and\nhave two pathways to learn features from both the brain tissue and its\ncomplementary part located outside of the brain. The complementary pathway\nextracts the features in the non-brain region and leads to a robust solution to\nbrain extraction from MRIs with pathologies, which do not exist in our training\ndataset. We demonstrate the effectiveness of our networks by evaluating them on\nthe OASIS dataset, resulting in the state of the art performance under the\ntwo-fold cross-validation setting. Moreover, the robustness of our networks is\nverified by testing on images with introduced pathologies and by showing its\ninvariance to unseen brain pathologies. In addition, our complementary network\ndesign is general and can be extended to address other image segmentation\nproblems with better generalization.",
    "We introduce the concept of derivate-based component-trees for images with an\narbitrary number of channels. The approach is a natural extension of the\nclassical component-tree devoted to gray-scale images. The similar structure\nenables the translation of many gray-level image processing techniques based on\nthe component-tree to hyperspectral and color images. As an example\napplication, we present an image segmentation approach that extracts Maximally\nStable Homogeneous Regions (MSHR). The approach very similar to MSER but can be\napplied to images with an arbitrary number of channels. As opposed to MSER, our\napproach implicitly segments regions with are both lighter and darker than\ntheir background for gray-scale images and can be used in OCR applications\nwhere MSER will fail. We introduce a local flooding-based immersion for the\nderivate-based component-tree construction which is linear in the number of\npixels. In the experiments, we show that the runtime scales favorably with an\nincreasing number of channels and may improve algorithms which build on MSER.",
    "  A distributed adaptive algorithm is proposed to solve a node-specific\nparameter estimation problem where nodes are interested in estimating\nparameters of local interest, parameters of common interest to a subset of\nnodes and parameters of global interest to the whole network. To address the\ndifferent node-specific parameter estimation problems, this novel algorithm\nrelies on a diffusion-based implementation of different Least Mean Squares\n(LMS) algorithms, each associated with the estimation of a specific set of\nlocal, common or global parameters. Coupled with the estimation of the\ndifferent sets of parameters, the implementation of each LMS algorithm is only\nundertaken by the nodes of the network interested in a specific set of local,\ncommon or global parameters. The study of convergence in the mean sense reveals\nthat the proposed algorithm is asymptotically unbiased. Moreover, a\nspatial-temporal energy conservation relation is provided to evaluate the\nsteady-state performance at each node in the mean-square sense. Finally, the\ntheoretical results and the effectiveness of the proposed technique are\nvalidated through computer simulations in the context of cooperative spectrum\nsensing in Cognitive Radio networks.\n",
    "  The $A_\\infty$ T-system, also called the octahedron recurrence, is a\ndynamical recurrence relation. It can be realized as mutation in a\ncoefficient-free cluster algebra (Kedem 2008, Di Francesco and Kedem 2009). We\ndefine T-systems with principal coefficients from cluster algebra aspect, and\ngive combinatorial solutions with respect to any valid initial condition in\nterms of partition functions of perfect matchings, non-intersecting paths and\nnetworks. This also provides a solution to other systems with various choices\nof coefficients on T-systems including Speyer's octahedron recurrence (Speyer\n2007), generalized lambda-determinants (Di Francesco 2013) and (higher)\npentagram maps (Schwartz 1992, Ovsienko et al. 2010, Glick 2011, Gekhtman et\nal. 2014).\n",
    "  We characterize Leavitt path algebras which are Rickart, Baer, and Baer\n$*$-rings in terms of the properties of the underlying graph. In order to treat\nnon-unital Leavitt path algebras as well, we generalize these\nannihilator-related properties to locally unital rings and provide a more\ngeneral characterizations of Leavitt path algebras which are locally Rickart,\nlocally Baer, and locally Baer $*$-rings. Leavitt path algebras are also graded\nrings and we formulate the graded versions of these annihilator-related\nproperties and characterize Leavitt path algebras having those properties as\nwell.\n  Our characterizations provide a quick way to generate a wide variety of\nexamples of rings. For example, creating a Baer and not a Baer $*$-ring, a\nRickart $*$-ring which is not Baer, or a Baer and not a Rickart $*$-ring, is\nstraightforward using the graph-theoretic properties from our results. In\naddition, our characterizations showcase more properties which distinguish\nbehavior of Leavitt path algebras from their $C^*$-algebra counterparts. For\nexample, while a graph $C^*$-algebra is Baer (and a Baer $*$-ring) if and only\nif the underlying graph is finite and acyclic, a Leavitt path algebra is Baer\nif and only if the graph is finite and no cycle has an exit, and it is a Baer\n$*$-ring if and only if the graph is a finite disjoint union of graphs which\nare finite and acyclic or loops.\n",
    "We present Convolutional Oriented Boundaries (COB), which produces multiscale\noriented contours and region hierarchies starting from generic image\nclassification Convolutional Neural Networks (CNNs). COB is computationally\nefficient, because it requires a single CNN forward pass for multi-scale\ncontour detection and it uses a novel sparse boundary representation for\nhierarchical segmentation; it gives a significant leap in performance over the\nstate-of-the-art, and it generalizes very well to unseen categories and\ndatasets. Particularly, we show that learning to estimate not only contour\nstrength but also orientation provides more accurate results. We perform\nextensive experiments for low-level applications on BSDS, PASCAL Context,\nPASCAL Segmentation, and NYUD to evaluate boundary detection performance,\nshowing that COB provides state-of-the-art contours and region hierarchies in\nall datasets. We also evaluate COB on high-level tasks when coupled with\nmultiple pipelines for object proposals, semantic contours, semantic\nsegmentation, and object detection on MS-COCO, SBD, and PASCAL; showing that\nCOB also improves the results for all tasks.",
    "Semi-supervised learning has recently been attracting attention as an\nalternative to fully supervised models that require large pools of labeled\ndata. Moreover, optimizing a model for multiple tasks can provide better\ngeneralizability than single-task learning. Leveraging self-supervision and\nadversarial training, we propose a novel general purpose semi-supervised,\nmultiple-task model---namely, self-supervised, semi-supervised, multitask\nlearning (S$^4$MTL)---for accomplishing two important tasks in medical imaging,\nsegmentation and diagnostic classification. Experimental results on chest and\nspine X-ray datasets suggest that our S$^4$MTL model significantly outperforms\nsemi-supervised single task, semi/fully-supervised multitask, and\nfully-supervised single task models, even with a 50\\% reduction of class and\nsegmentation labels. We hypothesize that our proposed model can be effective in\ntackling limited annotation problems for joint training, not only in medical\nimaging domains, but also for general-purpose vision tasks.",
    "While making a tremendous impact in various fields, deep neural networks\nusually require large amounts of labeled data for training which are expensive\nto collect in many applications, especially in the medical domain. Unlabeled\ndata, on the other hand, is much more abundant. Semi-supervised learning\ntechniques, such as co-training, could provide a powerful tool to leverage\nunlabeled data. In this paper, we propose a novel framework, uncertainty-aware\nmulti-view co-training (UMCT), to address semi-supervised learning on 3D data,\nsuch as volumetric data from medical imaging. In our work, co-training is\nachieved by exploiting multi-viewpoint consistency of 3D data. We generate\ndifferent views by rotating or permuting the 3D data and utilize asymmetrical\n3D kernels to encourage diversified features in different sub-networks. In\naddition, we propose an uncertainty-weighted label fusion mechanism to estimate\nthe reliability of each view's prediction with Bayesian deep learning. As one\nview requires the supervision from other views in co-training, our\nself-adaptive approach computes a confidence score for the prediction of each\nunlabeled sample in order to assign a reliable pseudo label. Thus, our approach\ncan take advantage of unlabeled data during training. We show the effectiveness\nof our proposed semi-supervised method on several public datasets from medical\nimage segmentation tasks (NIH pancreas & LiTS liver tumor dataset). Meanwhile,\na fully-supervised method based on our approach achieved state-of-the-art\nperformances on both the LiTS liver tumor segmentation and the Medical\nSegmentation Decathlon (MSD) challenge, demonstrating the robustness and value\nof our framework, even when fully supervised training is feasible.",
    "We introduce a novel Deep Learning framework, which quantitatively estimates\nimage segmentation quality without the need for human inspection or labeling.\nWe refer to this method as a Quality Assurance Network -- QANet. Specifically,\ngiven an image and a `proposed' corresponding segmentation, obtained by any\nmethod including manual annotation, the QANet solves a regression problem in\norder to estimate a predefined quality measure with respect to the unknown\nground truth. The QANet is by no means yet another segmentation method.\nInstead, it performs a multi-level, multi-feature comparison of an\nimage-segmentation pair based on a unique network architecture, called the\nRibCage.\n  To demonstrate the strength of the QANet, we addressed the evaluation of\ninstance segmentation using two different datasets from different domains,\nnamely, high throughput live cell microscopy images from the Cell Segmentation\nBenchmark and natural images of plants from the Leaf Segmentation Challenge.\nWhile synthesized segmentations were used to train the QANet, it was tested on\nsegmentations obtained by publicly available methods that participated in the\ndifferent challenges. We show that the QANet accurately estimates the scores of\nthe evaluated segmentations with respect to the hidden ground truth, as\npublished by the challenges' organizers.\n  The code is available at: TBD.",
    "Person re-identification is becoming a hot research for developing both\nmachine learning algorithms and video surveillance applications. The task of\nperson re-identification is to determine which person in a gallery has the same\nidentity to a probe image. This task basically assumes that the subject of the\nprobe image belongs to the gallery, that is, the gallery contains this person.\nHowever, in practical applications such as searching a suspect in a video, this\nassumption is usually not true. In this paper, we consider the open-set person\nre-identification problem, which includes two sub-tasks, detection and\nidentification. The detection sub-task is to determine the presence of the\nprobe subject in the gallery, and the identification sub-task is to determine\nwhich person in the gallery has the same identity as the accepted probe. We\npresent a database collected from a video surveillance setting of 6 cameras,\nwith 200 persons and 7,413 images segmented. Based on this database, we develop\na benchmark protocol for evaluating the performance under the open-set person\nre-identification scenario. Several popular metric learning algorithms for\nperson re-identification have been evaluated as baselines. From the baseline\nperformance, we observe that the open-set person re-identification problem is\nstill largely unresolved, thus further attention and effort is needed.",
    "Mining and learning the shape variability of underlying population has\nbenefited the applications including parametric shape modeling, 3D animation,\nand image segmentation. The current statistical shape modeling method works\nwell on learning unstructured shape variations without obvious pose changes\n(relative rotations of the body parts). Studying the pose variations within a\nshape population involves segmenting the shapes into different articulated\nparts and learning the transformations of the segmented parts. This paper\nformulates the pose learning problem as mixtures of factor analyzers. The\nsegmentation is obtained by components posterior probabilities and the\nrotations in pose variations are learned by the factor loading matrices. To\nguarantee that the factor loading matrices are composed by rotation matrices,\nconstraints are imposed and the corresponding closed form optimal solution is\nderived. Based on the proposed method, the pose variations are automatically\nlearned from the given shape populations. The method is applied in motion\nanimation where new poses are generated by interpolating the existing poses in\nthe training set. The obtained results are smooth and realistic.",
    "  Timed systems, such as timed automata, are usually analyzed using their\noperational semantics on timed words. The classical region abstraction for\ntimed automata reduces them to (untimed) finite state automata with the same\ntime-abstract properties, such as state reachability. We propose a new\ntechnique to analyze such timed systems using finite tree automata instead of\nfinite word automata. The main idea is to consider timed behaviors as graphs\nwith matching edges capturing timing constraints. When a family of graphs has\nbounded tree-width, they can be interpreted in trees and MSO-definable\nproperties of such graphs can be checked using tree automata. The technique is\nquite general and applies to many timed systems. In this paper, as an example,\nwe develop the technique on timed pushdown systems, which have recently\nreceived considerable attention. Further, we also demonstrate how we can use it\non timed automata and timed multi-stack pushdown systems (with boundedness\nrestrictions).\n",
    "  The Aw-Rascle-Zhang (ARZ) model can be interpreted as a generalization of the\nLighthill-Whitham-Richards (LWR) model, possessing a family of fundamental\ndiagram curves, each of which represents a class of drivers with a different\nempty road velocity. A weakness of this approach is that different drivers\npossess vastly different densities at which traffic flow stagnates. This\ndrawback can be overcome by modifying the pressure relation in the ARZ model,\nleading to the generalized Aw-Rascle-Zhang (GARZ) model. We present an approach\nto determine the parameter functions of the GARZ model from fundamental diagram\nmeasurement data. The predictive accuracy of the resulting data-fitted GARZ\nmodel is compared to other traffic models by means of a three-detector test\nsetup, employing two types of data: vehicle trajectory data, and sensor data.\nThis work also considers the extension of the ARZ and the GARZ models to models\nwith a relaxation term, and conducts an investigation of the optimal relaxation\ntime.\n",
    "  In this paper, we have studied $F(R,T)$ gravity as an arbitrary function of\ncurvature and torsion scalars in Friedmann--Lema\\^{\\i}tre--Robertson--Walker\n(FLRW) background. Then, we have considered interacting model between $F(R,T)$\ngravity and modified Chaplygin gas. The novelty of this model is that the\nUniverse includes both cases curvature and torsion, and one dominated by a\nChaplygin gas. In order to calculate cosmological solutions, we obtained\nFriedmann equations and also equation of state (EoS) parameter of dark energy.\nBy employing interacting model we considered the total energy density and the\ntotal pressure of Universe as the combination of components of dark energy and\nChaplygin gas. Subsequently, we reconstructed the model by an origin of a\nscalar field entitled quintessence model with a field potential. The field\npotential has been calculated in terms of free parameters of $F(R,T)$ gravity\nand modified Chaplygin gas. In what follows, we used a parametrization, and the\ncosmological parameters have been written in terms of redshift $z$. Next, we\nplotted cosmological parameters with respect to three variable of cosmic time,\nredshift $z$ and $e$-folding number $N=ln(a)$, and the figures showed us an\naccelerated expansion of Universe. Also, we have described the scenario in\nthree status early time, late time and future time by $e$-folding number.\nFinally, the stability of scenario has been investigated by a useful function\nnamed sound speed, and the graph of sound speed versus $e$-folding number has\nbeen showed us that there is the stability in late time.\n",
    "  The aim of this paper to draw attention to several aspects of the algebraic\ndependence in algebras. The article starts with discussions of the algebraic\ndependence problem in commutative algebras. Then the Burchnall-Chaundy\nconstruction for proving algebraic dependence and obtaining the corresponding\nalgebraic curves for commuting differential operators in the Heisenberg algebra\nis reviewed. Next some old and new results on algebraic dependence of commuting\nq-difference operators and elements in q-deformed Heisenberg algebras are\nreviewed. The main ideas and essence of two proofs of this are reviewed and\ncompared. One is the algorithmic dimension growth existence proof. The other is\nthe recent proof extending the Burchnall-Chaundy approach from differential\noperators and the Heisenberg algebra to the q-deformed Heisenberg algebra,\nshowing that the Burchnall-Chaundy eliminant construction indeed provides\nannihilating curves for commuting elements in the q-deformed Heisenberg\nalgebras for q not a root of unity.\n",
    "Histopathological prognostication of neoplasia including most tumor grading\nsystems are based upon a number of criteria. Probably the most important is the\nnumber of mitotic figures which are most commonly determined as the mitotic\ncount (MC), i.e. number of mitotic figures within 10 consecutive high power\nfields. Often the area with the highest mitotic activity is to be selected for\nthe MC. However, since mitotic activity is not known in advance, an arbitrary\nchoice of this region is considered one important cause for high variability in\nthe prognostication and grading.\n  In this work, we present an algorithmic approach that first calculates a\nmitotic cell map based upon a deep convolutional network. This map is in a\nsecond step used to construct a mitotic activity estimate. Lastly, we select\nthe image segment representing the size of ten high power fields with the\noverall highest mitotic activity as a region proposal for an expert MC\ndetermination. We evaluate the approach using a dataset of 32 completely\nannotated whole slide images, where 22 were used for training of the network\nand 10 for test. We find a correlation of r=0.936 in mitotic count estimate.",
    "State-of-the-art semantic segmentation approaches increase the receptive\nfield of their models by using either a downsampling path composed of\npoolings/strided convolutions or successive dilated convolutions. However, it\nis not clear which operation leads to best results. In this paper, we\nsystematically study the differences introduced by distinct receptive field\nenlargement methods and their impact on the performance of a novel\narchitecture, called Fully Convolutional DenseResNet (FC-DRN). FC-DRN has a\ndensely connected backbone composed of residual networks. Following standard\nimage segmentation architectures, receptive field enlargement operations that\nchange the representation level are interleaved among residual networks. This\nallows the model to exploit the benefits of both residual and dense\nconnectivity patterns, namely: gradient flow, iterative refinement of\nrepresentations, multi-scale feature combination and deep supervision. In order\nto highlight the potential of our model, we test it on the challenging CamVid\nurban scene understanding benchmark and make the following observations: 1)\ndownsampling operations outperform dilations when the model is trained from\nscratch, 2) dilations are useful during the finetuning step of the model, 3)\ncoarser representations require less refinement steps, and 4) ResNets (by model\nconstruction) are good regularizers, since they can reduce the model capacity\nwhen needed. Finally, we compare our architecture to alternative methods and\nreport state-of-the-art result on the Camvid dataset, with at least twice fewer\nparameters.",
    "  A Software-defined Constrained Optimal Routing (SCOR) platform is introduced\nas a Northbound interface in SDN architecture. It is based on constraint\nprogramming techniques and is implemented in MiniZinc modelling language. Using\nconstraint programming techniques in this Northbound interface has created an\nefficient tool for implementing complex Quality of Service routing applications\nin a few lines of code. The code includes only the problem statement and the\nsolution is found by a general solver program. A routing framework is\nintroduced based on SDN's architecture model which uses SCOR as its Northbound\ninterface and an upper layer of applications implemented in SCOR. Performance\nof a few implemented routing applications are evaluated in different network\ntopologies, network sizes and various number of concurrent flows.\n",
    "  In this paper, we consider the well-known modal logics $\\mathbf{K}$,\n$\\mathbf{T}$, $\\mathbf{K4}$, and $\\mathbf{S4}$, and we study some of their\nsub-propositional fragments, namely the classical Horn fragment, the Krom\nfragment, the so-called core fragment, defined as the intersection of the Horn\nand the Krom fragments, plus their sub-fragments obtained by limiting the use\nof boxes and diamonds in clauses. We focus, first, on the relative expressive\npower of such languages: we introduce a suitable measure of expressive power,\nand we obtain a complex hierarchy that encompasses all fragments of the\nconsidered logics. Then, after observing the low expressive power, in\nparticular, of the Horn fragments without diamonds, we study the computational\ncomplexity of their satisfiability problem, proving that, in general, it\nbecomes polynomial.\n",
    "  Recently developed information communication technologies, particularly the\nInternet, have affected how we, both as individuals and as a society, create,\nstore, and recall information. Internet also provides us with a great\nopportunity to study memory using transactional large scale data, in a\nquantitative framework similar to the practice in statistical physics. In this\nproject, we make use of online data by analysing viewership statistics of\nWikipedia articles on aircraft crashes. We study the relation between recent\nevents and past events and particularly focus on understanding memory\ntriggering patterns. We devise a quantitative model that explains the flow of\nviewership from a current event to past events based on similarity in time,\ngeography, topic, and the hyperlink structure of Wikipedia articles. We show\nthat on average the secondary flow of attention to past events generated by\nsuch remembering processes is larger than the primary attention flow to the\ncurrent event. We are the first to report these cascading effects.\n",
    "Single Image Super Resolution (SISR) techniques based on Super Resolution\nConvolutional Neural Networks (SRCNN) are applied to micro-computed tomography\n({\\mu}CT) images of sandstone and carbonate rocks. Digital rock imaging is\nlimited by the capability of the scanning device resulting in trade-offs\nbetween resolution and field of view, and super resolution methods tested in\nthis study aim to compensate for these limits. SRCNN models SR-Resnet, Enhanced\nDeep SR (EDSR), and Wide-Activation Deep SR (WDSR) are used on the Digital Rock\nSuper Resolution 1 (DRSRD1) Dataset of 4x downsampled images, comprising of\n2000 high resolution (800x800) raw micro-CT images of Bentheimer sandstone and\nEstaillades carbonate. The trained models are applied to the validation and\ntest data within the dataset and show a 3-5 dB rise in image quality compared\nto bicubic interpolation, with all tested models performing within a 0.1 dB\nrange. Difference maps indicate that edge sharpness is completely recovered in\nimages within the scope of the trained model, with only high frequency noise\nrelated detail loss. We find that aside from generation of high-resolution\nimages, a beneficial side effect of super resolution methods applied to\nsynthetically downgraded images is the removal of image noise while recovering\nedgewise sharpness which is beneficial for the segmentation process. The model\nis also tested against real low-resolution images of Bentheimer rock with image\naugmentation to account for natural noise and blur. The SRCNN method is shown\nto act as a preconditioner for image segmentation under these circumstances\nwhich naturally leads to further future development and training of models that\nsegment an image directly. Image restoration by SRCNN on the rock images is of\nsignificantly higher quality than traditional methods and suggests SRCNN\nmethods are a viable processing step in a digital rock workflow.",
    "Interactive image segmentation is a topic of many studies in image\nprocessing. In a conventional approach, a user marks some pixels of the\nobject(s) of interest and background, and an algorithm propagates these labels\nto the rest of the image. This paper presents a new graph-based method for\ninteractive segmentation with two stages. In the first stage, nodes\nrepresenting pixels are connected to their $k$-nearest neighbors to build a\ncomplex network with the small-world property to propagate the labels quickly.\nIn the second stage, a regular network in a grid format is used to refine the\nsegmentation on the object borders. Despite its simplicity, the proposed method\ncan perform the task with high accuracy. Computer simulations are performed\nusing some real-world images to show its effectiveness in both two-classes and\nmulti-classes problems. It is also applied to all the images from the Microsoft\nGrabCut dataset for comparison, and the segmentation accuracy is comparable to\nthose achieved by some state-of-the-art methods, while it is faster than them.\nIn particular, it outperforms some recent approaches when the user input is\ncomposed only by a few \"scribbles\" draw over the objects. Its computational\ncomplexity is only linear on the image size at the best-case scenario and\nlinearithmic in the worst case.",
    "The development of high quality medical image segmentation algorithms depends\non the availability of large datasets with pixel-level labels. The challenges\nof collecting such datasets, especially in case of 3D volumes, motivate to\ndevelop approaches that can learn from other types of labels that are cheap to\nobtain, e.g. bounding boxes. We focus on 3D medical images with their\ncorresponding 3D bounding boxes which are considered as series of per-slice\nnon-tight 2D bounding boxes. While current weakly-supervised approaches that\nuse 2D bounding boxes as weak labels can be applied to medical image\nsegmentation, we show that their success is limited in cases when the\nassumption about the tightness of the bounding boxes breaks. We propose a new\nbounding box correction framework which is trained on a small set of\npixel-level annotations to improve the tightness of a larger set of non-tight\nbounding box annotations. The effectiveness of our solution is demonstrated by\nevaluating a known weakly-supervised segmentation approach with and without the\nproposed bounding box correction algorithm. When the tightness is improved by\nour solution, the results of the weakly-supervised segmentation become much\ncloser to those of the fully-supervised one.",
    "This paper presents a novel unsupervised segmentation method for 3D medical\nimages. Convolutional neural networks (CNNs) have brought significant advances\nin image segmentation. However, most of the recent methods rely on supervised\nlearning, which requires large amounts of manually annotated data. Thus, it is\nchallenging for these methods to cope with the growing amount of medical\nimages. This paper proposes a unified approach to unsupervised deep\nrepresentation learning and clustering for segmentation. Our proposed method\nconsists of two phases. In the first phase, we learn deep feature\nrepresentations of training patches from a target image using joint\nunsupervised learning (JULE) that alternately clusters representations\ngenerated by a CNN and updates the CNN parameters using cluster labels as\nsupervisory signals. We extend JULE to 3D medical images by utilizing 3D\nconvolutions throughout the CNN architecture. In the second phase, we apply\nk-means to the deep representations from the trained CNN and then project\ncluster labels to the target image in order to obtain the fully segmented\nimage. We evaluated our methods on three images of lung cancer specimens\nscanned with micro-computed tomography (micro-CT). The automatic segmentation\nof pathological regions in micro-CT could further contribute to the\npathological examination process. Hence, we aim to automatically divide each\nimage into the regions of invasive carcinoma, noninvasive carcinoma, and normal\ntissue. Our experiments show the potential abilities of unsupervised deep\nrepresentation learning for medical image segmentation.",
    "  We study the impact of electrode band structure on transport through\nsingle-molecule junctions by measuring the conductance of pyridine-based\nmolecules using Ag and Au electrodes. Our experiments are carried out using the\nscanning tunneling microscope based break-junction technique and are supported\nby density functional theory based calculations. We find from both experiments\nand calculations that the coupling of the dominant transport orbital to the\nmetal is stronger for Au-based junctions when compared with Ag-based junctions.\nWe attribute this difference to relativistic effects, which results in an\nenhanced density of d-states at the Fermi energy for Au compared with Ag. We\nfurther show that the alignment of the conducting orbital relative to the Fermi\nlevel does not follow the work function difference between two metals and is\ndifferent for conjugated and saturated systems. We thus demonstrate that the\ndetails of the molecular level alignment and electronic coupling in\nmetal-organic interfaces do not follow simple rules, but are rather the\nconsequence of subtle local interactions.\n",
    "  Many practical sensing applications involve multiple sensors simultaneously\nacquiring measurements of a single object. Conversely, most existing sparse\nrecovery guarantees in compressed sensing concern only single-sensor\nacquisition scenarios. In this paper, we address the optimal recovery of\ncompressible signals from multi-sensor measurements using compressed sensing\ntechniques, thereby confirming the benefits of multi- over single-sensor\nenvironments. Throughout the paper, we consider a broad class of sensing\nmatrices, and two fundamentally different sampling scenarios (distinct and\nidentical respectively), both of which are relevant to applications. For the\ncase of diagonal sensor profile matrices (which characterize environmental\nconditions between a source and the sensors), this paper presents two key\nimprovements over existing results. First, a simpler optimal recovery guarantee\nfor distinct sampling, and second, an improved recovery guarantee for identical\nsampling, based on the so-called sparsity in levels signal model.\n",
    "This paper proposes the first, known to us, open source presentation attack\ndetection (PAD) solution to distinguish between authentic iris images (possibly\nwearing clear contact lenses) and irises with textured contact lenses. This\nsoftware can serve as a baseline in various PAD evaluations, and also as an\nopen-source platform with an up-to-date reference method for iris PAD. The\nsoftware is written in C++ and Python and uses only open source resources, such\nas OpenCV. This method does not incorporate iris image segmentation, which may\nbe problematic for unknown fake samples. Instead, it makes a best guess to\nlocalize the rough position of the iris. The PAD-related features are extracted\nwith the Binary Statistical Image Features (BSIF), which are classified by an\nensemble of classifiers incorporating support vector machine, random forest and\nmultilayer perceptron. The models attached to the current software have been\ntrained with the NDCLD'15 database and evaluated on the independent datasets\nincluded in the LivDet-Iris 2017 competition. The software implements the\nfunctionality of retraining the classifiers with any database of authentic and\nattack images. The accuracy of the current version offered with this paper\nexceeds 99% when tested on subject-disjoint subsets of NDCLD'15, and oscillates\naround 85% when tested on the LivDet-Iris 2017 benchmarks, which is on par with\nthe results obtained by the LivDet-Iris 2017 winner.",
    "  Analyzing the exchange energy of two conduction electrons in a crystal we\nfind that the exchange energy may be negative and, thus, a singlet state may be\nfavorable. A full overlap in real space of wave functions of two conduction\nelectrons leads to a deeper exchange energy. Thus, the exchange interaction\ncauses a bond between two conduction electrons in real space. The singlet bond\nis possible because the singlet electrons can simultaneously and permanently\noccupy one spatial ground state, so the average energy of paired electrons is\nlower than the energy of unpaired electrons. Thus, the pairing is a result of\nthe Pauli Exclusion Principle. If conduction electrons, before pairing, are put\non the Fermi surface in the momentum space, then every pair may exist\npermanently in time. The motion of conduction electrons in the crystal may\nprevent the formation of Cooper pairs, because the kinetic energy of the motion\nis usually larger than the binding energy in the pair. Conduction electrons as\nstanding waves are local and have zero momenta, hence their momenta are\nsynchronous; therefore, weak singlet bonds are stable despite the large kinetic\nenergy on the Fermi surface. The local pairing of standing waves explains the\ninverse isotope effect, Tc-dome, insulator-superconductor transitions and many\nother facts about superconductors. The electron pairs, as bosons, can form a\nmacroscopically coherent Bose-Einstein-Condensate and, thus, become\nnon-dissipative and non-local.\n",
    "In this work we propose a structured prediction technique that combines the\nvirtues of Gaussian Conditional Random Fields (G-CRF) with Deep Learning: (a)\nour structured prediction task has a unique global optimum that is obtained\nexactly from the solution of a linear system (b) the gradients of our model\nparameters are analytically computed using closed form expressions, in contrast\nto the memory-demanding contemporary deep structured prediction approaches that\nrely on back-propagation-through-time, (c) our pairwise terms do not have to be\nsimple hand-crafted expressions, as in the line of works building on the\nDenseCRF, but can rather be `discovered' from data through deep architectures,\nand (d) out system can trained in an end-to-end manner. Building on standard\ntools from numerical analysis we develop very efficient algorithms for\ninference and learning, as well as a customized technique adapted to the\nsemantic segmentation task. This efficiency allows us to explore more\nsophisticated architectures for structured prediction in deep learning: we\nintroduce multi-resolution architectures to couple information across scales in\na joint optimization framework, yielding systematic improvements. We\ndemonstrate the utility of our approach on the challenging VOC PASCAL 2012\nimage segmentation benchmark, showing substantial improvements over strong\nbaselines. We make all of our code and experiments available at\n{https://github.com/siddharthachandra/gcrf}",
    "  This paper presents a variational based approach to fusing hyperspectral and\nmultispectral images. The fusion process is formulated as an inverse problem\nwhose solution is the target image assumed to live in a much lower dimensional\nsubspace. A sparse regularization term is carefully designed, relying on a\ndecomposition of the scene on a set of dictionaries. The dictionary atoms and\nthe corresponding supports of active coding coefficients are learned from the\nobserved images. Then, conditionally on these dictionaries and supports, the\nfusion problem is solved via alternating optimization with respect to the\ntarget image (using the alternating direction method of multipliers) and the\ncoding coefficients. Simulation results demonstrate the efficiency of the\nproposed algorithm when compared with the state-of-the-art fusion methods.\n",
    "  The gauge formalism in Telepalallel Gravity provides an interesting viewpoint\nto describe interactions according to an anholonomic observes tetrad basis. The\nperturbed spacetime algebra with Weitzenb\\\"ock connection can be assimilated to\na local complexification based on the SU(4) Yang--Mills theory,that we call\nhypercolour or, simply, colour. The formulation of the hypercolour dynamics is\nconstructed by means of a translational gauge, as in the teleparallel gravity.\nIn particular, this work explores small perturbations of a metric decomposition\nrelated to the Wilson line and the Kaluza--Klein metric, but obtaining\nelectrodynamics in four dimensions. The spacetime coordinates are now matrices\nrepresenting elements of the $\\mathfrak{su}(4)$ Lie algebra. To make compatible\nthe formulation of a coloured gravity with the Lorentz force and the Maxwell's\nequations, it is enough to define any energy potential origin as 0 in the event\nhorizon, instead of the classic zero potential at infinity. Under the coloured\ngravity framework, standard electromagnetism can be obtained as a particular\nabelian case.\n",
    "Deep neural networks (DNNs) have become increasingly important due to their\nexcellent empirical performance on a wide range of problems. However,\nregularization is generally achieved by indirect means, largely due to the\ncomplex set of functions defined by a network and the difficulty in measuring\nfunction complexity. There exists no method in the literature for additive\nregularization based on a norm of the function, as is classically considered in\nstatistical learning theory. In this work, we propose sampling-based\napproximations to weighted function norms as regularizers for deep neural\nnetworks. We provide, to the best of our knowledge, the first proof in the\nliterature of the NP-hardness of computing function norms of DNNs, motivating\nthe necessity of an approximate approach. We then derive a generalization bound\nfor functions trained with weighted norms and prove that a natural stochastic\noptimization strategy minimizes the bound. Finally, we empirically validate the\nimproved performance of the proposed regularization strategies for both convex\nfunction sets as well as DNNs on real-world classification and image\nsegmentation tasks demonstrating improved performance over weight decay,\ndropout, and batch normalization. Source code will be released at the time of\npublication.",
    "  Let s_q(n) denote the base q sum of digits function, which for n<x, is\ncentered around (q-1)/2 log_q x. In Drmota, Mauduit and Rivat's 2009 paper,\nthey look at sum of digits of prime numbers, and provide asymptotics for the\nsize of the set {p<x, p prime : s_q(p)=alpha(q-1)log_q x} where alpha lies in a\ntight range around 1/2. In this paper, we examine the tails of this\ndistribution, and provide the lower bound |{p < x, p prime :\ns_q(p)>alpha(q-1)log_q x}| >>x^{2(1-alpha)}e^{-c(log x)^{1/2+epsilon}} for\n1/2<alpha<0.7375. To attain this lower bound, we note that the multinomial\ndistribution is sharply peaked, and apply results regarding primes in short\nintervals. This proves that there are infinitely many primes with more than\ntwice as many ones than zeros in their binary expansion.\n",
    "  Caffrey, Egge, Michel, Rubin and Ver Steegh recently introduced snow leopard\npermutations, which are the anti-Baxter permutations that are compatible with\nthe doubly alternating Baxter permutations. Among other things, they showed\nthat these permutations preserve parity, and that the number of snow leopard\npermutations of length $2n-1$ is the Catalan number $C_n$. In this paper we\ninvestigate the permutations that the snow leopard permutations induce on their\neven and odd entries; we call these the even threads and the odd threads,\nrespectively. We give recursive bijections between these permutations and\ncertain families of Catalan paths. We characterize the odd (resp. even) threads\nwhich form the other half of a snow leopard permutation whose even (resp. odd)\nthread is layered in terms of pattern avoidance, and we give a constructive\nbijection between the set of permutations of length $n$ which are both even\nthreads and odd threads and the set of peakless Motzkin paths of length $n+1$.\n",
    "A variety of deep neural networks have been applied in medical image\nsegmentation and achieve good performance. Unlike natural images, medical\nimages of the same imaging modality are characterized by the same pattern,\nwhich indicates that same normal organs or tissues locate at similar positions\nin the images. Thus, in this paper we try to incorporate the prior knowledge of\nmedical images into the structure of neural networks such that the prior\nknowledge can be utilized for accurate segmentation. Based on this idea, we\npropose a novel deep network called knowledge-based fully convolutional network\n(KFCN) for medical image segmentation. The segmentation function and\ncorresponding error is analyzed. We show the existence of an asymptotically\nstable region for KFCN which traditional FCN doesn't possess. Experiments\nvalidate our knowledge assumption about the incorporation of prior knowledge\ninto the convolution kernels of KFCN and show that KFCN can achieve a\nreasonable segmentation and a satisfactory accuracy.",
    "  We propose and demonstrate localized mode coupling as a viable dispersion\nengineering technique for phase-matched resonant four-wave mixing (FWM). We\ndemonstrate a dual-cavity resonant structure that employs coupling-induced\nfrequency splitting at one of three resonances to compensate for cavity\ndispersion, enabling phase-matching. Coupling strength is controlled by thermal\ntuning of one cavity enabling active control of the resonant\nfrequency-matching. In a fabricated silicon microresonator, we show an 8 dB\nenhancement of seeded FWM efficiency over the non-compensated state. The\nmeasured four-wave mixing has a peak wavelength conversion efficiency of -37.9\ndB across a free spectral range (FSR) of 3.334 THz ($\\sim$27 nm). Enabled by\nstrong counteraction of dispersion, this FSR is, to our knowledge, the largest\nin silicon to demonstrate FWM to date. This form of mode-coupling-based, active\ndispersion compensation can be beneficial for many FWM-based devices including\nwavelength converters, parametric amplifiers, and widely detuned correlated\nphoton-pair sources. Apart from compensating intrinsic dispersion, the proposed\nmechanism can alternatively be utilized in an otherwise dispersionless\nresonator to counteract the detuning effect of self- and cross-phase modulation\non the pump resonance during FWM, thereby addressing a fundamental issue in the\nperformance of light sources such as broadband optical frequency combs.\n",
    "  We analyze the performance of a linear-equality-constrained least-squares\n(CLS) algorithm and its relaxed version, called rCLS, that is obtained via the\nmethod of weighting. The rCLS algorithm solves an unconstrained least-squares\nproblem that is augmented by incorporating a weighted form of the linear\nconstraints. As a result, unlike the CLS algorithm, the rCLS algorithm is\namenable to our approach to performance analysis presented here, which is akin\nto the energy-conservation-based methodology. Therefore, we initially inspect\nthe convergence properties and evaluate the precision of estimation as well as\nsatisfaction of the constraints for the rCLS algorithm in both mean and\nmean-square senses. Afterwards, we examine the performance of the CLS algorithm\nby evaluating the limiting performance of the rCLS algorithm as the relaxation\nparameter (weight) approaches infinity. Numerical examples verify the accuracy\nof the theoretical findings.\n",
    "The random walker (RW) algorithm is used for both image segmentation and\nregistration, and possesses several useful properties that make it popular in\nmedical imaging, such as being globally optimizable, allowing user interaction,\nand providing uncertainty information. The RW algorithm defines a weighted\ngraph over an image and uses the graph's Laplacian matrix to regularize its\nsolutions. This regularization reduces to solving a large system of equations,\nwhich may be excessively time consuming in some applications, such as when\ninteracting with a human user. Techniques have been developed that precompute\neigenvectors of a Laplacian offline, after image acquisition but before any\nanalysis, in order speed up the RW algorithm online, when segmentation or\nregistration is being performed. However, precomputation requires certain\nalgorithm parameters be fixed offline, limiting their flexibility. In this\npaper, we develop techniques to update the precomputed data online when RW\nparameters are altered. Specifically, we dynamically determine the number of\neigenvectors needed for a desired accuracy based on user input, and derive\nupdate equations for the eigenvectors when the edge weights or topology of the\nimage graph are changed. We present results demonstrating that our techniques\nmake RW with precomputation much more robust to offline settings while only\nsacrificing minimal accuracy.",
    "We propose a novel superpixel-based multi-view convolutional neural network\nfor semantic image segmentation. The proposed network produces a high quality\nsegmentation of a single image by leveraging information from additional views\nof the same scene. Particularly in indoor videos such as captured by robotic\nplatforms or handheld and bodyworn RGBD cameras, nearby video frames provide\ndiverse viewpoints and additional context of objects and scenes. To leverage\nsuch information, we first compute region correspondences by optical flow and\nimage boundary-based superpixels. Given these region correspondences, we\npropose a novel spatio-temporal pooling layer to aggregate information over\nspace and time. We evaluate our approach on the NYU--Depth--V2 and the SUN3D\ndatasets and compare it to various state-of-the-art single-view and multi-view\napproaches. Besides a general improvement over the state-of-the-art, we also\nshow the benefits of making use of unlabeled frames during training for\nmulti-view as well as single-view prediction.",
    "The main obstacle to weakly supervised semantic image segmentation is the\ndifficulty of obtaining pixel-level information from coarse image-level\nannotations. Most methods based on image-level annotations use localization\nmaps obtained from the classifier, but these only focus on the small\ndiscriminative parts of objects and do not capture precise boundaries.\nFickleNet explores diverse combinations of locations on feature maps created by\ngeneric deep neural networks. It selects hidden units randomly and then uses\nthem to obtain activation scores for image classification. FickleNet implicitly\nlearns the coherence of each location in the feature maps, resulting in a\nlocalization map which identifies both discriminative and other parts of\nobjects. The ensemble effects are obtained from a single network by selecting\nrandom hidden unit pairs, which means that a variety of localization maps are\ngenerated from a single image. Our approach does not require any additional\ntraining steps and only adds a simple layer to a standard convolutional neural\nnetwork; nevertheless it outperforms recent comparable techniques on the Pascal\nVOC 2012 benchmark in both weakly and semi-supervised settings.",
    "  The measurement-device-independent quantum key distribution (MDI-QKD)\nprotocol has been proposed for the purpose of removing the detector side\nchannel attacks. Due to the multi-photon events of coherent states sources,\nreal-life implementations of MDI-QKD protocol must employ decoy states to beat\nthe photon-number-splitting attack. Decoy states for MDI-QKD based on the weak\ncoherent states have been studied recently. In this paper, we propose to\nperform MDI-QKD protocol with modified coherent states (MCS) sources. We\nsimulate the performance of MDI-QKD with the decoy states based on MCS sources.\nAnd our simulation indicates that both the secure-key rate and transmission\ndistance can be improved evidently with MCS sources.The physics behind this\nimprovement is that the probability of multi-photon events of the MCS is lower\nthan that of weak coherent states while at the same time the probability of\nsingle-photon is higher.\n",
    "LIDAR point clouds and RGB-images are both extremely essential for 3D object\ndetection. So many state-of-the-art 3D detection algorithms dedicate in fusing\nthese two types of data effectively. However, their fusion methods based on\nBirds Eye View (BEV) or voxel format are not accurate. In this paper, we\npropose a novel fusion approach named Point-based Attentive Cont-conv\nFusion(PACF) module, which fuses multi-sensor features directly on 3D points.\nExcept for continuous convolution, we additionally add a Point-Pooling and an\nAttentive Aggregation to make the fused features more expressive. Moreover,\nbased on the PACF module, we propose a 3D multi-sensor multi-task network\ncalled Pointcloud-Image RCNN(PI-RCNN as brief), which handles the image\nsegmentation and 3D object detection tasks. PI-RCNN employs a segmentation\nsub-network to extract full-resolution semantic feature maps from images and\nthen fuses the multi-sensor features via powerful PACF module. Beneficial from\nthe effectiveness of the PACF module and the expressive semantic features from\nthe segmentation module, PI-RCNN can improve much in 3D object detection. We\ndemonstrate the effectiveness of the PACF module and PI-RCNN on the KITTI 3D\nDetection benchmark, and our method can achieve state-of-the-art on the metric\nof 3D AP.",
    "  The main idea of this challenging research is to revisit the solar-centric\ndynamics of Earth around the Sun in analysis of its position on 13 April 2029\nclose to asteroid Apophis which is supposed to be moving in fly-by near the\nEarth on its orbit. As of now, we can be sure that trajectory of Apophis is\nwell-known with respect to the center of Sun. Also, NASA experts calculated\nthat relative distance between center of Earth and Apophis should be less than\n38 thousands of kilometers during closest Apophis approach to the Earth. But\nthe reasonable question is: will the center of Earth be at the predicted\nposition at the beginning of April 2029? The matter is that NASA solving\nprocedure disregards influence of Milankovich cycles to the orbit of Earth but\nalternative concept suggests another solution (with additional quasi-periodic\ndeviation from their solution, proportional to square of eccentricity of Earth\norbit around the Sun equals to ~ 0.017). So, possible perturbation of Earth\norbit is likely to be proportional to (0.017)$^2$ ~ 0.03% from 1 a.e. or ~ 43\n200 km which could be compared with gap between Earth and Apophis during\nclosest Apophis approach to Earth in April 2029.\n",
    "Building a large image dataset with high-quality object masks for semantic\nsegmentation is costly and time consuming. In this paper, we introduce a\nprincipled semi-supervised framework that only uses a small set of fully\nsupervised images (having semantic segmentation labels and box labels) and a\nset of images with only object bounding box labels (we call it the weak set).\nOur framework trains the primary segmentation model with the aid of an\nancillary model that generates initial segmentation labels for the weak set and\na self-correction module that improves the generated labels during training\nusing the increasingly accurate primary model. We introduce two variants of the\nself-correction module using either linear or convolutional functions.\nExperiments on the PASCAL VOC 2012 and Cityscape datasets show that our models\ntrained with a small fully supervised set perform similar to, or better than,\nmodels trained with a large fully supervised set while requiring ~7x less\nannotation effort.",
    "To bridge the gap between the source and target domains in unsupervised\ndomain adaptation (UDA), the most common strategy puts focus on matching the\nmarginal distributions in the feature space through adversarial learning.\nHowever, such category-agnostic global alignment lacks of exploiting the\nclass-level joint distributions, causing the aligned distribution less\ndiscriminative. To address this issue, we propose in this paper a novel margin\npreserving self-paced contrastive Learning (MPSCL) model for cross-modal\nmedical image segmentation. Unlike the conventional construction of contrastive\npairs in contrastive learning, the domain-adaptive category prototypes are\nutilized to constitute the positive and negative sample pairs. With the\nguidance of progressively refined semantic prototypes, a novel margin\npreserving contrastive loss is proposed to boost the discriminability of\nembedded representation space. To enhance the supervision for contrastive\nlearning, more informative pseudo-labels are generated in target domain in a\nself-paced way, thus benefiting the category-aware distribution alignment for\nUDA. Furthermore, the domain-invariant representations are learned through\njoint contrastive learning between the two domains. Extensive experiments on\ncross-modal cardiac segmentation tasks demonstrate that MPSCL significantly\nimproves semantic segmentation performance, and outperforms a wide variety of\nstate-of-the-art methods by a large margin.",
    "Image segmentation is a fundamental and challenging problem in computer\nvision with applications spanning multiple areas, such as medical imaging,\nremote sensing, and autonomous vehicles. Recently, convolutional neural\nnetworks (CNNs) have gained traction in the design of automated segmentation\npipelines. Although CNN-based models are adept at learning abstract features\nfrom raw image data, their performance is dependent on the availability and\nsize of suitable training datasets. Additionally, these models are often unable\nto capture the details of object boundaries and generalize poorly to unseen\nclasses. In this thesis, we devise novel methodologies that address these\nissues and establish robust representation learning frameworks for\nfully-automatic semantic segmentation in medical imaging and mainstream\ncomputer vision. In particular, our contributions include (1) state-of-the-art\n2D and 3D image segmentation networks for computer vision and medical image\nanalysis, (2) an end-to-end trainable image segmentation framework that unifies\nCNNs and active contour models with learnable parameters for fast and robust\nobject delineation, (3) a novel approach for disentangling edge and texture\nprocessing in segmentation networks, and (4) a novel few-shot learning model in\nboth supervised settings and semi-supervised settings where synergies between\nlatent and image spaces are leveraged to learn to segment images given limited\ntraining data.",
    "We develop a generalized active contour formalism for image segmentation\nbased on shape templates. The shape template is subjected to a restricted\naffine transformation (RAT) in order to segment the object of interest. RAT\nallows for translation, rotation, and scaling, which give a total of five\ndegrees of freedom. The proposed active contour comprises an inner and outer\ncontour pair, which are closed and concentric. The active contour energy is a\ncontrast function defined based on the intensities of pixels that lie inside\nthe inner contour and those that lie in the annulus between the inner and outer\ncontours. We show that the contrast energy functional is optimal under certain\nconditions. The optimal RAT parameters are computed by maximizing the contrast\nfunction using a gradient descent optimizer. We show that the calculations are\nmade efficient through use of Green's theorem. The proposed formalism is\ncapable of handling a variety of shapes because for a chosen template,\noptimization is carried with respect to the RAT parameters only. The proposed\nformalism is validated on multiple images to show robustness to Gaussian and\nPoisson noise, to initialization, and to partial loss of structure in the\nobject to be segmented.",
    "We introduce an approach for image segmentation based on sparse\ncorrespondences between keypoints in testing and training images. Keypoints\nrepresent automatically identified distinctive image locations, where each\nkeypoint correspondence suggests a transformation between images. We use these\ncorrespondences to transfer label maps of entire organs from the training\nimages to the test image. The keypoint transfer algorithm includes three steps:\n(i) keypoint matching, (ii) voting-based keypoint labeling, and (iii)\nkeypoint-based probabilistic transfer of organ segmentations. We report\nsegmentation results for abdominal organs in whole-body CT and MRI, as well as\nin contrast-enhanced CT and MRI. Our method offers a speed-up of about three\norders of magnitude in comparison to common multi-atlas segmentation, while\nachieving an accuracy that compares favorably. Moreover, keypoint transfer does\nnot require the registration to an atlas or a training phase. Finally, the\nmethod allows for the segmentation of scans with highly variable field-of-view.",
    "Over the last two decades, deep learning has transformed the field of\ncomputer vision. Deep convolutional networks were successfully applied to learn\ndifferent vision tasks such as image classification, image segmentation, object\ndetection and many more. By transferring the knowledge learned by deep models\non large generic datasets, researchers were further able to create fine-tuned\nmodels for other more specific tasks. Recently this idea was applied for\nregressing the absolute camera pose from an RGB image. Although the resulting\naccuracy was sub-optimal, compared to classic feature-based solutions, this\neffort led to a surge of learning-based pose estimation methods. Here, we\nreview deep learning approaches for camera pose estimation. We describe key\nmethods in the field and identify trends aiming at improving the original deep\npose regression solution. We further provide an extensive cross-comparison of\nexisting learning-based pose estimators, together with practical notes on their\nexecution for reproducibility purposes. Finally, we discuss emerging solutions\nand potential future research directions.",
    "  When nodes can repeatedly update their behavior (as in agent-based models\nfrom computational social science or repeated-game play settings) the problem\nof optimal network seeding becomes very complex. For a popular\nspreading-phenomena model of binary-behavior updating based on thresholds of\nadoption among neighbors, we consider several planning problems in the design\nof \\textit{Sticky Interventions}: when adoption decisions are reversible, the\nplanner aims to find a Seed Set where temporary intervention leads to long-term\nbehavior change. We prove that completely converting a network at minimum cost\nis $\\Omega(\\ln (OPT) )$-hard to approximate and that maximizing conversion\nsubject to a budget is $(1-\\frac{1}{e})$-hard to approximate. Optimization\nheuristics which rely on many objective function evaluations may still be\npractical, particularly in relatively-sparse networks: we prove that the\nlong-term impact of a Seed Set can be evaluated in $O(|E|^2)$ operations. For a\nmore descriptive model variant in which some neighbors may be more influential\nthan others, we show that under integer edge weights from $\\{0,1,2,...,k\\}$\nobjective function evaluation requires only $O(k|E|^2)$ operations. These\noperation bounds are based on improvements we give for bounds on\ntime-steps-to-convergence under discrete-time reversible-threshold updates in\nnetworks.\n",
    "Deep learning-based medical image segmentation technology aims at automatic\nrecognizing and annotating objects on the medical image. Non-local attention\nand feature learning by multi-scale methods are widely used to model network,\nwhich drives progress in medical image segmentation. However, those attention\nmechanism methods have weakly non-local receptive fields' strengthened\nconnection for small objects in medical images. Then, the features of important\nsmall objects in abstract or coarse feature maps may be deserted, which leads\nto unsatisfactory performance. Moreover, the existing multi-scale methods only\nsimply focus on different sizes of view, whose sparse multi-scale features\ncollected are not abundant enough for small objects segmentation. In this work,\na multi-dimensional attention segmentation model with cascade multi-scale\nconvolution is proposed to predict accurate segmentation for small objects in\nmedical images. As the weight function, multi-dimensional attention modules\nprovide coefficient modification for significant/informative small objects\nfeatures. Furthermore, The cascade multi-scale convolution modules in each\nskip-connection path are exploited to capture multi-scale features in different\nsemantic depth. The proposed method is evaluated on three datasets: KiTS19,\nPancreas CT of Decathlon-10, and MICCAI 2018 LiTS Challenge, demonstrating\nbetter segmentation performances than the state-of-the-art baselines.",
    "  Few layer graphene systems such as Bernal stacked bilayer and rhombohedral\n(ABC-) stacked trilayer offer the unique possibility to open an electric field\ntunable energy gap. To date, this energy gap has been experimentally confirmed\nin optical spectroscopy. Here we report the first direct observation of the\nelectric field tunable energy gap in electronic transport experiments on doubly\ngated suspended ABC-trilayer graphene. From a systematic study of the\nnon-linearities in current \\textit{versus} voltage characteristics and the\ntemperature dependence of the conductivity we demonstrate that thermally\nactivated transport over the energy-gap dominates the electrical response of\nthese transistors. The estimated values for energy gap from the temperature\ndependence and from the current voltage characteristics follow the\ntheoretically expected electric field dependence with critical exponent $3/2$.\nThese experiments indicate that high quality few-layer graphene are suitable\ncandidates for exploring novel tunable THz light sources and detectors.\n",
    "  Wisely utilizing the internal and external learning methods is a new\nchallenge in super-resolution problem. To address this issue, we analyze the\nattributes of two methodologies and find two observations of their recovered\ndetails: 1) they are complementary in both feature space and image plane, 2)\nthey distribute sparsely in the spatial space. These inspire us to propose a\nlow-rank solution which effectively integrates two learning methods and then\nachieves a superior result. To fit this solution, the internal learning method\nand the external learning method are tailored to produce multiple preliminary\nresults. Our theoretical analysis and experiment prove that the proposed\nlow-rank solution does not require massive inputs to guarantee the performance,\nand thereby simplifying the design of two learning methods for the solution.\nIntensive experiments show the proposed solution improves the single learning\nmethod in both qualitative and quantitative assessments. Surprisingly, it shows\nmore superior capability on noisy images and outperforms state-of-the-art\nmethods.\n",
    "In response to the growing importance of geospatial data, its analysis\nincluding semantic segmentation becomes an increasingly popular task in\ncomputer vision today. Convolutional neural networks are powerful visual models\nthat yield hierarchies of features and practitioners widely use them to process\nremote sensing data. When performing remote sensing image segmentation,\nmultiple instances of one class with precisely defined boundaries are often the\ncase, and it is crucial to extract those boundaries accurately. The accuracy of\nsegments boundaries delineation influences the quality of the whole segmented\nareas explicitly. However, widely-used segmentation loss functions such as BCE,\nIoU loss or Dice loss do not penalize misalignment of boundaries sufficiently.\nIn this paper, we propose a novel loss function, namely a differentiable\nsurrogate of a metric accounting accuracy of boundary detection. We can use the\nloss function with any neural network for binary segmentation. We performed\nvalidation of our loss function with various modifications of UNet on a\nsynthetic dataset, as well as using real-world data (ISPRS Potsdam, INRIA AIL).\nTrained with the proposed loss function, models outperform baseline methods in\nterms of IoU score.",
    "Uncertainty estimation is important for interpreting the trustworthiness of\nmachine learning models in many applications. This is especially critical in\nthe data-driven active learning setting where the goal is to achieve a certain\naccuracy with minimum labeling effort. In such settings, the model learns to\nselect the most informative unlabeled samples for annotation based on its\nestimated uncertainty. The highly uncertain predictions are assumed to be more\ninformative for improving model performance. In this paper, we explore\nuncertainty calibration within an active learning framework for medical image\nsegmentation, an area where labels often are scarce. Various uncertainty\nestimation methods and acquisition strategies (regions and full images) are\ninvestigated. We observe that selecting regions to annotate instead of full\nimages leads to more well-calibrated models. Additionally, we experimentally\nshow that annotating regions can cut 50% of pixels that need to be labeled by\nhumans compared to annotating full images.",
    "  This paper presents a new Bayesian collaborative sparse regression method for\nlinear unmixing of hyperspectral images. Our contribution is twofold; first, we\npropose a new Bayesian model for structured sparse regression in which the\nsupports of the sparse abundance vectors are a priori spatially correlated\nacross pixels (i.e., materials are spatially organised rather than randomly\ndistributed at a pixel level). This prior information is encoded in the model\nthrough a truncated multivariate Ising Markov random field, which also takes\ninto consideration the facts that pixels cannot be empty (i.e, there is at\nleast one material present in each pixel), and that different materials may\nexhibit different degrees of spatial regularity. Secondly, we propose an\nadvanced Markov chain Monte Carlo algorithm to estimate the posterior\nprobabilities that materials are present or absent in each pixel, and,\nconditionally to the maximum marginal a posteriori configuration of the\nsupport, compute the MMSE estimates of the abundance vectors. A remarkable\nproperty of this algorithm is that it self-adjusts the values of the parameters\nof the Markov random field, thus relieving practitioners from setting\nregularisation parameters by cross-validation. The performance of the proposed\nmethodology is finally demonstrated through a series of experiments with\nsynthetic and real data and comparisons with other algorithms from the\nliterature.\n",
    "Superpixel segmentation has become an important research problem in image\nprocessing. In this paper, we propose an Iterative Spanning Forest (ISF)\nframework, based on sequences of Image Foresting Transforms, where one can\nchoose i) a seed sampling strategy, ii) a connectivity function, iii) an\nadjacency relation, and iv) a seed pixel recomputation procedure to generate\nimproved sets of connected superpixels (supervoxels in 3D) per iteration. The\nsuperpixels in ISF structurally correspond to spanning trees rooted at those\nseeds. We present five ISF methods to illustrate different choices of its\ncomponents. These methods are compared with approaches from the\nstate-of-the-art in effectiveness and efficiency. The experiments involve 2D\nand 3D datasets with distinct characteristics, and a high level application,\nnamed sky image segmentation. The theoretical properties of ISF are\ndemonstrated in the supplementary material and the results show that some of\nits methods are competitive with or superior to the best baselines in\neffectiveness and efficiency.",
    "It is important to find the target as soon as possible for search and rescue\noperations. Surveillance camera systems and unmanned aerial vehicles (UAVs) are\nused to support search and rescue. Automatic object detection is important\nbecause a person cannot monitor multiple surveillance screens simultaneously\nfor 24 hours. Also, the object is often too small to be recognized by the human\neye on the surveillance screen. This study used UAVs around the Port of Houston\nand fixed surveillance cameras to build an automatic target detection system\nthat supports the US Coast Guard (USCG) to help find targets (e.g., person\noverboard). We combined image segmentation, enhancement, and convolution neural\nnetworks to reduce detection time to detect small targets. We compared the\nperformance between the auto-detection system and the human eye. Our system\ndetected the target within 8 seconds, but the human eye detected the target\nwithin 25 seconds. Our systems also used synthetic data generation and data\naugmentation techniques to improve target detection accuracy. This solution may\nhelp the search and rescue operations of the first responders in a timely\nmanner.",
    "  We present an application of multi-mesh finite element methods as part of a\nmethodology for optimizing settlement layouts. By formulating a multi-objective\noptimization problem, we demonstrate how a given number of buildings may be\noptimally placed on a given piece of land with respect to both wind conditions\nand the view experienced from the buildings. The wind flow is modeled by a\nmulti-mesh (cut finite element) method. This allows each building to be\nembedded in a boundary-fitted mesh which can be moved freely on top of a fixed\nbackground mesh. This approach enables a multitude of settlement layouts to be\nevaluated without the need for costly mesh generation when changing the\nconfiguration of buildings. The view is modeled by a measure that takes into\naccount the totality of unobstructed view from the collection of buildings, and\nis efficiently computed by rasterization.\n",
    "  We prove the existence and uniqueness of probabilistically strong solutions\nto stochastic porous media equations driven by time-dependent multiplicative\nnoise on a general measure space $(E, \\mathscr{B}(E), \\mu)$, and the Laplacian\nreplaced by a self-adjoint operator $L$. In the case of Lipschitz\nnonlinearities $\\Psi$, we in particular generalize previous results for open\n$E\\subset \\mathbb{R}^d$ and $L\\!\\!=$Laplacian to fractional Laplacians. We also\ngeneralize known results on general measure spaces, where we succeeded in\ndropping the transience assumption on $L$, in extending the set of allowed\ninitial data and in avoiding the restriction to superlinear behavior of $\\Psi$\nat infinity for $L^2(\\mu)$-initial data.\n",
    "Electron microscopic connectomics is an ambitious research direction with the\ngoal of studying comprehensive brain connectivity maps by using\nhigh-throughput, nano-scale microscopy. One of the main challenges in\nconnectomics research is developing scalable image analysis algorithms that\nrequire minimal user intervention. Recently, deep learning has drawn much\nattention in computer vision because of its exceptional performance in image\nclassification tasks. For this reason, its application to connectomic analyses\nholds great promise, as well. In this paper, we introduce a novel deep neural\nnetwork architecture, FusionNet, for the automatic segmentation of neuronal\nstructures in connectomics data. FusionNet leverages the latest advances in\nmachine learning, such as semantic segmentation and residual neural networks,\nwith the novel introduction of summation-based skip connections to allow a much\ndeeper network architecture for a more accurate segmentation. We demonstrate\nthe performance of the proposed method by comparing it with state-of-the-art\nelectron microscopy (EM) segmentation methods from the ISBI EM segmentation\nchallenge. We also show the segmentation results on two different tasks\nincluding cell membrane and cell body segmentation and a statistical analysis\nof cell morphology.",
    "In photography, low depth of field (DOF) is an important technique to\nemphasize the object of interest (OOI) within an image. Thus, low DOF images\nare widely used in the application area of macro, portrait or sports\nphotography. When viewing a low DOF image, the viewer implicitly concentrates\non the regions that are sharper regions of the image and thus segments the\nimage into regions of interest and non regions of interest which has a major\nimpact on the perception of the image. Thus, a robust algorithm for the fully\nautomatic detection of the OOI in low DOF images provides valuable information\nfor subsequent image processing and image retrieval. In this paper we propose a\nrobust and parameterless algorithm for the fully automatic segmentation of low\nDOF images. We compare our method with three similar methods and show the\nsuperior robustness even though our algorithm does not require any parameters\nto be set by hand. The experiments are conducted on a real world data set with\nhigh and low DOF images.",
    "  We consider the Longest Queue Drop memory management policy in shared-memory\nswitches consisting of $N$ output ports. The shared memory of size $M\\geq N$\nmay have an arbitrary number of input ports. Each packet may be admitted by any\nincoming port, but must be destined to a specific output port and each output\nport may be used by only one queue. The Longest Queue Drop policy is a natural\nonline strategy used in directing the packet flow in buffering problems.\nAccording to this policy and assuming unit packet values and cost of\ntransmission, every incoming packet is accepted, whereas if the shared memory\nbecomes full, one or more packets belonging to the longest queue are preempted,\nin order to make space for the newly arrived packets. It was proved in 2001\n[Hahne et al., SPAA '01] that the Longest Queue Drop policy is 2-competitive\nand at least $\\sqrt{2}$-competitive. It remained an open question whether a\n(2-\\epsilon) upper bound for the competitive ratio of this policy could be\nshown, for any positive constant \\epsilon. We show that the Longest Queue Drop\nonline policy is 1.5-competitive.\n",
    "We present a novel and practical deep fully convolutional neural network\narchitecture for semantic pixel-wise segmentation termed SegNet. This core\ntrainable segmentation engine consists of an encoder network, a corresponding\ndecoder network followed by a pixel-wise classification layer. The architecture\nof the encoder network is topologically identical to the 13 convolutional\nlayers in the VGG16 network. The role of the decoder network is to map the low\nresolution encoder feature maps to full input resolution feature maps for\npixel-wise classification. The novelty of SegNet lies is in the manner in which\nthe decoder upsamples its lower resolution input feature map(s). Specifically,\nthe decoder uses pooling indices computed in the max-pooling step of the\ncorresponding encoder to perform non-linear upsampling. This eliminates the\nneed for learning to upsample. The upsampled maps are sparse and are then\nconvolved with trainable filters to produce dense feature maps. We compare our\nproposed architecture with the widely adopted FCN and also with the well known\nDeepLab-LargeFOV, DeconvNet architectures. This comparison reveals the memory\nversus accuracy trade-off involved in achieving good segmentation performance.\n  SegNet was primarily motivated by scene understanding applications. Hence, it\nis designed to be efficient both in terms of memory and computational time\nduring inference. It is also significantly smaller in the number of trainable\nparameters than other competing architectures. We also performed a controlled\nbenchmark of SegNet and other architectures on both road scenes and SUN RGB-D\nindoor scene segmentation tasks. We show that SegNet provides good performance\nwith competitive inference time and more efficient inference memory-wise as\ncompared to other architectures. We also provide a Caffe implementation of\nSegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.",
    "Semantic segmentation models trained on public datasets have achieved great\nsuccess in recent years. However, these models didn't consider the\npersonalization issue of segmentation though it is important in practice. In\nthis paper, we address the problem of personalized image segmentation. The\nobjective is to generate more accurate segmentation results on unlabeled\npersonalized images by investigating the data's personalized traits. To open up\nfuture research in this area, we collect a large dataset containing various\nusers' personalized images called PIS (Personalized Image Semantic\nSegmentation). We also survey some recent researches related to this problem\nand report their performance on our dataset. Furthermore, by observing the\ncorrelation among a user's personalized images, we propose a baseline method\nthat incorporates the inter-image context when segmenting certain images.\nExtensive experiments show that our method outperforms the existing methods on\nthe proposed dataset. The code and the PIS dataset will be made publicly\navailable.",
    "Methods that move towards less supervised scenarios are key for image\nsegmentation, as dense labels demand significant human intervention. Generally,\nthe annotation burden is mitigated by labeling datasets with weaker forms of\nsupervision, e.g. image-level labels or bounding boxes. Another option are\nsemi-supervised settings, that commonly leverage a few strong annotations and a\nhuge number of unlabeled/weakly-labeled data. In this paper, we revisit\nsemi-supervised segmentation schemes and narrow down significantly the\nannotation budget (in terms of total labeling time of the training set)\ncompared to previous approaches. With a very simple pipeline, we demonstrate\nthat at low annotation budgets, semi-supervised methods outperform by a wide\nmargin weakly-supervised ones for both semantic and instance segmentation. Our\napproach also outperforms previous semi-supervised works at a much reduced\nlabeling cost. We present results for the Pascal VOC benchmark and unify weakly\nand semi-supervised approaches by considering the total annotation budget, thus\nallowing a fairer comparison between methods.",
    "Transformer architecture has emerged to be successful in a number of natural\nlanguage processing tasks. However, its applications to medical vision remain\nlargely unexplored. In this study, we present UTNet, a simple yet powerful\nhybrid Transformer architecture that integrates self-attention into a\nconvolutional neural network for enhancing medical image segmentation. UTNet\napplies self-attention modules in both encoder and decoder for capturing\nlong-range dependency at different scales with minimal overhead. To this end,\nwe propose an efficient self-attention mechanism along with relative position\nencoding that reduces the complexity of self-attention operation significantly\nfrom $O(n^2)$ to approximate $O(n)$. A new self-attention decoder is also\nproposed to recover fine-grained details from the skipped connections in the\nencoder. Our approach addresses the dilemma that Transformer requires huge\namounts of data to learn vision inductive bias. Our hybrid layer design allows\nthe initialization of Transformer into convolutional networks without a need of\npre-training. We have evaluated UTNet on the multi-label, multi-vendor cardiac\nmagnetic resonance imaging cohort. UTNet demonstrates superior segmentation\nperformance and robustness against the state-of-the-art approaches, holding the\npromise to generalize well on other medical image segmentations.",
    "  Differential privacy is a definition of \"privacy'\" for algorithms that\nanalyze and publish information about statistical databases. It is often\nclaimed that differential privacy provides guarantees against adversaries with\narbitrary side information. In this paper, we provide a precise formulation of\nthese guarantees in terms of the inferences drawn by a Bayesian adversary. We\nshow that this formulation is satisfied by both \"vanilla\" differential privacy\nas well as a relaxation known as (epsilon,delta)-differential privacy. Our\nformulation follows the ideas originally due to Dwork and McSherry [Dwork\n2006]. This paper is, to our knowledge, the first place such a formulation\nappears explicitly. The analysis of the relaxed definition is new to this\npaper, and provides some concrete guidance for setting parameters when using\n(epsilon,delta)-differential privacy.\n",
    "  We propose a theory of weakly nonlinear multi-dimensional self sustained\ndetonations based on asymptotic analysis of the reactive compressible\nNavier-Stokes equations. We show that these equations can be reduced to a model\nconsisting of a forced, unsteady, small disturbance, transonic equation and a\nrate equation for the heat release. In one spatial dimension, the model\nsimplifies to a forced Burgers equation. Through analysis, numerical\ncalculations and comparison with the reactive Euler equations, the model is\ndemonstrated to capture such essential dynamical characteristics of detonations\nas the steady-state structure, the linear stability spectrum, the\nperiod-doubling sequence of bifurcations and chaos in one-dimensional\ndetonations and cellular structures in multi- dimensional detonations.\n",
    "  We develop a theory of aggregation using statistical mechanical methods. An\nexample of a complicated aggregation system with several levels of structures\nis peptide/protein self-assembly. The problem of protein aggregation is\nimportant for the understanding and treatment of neurodegenerative diseases and\nalso for the development of bio-macromolecules as new materials. We write the\neffective Hamiltonian in terms of interaction energies between protein\nmonomers, protein and solvent, as well as between protein filaments. The grand\npartition function can be expressed in terms of a Zimm-Bragg-like transfer\nmatrix, which is calculated exactly and all thermodynamic properties can be\nobtained. We start with two-state and three-state descriptions of protein\nmonomers using Potts models that can be generalized to include q-states, for\nwhich the exactly solvable feature of the model remains. We focus on n X N\nlattice systems, corresponding to the ordered structures observed in some real\nfibrils. We have obtained results on nucleation processes and phase diagrams,\nin which a protein property such as the sheet content of aggregates is\nexpressed as a function of the number of proteins on the lattice and\ninter-protein or interfacial interaction energies. We have applied our methods\nto A{\\beta}(1-40) and Curli fibrils and obtained results in good agreement with\nexperiments.\n",
    "  We propose a new method for simplifying semidefinite programs (SDP) inspired\nby symmetry reduction. Specifically, we show if an orthogonal projection map\nsatisfies certain invariance conditions, restricting to its range yields an\nequivalent primal-dual pair over a lower-dimensional symmetric cone---namely,\nthe cone-of-squares of a Jordan subalgebra of symmetric matrices. We present a\nsimple algorithm for minimizing the rank of this projection and hence the\ndimension of this subalgebra. We also show that minimizing rank optimizes the\ndirect-sum decomposition of the algebra into simple ideals, yielding an optimal\n\"block-diagonalization\" of the SDP. Finally, we give combinatorial versions of\nour algorithm that execute at reduced computational cost and illustrate\neffectiveness of an implementation on examples. Through the theory of Jordan\nalgebras, the proposed method easily extends to linear and second-order-cone\nprogramming and, more generally, symmetric cone optimization.\n",
    "The hatching process also influences the success of hatching eggs beside the\ninitial egg factor. So that the results have a large percentage of hatching, it\nis necessary to check the development of the embryo at the beginning of the\nhatching. This process aims to sort eggs that have embryos to remain hatched\nuntil the end. Maximum checking is done the first week in the hatching period.\nThis study aims to detect the presence of embryos in eggs. Detection of the\nexistence of embryos is processed using segmentation. Egg images are segmented\nusing the K-means algorithm based on Lab color images. The results of the\nimages acquisition are converted into Lab color space images. The results of\nLab color space images are processed using K-means for each color. The K-means\nprocess uses cluster k=3, where this cluster divided the image into three\nparts, namely background, eggs, and yolk eggs. Yolk eggs are part of eggs that\nhave embryonic characteristics. This study applies the concept of color in the\ninitial segmentation and grayscale in the final stages. The results of the\ninitial phase show that the image segmentation results using k-means clustering\nbased on Lab color space provide a grouping of three parts. At the grayscale\nimage processing stage, the results of color image segmentation are processed\nwith grayscaling, image enhancement, and morphology. Thus, it seems clear that\nthe yolk segmented shows the presence of egg embryos. Based on this process and\nresults, K-means segmentation based on Lab color space can be used for the\ninitial stages of the embryo detection process. The evaluation uses MSE and\nMSSIM, with values of 0.0486 and 0.9979; this can be used as a reference that\nthe results obtained can indicate the detection of embryos in egg yolk.",
    "Fully convolutional deep neural networks have been asserted to be fast and\nprecise frameworks with great potential in image segmentation. One of the major\nchallenges in training such networks raises when data is unbalanced, which is\ncommon in many medical imaging applications such as lesion segmentation where\nlesion class voxels are often much lower in numbers than non-lesion voxels. A\ntrained network with unbalanced data may make predictions with high precision\nand low recall, being severely biased towards the non-lesion class which is\nparticularly undesired in most medical applications where FNs are more\nimportant than FPs. Various methods have been proposed to address this problem,\nmore recently similarity loss functions and focal loss. In this work we trained\nfully convolutional deep neural networks using an asymmetric similarity loss\nfunction to mitigate the issue of data imbalance and achieve much better\ntradeoff between precision and recall. To this end, we developed a 3D\nFC-DenseNet with large overlapping image patches as input and an asymmetric\nsimilarity loss layer based on Tversky index (using Fbeta scores). We used\nlarge overlapping image patches as inputs for intrinsic and extrinsic data\naugmentation, a patch selection algorithm, and a patch prediction fusion\nstrategy using B-spline weighted soft voting to account for the uncertainty of\nprediction in patch borders. We applied this method to MS lesion segmentation\nbased on two different datasets of MSSEG and ISBI longitudinal MS lesion\nsegmentation challenge, where we achieved top performance in both challenges.\nOur network trained with focal loss ranked first according to the ISBI\nchallenge overall score and resulted in the lowest reported lesion false\npositive rate among all submitted methods. Our network trained with the\nasymmetric similarity loss led to the lowest surface distance and the best\nlesion true positive rate.",
    "  Mixture Markov Model (MMM) is a widely used tool to cluster sequences of\nevents coming from a finite state-space. However the MMM likelihood being\nmulti-modal, the challenge remains in its maximization. Although\nExpectation-Maximization (EM) algorithm remains one of the most popular ways to\nestimate the MMM parameters, however convergence of EM algorithm is not always\nguaranteed. Given the computational challenges in maximizing the mixture\nlikelihood on the constrained parameter space, we develop a pattern\nsearch-based global optimization technique which can optimize any objective\nfunction on a collection of simplexes, which is eventually used to maximize MMM\nlikelihood. This is shown to outperform other related global optimization\ntechniques. In simulation experiments, the proposed method is shown to\noutperform the expectation-maximization (EM) algorithm in the context of MMM\nestimation performance. The proposed method is applied to cluster Multiple\nsclerosis (MS) patients based on their treatment sequences of disease-modifying\ntherapies (DMTs). We also propose a novel method to cluster people with MS\nbased on DMT prescriptions and associated clinical features (covariates) using\nMMM with covariates. Based on the analysis, we divided MS patients into 3\nclusters. Further cluster-specific summaries of relevant covariates indicate\npatient differences among the clusters.\n",
    "  We present sound and complete environmental bisimilarities for a variant of\nDybvig et al.'s calculus of multi-prompted delimited-control operators with\ndynamic prompt generation. The reasoning principles that we obtain generalize\nand advance the existing techniques for establishing program equivalence in\ncalculi with single-prompted delimited control. The basic theory that we\ndevelop is presented using Madiot et al.'s framework that allows for smooth\nintegration and composition of up-to techniques facilitating bisimulation\nproofs. We also generalize the framework in order to express environmental\nbisimulations that support equivalence proofs of evaluation contexts\nrepresenting continuations. This change leads to a novel and powerful up-to\ntechnique enhancing bisimulation proofs in the presence of control operators.\n",
    "  We consider two interacting Bose-Einstein condensates (BEC's) with different\nkind of the potential energy of interaction of the condensates: (a) the\nstandard potential; (b) the potential has a positive three-body and a negative\ntwo-body scattering terms and (c) the potential has a positive four-body and a\nnegative three-body scattering terms for the first BEC and a positive\nthree-body and a negative two-body scattering terms for the second BEC. It is\nshown that in these cases there exist regular spherically symmetric solutions.\nPhysically such solution is either a defect or a droplet created by the\ncondensates. The defect is a cavity filled with one BEC on the background of\nanother BEC. The droplet is an object on the background of the empty space. For\n(a) and (b) cases the obtained objects are supported by a constant external\ntrapping potential and for (c) case the droplet is a self-maintaining object\nwithout any external potential. The possibility of construction of an\nelementary logic qubit device on the basis of this droplet is discussed.\n",
    "Few-shot semantic segmentation (FSS) has great potential for medical imaging\napplications. Most of the existing FSS techniques require abundant annotated\nsemantic classes for training. However, these methods may not be applicable for\nmedical images due to the lack of annotations. To address this problem we make\nseveral contributions: (1) A novel self-supervised FSS framework for medical\nimages in order to eliminate the requirement for annotations during training.\nAdditionally, superpixel-based pseudo-labels are generated to provide\nsupervision; (2) An adaptive local prototype pooling module plugged into\nprototypical networks, to solve the common challenging foreground-background\nimbalance problem in medical image segmentation; (3) We demonstrate the general\napplicability of the proposed approach for medical images using three different\ntasks: abdominal organ segmentation for CT and MRI, as well as cardiac\nsegmentation for MRI. Our results show that, for medical image segmentation,\nthe proposed method outperforms conventional FSS methods which require manual\nannotations for training.",
    "  We construct a mesoscale model of colloidal suspensions that contain solutes\nreversibly adsorbing onto the colloidal particle surfaces. The present model\ndescribes the coupled dynamics of the colloidal particles, the host fluid, and\nthe solutes through the Newton-Euler equations of motion, the hydrodynamic\nequations, and the advection-diffusion equation, respectively. The solute\nadsorption is modeled through a square-well potential, which represents a\nshort-range attractive interaction between a particle and a solute molecule.\nThe present model is formulated to be solved through direct numerical\nsimulations. Some numerical results are presented to validate the simulations.\nThe present model enables investigations of solute adsorption effects in the\npresence of a fluid flow and an inhomogeneous solute concentration\ndistribution.\n",
    "  Given a topological modular functor $\\mathcal{V}$ in the sense of Walker\n\\cite{Walker}, we construct vector bundles over $\\bar{\\mathcal{M}}_{g,n}$,\nwhose Chern classes define semi-simple cohomological field theories. This\nconstruction depends on a determination of the logarithm of the eigenvalues of\nthe Dehn twist and central element actions. We show that the intersection of\nthe Chern class with the $\\psi$-classes in $\\bar{\\mathcal{M}}_{g,n}$ is\ncomputed by the topological recursion of \\cite{EOFg}, for a local spectral\ncurve that we describe. In particular, we show how the Verlinde formula for the\ndimensions $D_{\\vec{\\lambda}}(\\mathbf{\\Sigma}_{g,n}) = \\dim\n\\mathcal{V}_{\\vec{\\lambda}}(\\mathbf{\\Sigma}_{g,n})$ is retrieved from the\ntopological recursion. We analyze the consequences of our result on two\nexamples: modular functors associated to a finite group $G$ (for which\n$D_{\\vec{\\lambda}}(\\mathbf{\\Sigma}_{g,n})$ enumerates certain $G$-principle\nbundles over a genus $g$ surface with $n$ boundary conditions specified by\n$\\vec{\\lambda}$), and the modular functor obtained from Wess-Zumino-Witten\nconformal field theory associated to a simple, simply-connected Lie group $G$\n(for which $\\mathcal{V}_{\\vec{\\lambda}}(\\mathbf{\\Sigma}_{g,n})$ is the Verlinde\nbundle).\n",
    "  We investigate the ultrafast optoelectronic properties of single\nAl0.3Ga0.7As/GaAs-core-shell-nanowires. The nanowires contain GaAs-based\nquantum wells. For a resonant excitation of the quantum wells, we find a\npicosecond photocurrent which is consistent with an ultrafast lateral expansion\nof the photogenerated charge carriers. This Dember-effect does not occur for an\nexcitation of the GaAs-based core of the nanowires. Instead, the core exhibits\nan ultrafast displacement current and a photo-thermoelectric current at the\nmetal Schottky contacts. Our results uncover the optoelectronic dynamics in\nsemiconductor core-shell nanowires comprising quantum wells, and they\ndemonstrate the possibility to use the low-dimensional quantum well states\ntherein for ultrafast photoswitches and photodetectors.\n",
    "Deep learning models are sensitive to domain shift phenomena. A model trained\non images from one domain cannot generalise well when tested on images from a\ndifferent domain, despite capturing similar anatomical structures. It is mainly\nbecause the data distribution between the two domains is different. Moreover,\ncreating annotation for every new modality is a tedious and time-consuming\ntask, which also suffers from high inter- and intra- observer variability.\nUnsupervised domain adaptation (UDA) methods intend to reduce the gap between\nsource and target domains by leveraging source domain labelled data to generate\nlabels for the target domain. However, current state-of-the-art (SOTA) UDA\nmethods demonstrate degraded performance when there is insufficient data in\nsource and target domains. In this paper, we present a novel UDA method for\nmulti-modal cardiac image segmentation. The proposed method is based on\nadversarial learning and adapts network features between source and target\ndomain in different spaces. The paper introduces an end-to-end framework that\nintegrates: a) entropy minimisation, b) output feature space alignment and c) a\nnovel point-cloud shape adaptation based on the latent features learned by the\nsegmentation model. We validated our method on two cardiac datasets by adapting\nfrom the annotated source domain, bSSFP-MRI (balanced Steady-State Free\nProcession-MRI), to the unannotated target domain, LGE-MRI (Late-gadolinium\nenhance-MRI), for the multi-sequence dataset; and from MRI (source) to CT\n(target) for the cross-modality dataset. The results highlighted that by\nenforcing adversarial learning in different parts of the network, the proposed\nmethod delivered promising performance, compared to other SOTA methods.",
    "  Higher order differentiation was introduced in a cryptographic context by\nLai. Several attacks can be viewed in the context of higher order\ndifferentiations, amongst them the cube attack and the AIDA attack. All of the\nabove have been developed for the binary case.\n  We examine differentiation in larger fields, starting with the field $GF(p)$\nof integers modulo a prime $p$. We prove a number of results on differentiating\npolynomials over such fields and then apply these techniques to generalising\nthe cube attack to $GF(p)$. The crucial difference is that now the degree in\neach variable can be higher than one, and our proposed attack will\ndifferentiate several times with respect to each variable (unlike the classical\ncube attack and its larger field version described by Dinur and Shamir, both of\nwhich differentiate at most once with respect to each variable).\n  Finally we describe differentiation over finite fields $GF(p^m)$ with $p^m$\nelements and prove that it can be reduced to differentiation over $GF(p)$, so a\ncube attack over $GF(p^m)$ would be equivalent to cube attacks over $GF(p)$.\n",
    "Over the past decade, Deep Convolutional Neural Networks have been widely\nadopted for medical image segmentation and shown to achieve adequate\nperformance. However, due to the inherent inductive biases present in the\nconvolutional architectures, they lack understanding of long-range dependencies\nin the image. Recently proposed Transformer-based architectures that leverage\nself-attention mechanism encode long-range dependencies and learn\nrepresentations that are highly expressive. This motivates us to explore\nTransformer-based solutions and study the feasibility of using\nTransformer-based network architectures for medical image segmentation tasks.\nMajority of existing Transformer-based network architectures proposed for\nvision applications require large-scale datasets to train properly. However,\ncompared to the datasets for vision applications, for medical imaging the\nnumber of data samples is relatively low, making it difficult to efficiently\ntrain transformers for medical applications. To this end, we propose a Gated\nAxial-Attention model which extends the existing architectures by introducing\nan additional control mechanism in the self-attention module. Furthermore, to\ntrain the model effectively on medical images, we propose a Local-Global\ntraining strategy (LoGo) which further improves the performance. Specifically,\nwe operate on the whole image and patches to learn global and local features,\nrespectively. The proposed Medical Transformer (MedT) is evaluated on three\ndifferent medical image segmentation datasets and it is shown that it achieves\nbetter performance than the convolutional and other related transformer-based\narchitectures. Code: https://github.com/jeya-maria-jose/Medical-Transformer",
    "This paper addresses the domain shift problem for segmentation. As a\nsolution, we propose OLVA, a novel and lightweight unsupervised domain\nadaptation method based on a Variational Auto-Encoder (VAE) and Optimal\nTransport (OT) theory. Thanks to the VAE, our model learns a shared\ncross-domain latent space that follows a normal distribution, which reduces the\ndomain shift. To guarantee valid segmentations, our shared latent space is\ndesigned to model the shape rather than the intensity variations. We further\nrely on an OT loss to match and align the remaining discrepancy between the two\ndomains in the latent space. We demonstrate OLVA's effectiveness for the\nsegmentation of multiple cardiac structures on the public Multi-Modality Whole\nHeart Segmentation (MM-WHS) dataset, where the source domain consists of\nannotated 3D MR images and the unlabelled target domain of 3D CTs. Our results\nshow remarkable improvements with an additional margin of 12.5\\% dice score\nover concurrent generative training approaches.",
    "Image segmentation is a fundamental research topic in image processing and\ncomputer vision. In the last decades, researchers developed a large number of\nsegmentation algorithms for various applications. Amongst these algorithms, the\nNormalized cut (Ncut) segmentation method is widely applied due to its good\nperformance. The Ncut segmentation model is an optimization problem whose\nenergy is defined on a specifically designed graph. Thus, the segmentation\nresults of the existing Ncut method are largely dependent on a pre-constructed\nsimilarity measure on the graph since this measure is usually given empirically\nby users. This flaw will lead to some undesirable segmentation results. In this\npaper, we propose a Ncut-based segmentation algorithm by integrating an\nadaptive similarity measure and spatial regularization. The proposed model\ncombines the Parzen-Rosenblatt window method, non-local weights entropy, Ncut\nenergy, and regularizer of phase field in a variational framework. Our method\ncan adaptively update the similarity measure function by estimating some\nparameters. This adaptive procedure enables the proposed algorithm finding a\nbetter similarity measure for classification than the Ncut method. We provide\nsome mathematical interpretation of the proposed adaptive similarity from\nmulti-viewpoints such as statistics and convex optimization. In addition, the\nregularizer of phase field can guarantee that the proposed algorithm has a\nrobust performance in the presence of noise, and it can also rectify the\nsimilarity measure with a spatial priori. The well-posed theory such as the\nexistence of the minimizer for the proposed model is given in the paper.\nCompared with some existing segmentation methods such as the traditional\nNcut-based model and the classical Chan-Vese model, the numerical experiments\nshow that our method can provide promising segmentation results.",
    "  Text data is often seen as \"take-away\" materials with little noise and easy\nto process information. Main questions are how to get data and transform them\ninto a good document format. But data can be sensitive to noise oftenly called\nambiguities. Ambiguities are aware from a long time, mainly because polysemy is\nobvious in language and context is required to remove uncertainty. I claim in\nthis paper that syntactic context is not suffisant to improve interpretation.\nIn this paper I try to explain that firstly noise can come from natural data\nthemselves, even involving high technology, secondly texts, seen as verified\nbut meaningless, can spoil content of a corpus; it may lead to contradictions\nand background noise.\n",
    "The task of image segmentation is inherently noisy due to ambiguities\nregarding the exact location of boundaries between anatomical structures. We\nargue that this information can be extracted from the expert annotations at no\nextra cost, and when integrated into state-of-the-art neural networks, it can\nlead to improved calibration between soft probabilistic predictions and the\nunderlying uncertainty. We built upon label smoothing (LS) where a network is\ntrained on 'blurred' versions of the ground truth labels which has been shown\nto be effective for calibrating output predictions. However, LS is not taking\nthe local structure into account and results in overly smoothed predictions\nwith low confidence even for non-ambiguous regions. Here, we propose Spatially\nVarying Label Smoothing (SVLS), a soft labeling technique that captures the\nstructural uncertainty in semantic segmentation. SVLS also naturally lends\nitself to incorporate inter-rater uncertainty when multiple labelmaps are\navailable. The proposed approach is extensively validated on four clinical\nsegmentation tasks with different imaging modalities, number of classes and\nsingle and multi-rater expert annotations. The results demonstrate that SVLS,\ndespite its simplicity, obtains superior boundary prediction with improved\nuncertainty and model calibration.",
    "Medical image segmentation is inherently an ambiguous task due to factors\nsuch as partial volumes and variations in anatomical definitions. While in most\ncases the segmentation uncertainty is around the border of structures of\ninterest, there can also be considerable inter-rater differences. The class of\nconditional variational autoencoders (cVAE) offers a principled approach to\ninferring distributions over plausible segmentations that are conditioned on\ninput images. Segmentation uncertainty estimated from samples of such\ndistributions can be more informative than using pixel level probability\nscores. In this work, we propose a novel conditional generative model that is\nbased on conditional Normalizing Flow (cFlow). The basic idea is to increase\nthe expressivity of the cVAE by introducing a cFlow transformation step after\nthe encoder. This yields improved approximations of the latent posterior\ndistribution, allowing the model to capture richer segmentation variations.\nWith this we show that the quality and diversity of samples obtained from our\nconditional generative model is enhanced. Performance of our model, which we\ncall cFlow Net, is evaluated on two medical imaging datasets demonstrating\nsubstantial improvements in both qualitative and quantitative measures when\ncompared to a recent cVAE based model.",
    "Currently, developments of deep learning techniques are providing\ninstrumental to identify, classify, and quantify patterns in medical images.\nSegmentation is one of the important applications in medical image analysis. In\nthis regard, U-Net is the predominant approach to medical image segmentation\ntasks. However, we found that those U-Net based models have limitations in\nseveral aspects, for example, millions of parameters in the U-Net consuming\nconsiderable computation resource and memory, lack of global information, and\nmissing some tough objects. Therefore, we applied two modifications to improve\nthe U-Net model: 1) designed and added the dilated channel-wise CNN module, 2)\nsimplified the U shape network. Based on these two modifications, we proposed a\nnovel light-weight architecture -- Channel-wise Feature Pyramid Network for\nMedicine (CFPNet-M). To evaluate our method, we selected five datasets with\ndifferent modalities: thermography, electron microscopy, endoscopy, dermoscopy,\nand digital retinal images. And we compared its performance with several models\nhaving different parameter scales. This paper also involves our previous\nstudies of DC-UNet and some commonly used light-weight neural networks. We\napplied the Tanimoto similarity instead of the Jaccard index for gray-level\nimage measurements. By comparison, CFPNet-M achieves comparable segmentation\nresults on all five medical datasets with only 0.65 million parameters, which\nis about 2% of U-Net, and 8.8 MB memory. Meanwhile, the inference speed can\nreach 80 FPS on a single RTX 2070Ti GPU with the 256 by 192 pixels input size.",
    "  In the current hyper-connected era, modern Information and Communication\nTechnology systems form sophisticated networks where not only do people\ninteract with other people, but also machines take an increasingly visible and\nparticipatory role. Such human-machine networks (HMNs) are embedded in the\ndaily lives of people, both for personal and professional use. They can have a\nsignificant impact by producing synergy and innovations. The challenge in\ndesigning successful HMNs is that they cannot be developed and implemented in\nthe same manner as networks of machines nodes alone, nor following a wholly\nhuman-centric view of the network. The problem requires an interdisciplinary\napproach. Here, we review current research of relevance to HMNs across many\ndisciplines. Extending the previous theoretical concepts of socio-technical\nsystems, actor-network theory, cyber-physical-social systems, and social\nmachines, we concentrate on the interactions among humans and between humans\nand machines. We identify eight types of HMNs: public-resource computing,\ncrowdsourcing, web search engines, crowdsensing, online markets, social media,\nmultiplayer online games and virtual worlds, and mass collaboration. We\nsystematically select literature on each of these types and review it with a\nfocus on implications for designing HMNs. Moreover, we discuss risks associated\nwith HMNs and identify emerging design and development trends.\n",
    "  In a k-linear triangulated category (where k is a field) we show that the\nexistence of Auslander-Reiten triangles implies that objects are determined, up\nto shift, by knowing dimensions of homomorphisms between them. In most cases\nthe objects themselves are distinguished by this information, a conclusion\nwhich was also reached under slightly different hypotheses in a theorem of\nJensen, Su and Zimmermann. The approach is to consider bilinear forms on\nGrothendieck groups which are analogous to the Green ring of a finite group.\n  We specialize to the category of perfect complexes for a self-injective\nalgebra, for which the Auslander-Reiten quiver has a known shape. We\ncharacterize the position in the quiver of many kinds of perfect complexes,\nincluding those of lengths 1, 2 and 3, rigid complexes and truncated projective\nresolutions. We describe completely the quiver components which contain\nprojective modules. We obtain relationships between the homology of complexes\nat different places in the quiver, deducing that every self-injective algebra\nof radical length at least 3 has indecomposable perfect complexes with\narbitrarily large homology in any given degree. We find also that homology\nstabilizes away from the rim of the quiver. We show that when the algebra is\nsymmetric, one of the forms considered earlier is Hermitian, and this allows us\nto compute its values knowing them only on objects on the rim of the quiver.\n",
    "  Suppose you're on a game show, and you're given the choice of three doors:\nBehind one door is a car; behind the others, goats. You pick a door, say No. 1,\nand the host, who knows what's behind the doors, opens another door, say No. 3,\nwhich has a goat. He then says to you, ``Do you want to pick door No. 2?'' Is\nit to your advantage to switch your choice? The answer is ``yes'' but the\nliterature offers many reasons why this is the correct answer. The present\npaper argues that the most common reasoning found in introductory statistics\ntexts, depending on making a number of ``obvious'' or ``natural'' assumptions\nand then computing a conditional probability, is a classical example of\nsolution driven science. The best reason to switch is to be found in von\nNeumann's minimax theorem from game theory, rather than in Bayes' theorem.\n",
    "In this paper we present our system for human-in-the-loop video object\nsegmentation. The backbone of our system is a method for one-shot video object\nsegmentation. While fast, this method requires an accurate pixel-level\nsegmentation of one (or several) frames as input. As manually annotating such a\nsegmentation is impractical, we propose a deep interactive image segmentation\nmethod, that can accurately segment objects with only a handful of clicks. On\nthe GrabCut dataset, our method obtains 90% IOU with just 3.8 clicks on\naverage, setting the new state of the art. Furthermore, as our method\niteratively refines an initial segmentation, it can effectively correct frames\nwhere the video object segmentation fails, thus allowing users to quickly\nobtain high quality results even on challenging sequences. Finally, we\ninvestigate usage patterns and give insights in how many steps users take to\nannotate frames, what kind of corrections they provide, etc., thus giving\nimportant insights for further improving interactive video segmentation.",
    "  Take a sequence of couples $(G_n,K_n)_n$, where $G_n$ is a group and $K_n$ is\na sub-group of $G_n.$ Under some conditions, we are able to give a formula that\nshows the form of the structure coefficients that appear in the product of\ndouble-classes of $K_n$ in $G_n.$ We show how this can give us a similar result\nfor the structure coefficients of the centers of group algebras.\n  These formulas allow us to re-obtain the polynomiality property of the\nstructure coefficients in the cases of the center of the symmetric group\nalgebra and the Hecke algebra of the pair $(\\mathcal{S}_{2n},\\mathcal{B}_{n}).$\nWe also give a new polynomiality property for the structure coefficients of the\ncenter of the hyperoctahedral group algebra and the double-class algebra\n$\\mathbb{C}[diag(\\mathcal{S}_{n-1})\\setminus \\mathcal{S}_n\\times\n\\mathcal{S}^{opp}_{n-1}/ diag(\\mathcal{S}_{n-1})].$\n",
    "Recent advances in deep learning based image segmentation methods have\nenabled real-time performance with human-level accuracy. However, occasionally\neven the best method fails due to low image quality, artifacts or unexpected\nbehaviour of black box algorithms. Being able to predict segmentation quality\nin the absence of ground truth is of paramount importance in clinical practice,\nbut also in large-scale studies to avoid the inclusion of invalid data in\nsubsequent analysis.\n  In this work, we propose two approaches of real-time automated quality\ncontrol for cardiovascular MR segmentations using deep learning. First, we\ntrain a neural network on 12,880 samples to predict Dice Similarity\nCoefficients (DSC) on a per-case basis. We report a mean average error (MAE) of\n0.03 on 1,610 test samples and 97% binary classification accuracy for\nseparating low and high quality segmentations. Secondly, in the scenario where\nno manually annotated data is available, we train a network to predict DSC\nscores from estimated quality obtained via a reverse testing strategy. We\nreport an MAE=0.14 and 91% binary classification accuracy for this case.\nPredictions are obtained in real-time which, when combined with real-time\nsegmentation methods, enables instant feedback on whether an acquired scan is\nanalysable while the patient is still in the scanner. This further enables new\napplications of optimising image acquisition towards best possible analysis\nresults.",
    "Convolutional neural networks (CNN) have had unprecedented success in medical\nimaging and, in particular, in medical image segmentation. However, despite the\nfact that segmentation results are closer than ever to the inter-expert\nvariability, CNNs are not immune to producing anatomically inaccurate\nsegmentations, even when built upon a shape prior. In this paper, we present a\nframework for producing cardiac image segmentation maps that are guaranteed to\nrespect pre-defined anatomical criteria, while remaining within the\ninter-expert variability. The idea behind our method is to use a well-trained\nCNN, have it process cardiac images, identify the anatomically implausible\nresults and warp these results toward the closest anatomically valid cardiac\nshape. This warping procedure is carried out with a constrained variational\nautoencoder (cVAE) trained to learn a representation of valid cardiac shapes\nthrough a smooth, yet constrained, latent space. With this cVAE, we can project\nany implausible shape into the cardiac latent space and steer it toward the\nclosest correct shape. We tested our framework on short-axis MRI as well as\napical two and four-chamber view ultrasound images, two modalities for which\ncardiac shapes are drastically different. With our method, CNNs can now produce\nresults that are both within the inter-expert variability and always\nanatomically plausible without having to rely on a shape prior.",
    "Deep learning based image segmentation has achieved the state-of-the-art\nperformance in many medical applications such as lesion quantification, organ\ndetection, etc. However, most of the methods rely on supervised learning, which\nrequire a large set of high-quality labeled data. Data annotation is generally\nan extremely time-consuming process. To address this problem, we propose a\ngeneric semi-supervised learning framework for image segmentation based on a\ndeep convolutional neural network (DCNN). An encoder-decoder based DCNN is\ninitially trained using a few annotated training samples. This initially\ntrained model is then copied into sub-models and improved iteratively using\nrandom subsets of unlabeled data with pseudo labels generated from models\ntrained in the previous iteration. The number of sub-models is gradually\ndecreased to one in the final iteration. We evaluate the proposed method on a\npublic grand-challenge dataset for skin lesion segmentation. Our method is able\nto significantly improve beyond fully supervised model learning by\nincorporating unlabeled data.",
    "  A simple method is proposed for inclusion of inelastic effects (electron\nabsorption) in computations of low-energy electron reflectivity (LEER) spectra.\nThe theoretical spectra are formulated by matching of electron wavefunctions\nobtained from first-principles computations in a repeated vacuum-slab-vacuum\ngeometry. Inelastic effects are included by allowing these states to decay in\ntime in accordance with an imaginary term in the potential of the slab, and by\nmixing of the slab states in accordance with the same type of distribution as\noccurs in a free-electron model. LEER spectra are computed for various\ntwo-dimensional materials, including free-standing multilayer graphene,\ngraphene on copper substrates, and hexagonal boron nitride (h-BN) on cobalt\nsubstrates.\n",
    "The recent advancements in artificial intelligence (AI) combined with the\nextensive amount of data generated by today's clinical systems, has led to the\ndevelopment of imaging AI solutions across the whole value chain of medical\nimaging, including image reconstruction, medical image segmentation,\nimage-based diagnosis and treatment planning. Notwithstanding the successes and\nfuture potential of AI in medical imaging, many stakeholders are concerned of\nthe potential risks and ethical implications of imaging AI solutions, which are\nperceived as complex, opaque, and difficult to comprehend, utilise, and trust\nin critical clinical applications. Despite these concerns and risks, there are\ncurrently no concrete guidelines and best practices for guiding future AI\ndevelopments in medical imaging towards increased trust, safety and adoption.\nTo bridge this gap, this paper introduces a careful selection of guiding\nprinciples drawn from the accumulated experiences, consensus, and best\npractices from five large European projects on AI in Health Imaging. These\nguiding principles are named FUTURE-AI and its building blocks consist of (i)\nFairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness\nand (vi) Explainability. In a step-by-step approach, these guidelines are\nfurther translated into a framework of concrete recommendations for specifying,\ndeveloping, evaluating, and deploying technically, clinically and ethically\ntrustworthy AI solutions into clinical practice.",
    "  Computing is a high-level process of a physical system. Recent interest in\nnon-standard computing systems, including quantum and biological computers, has\nbrought this physical basis of computing to the forefront. There has been,\nhowever, no consensus on how to tell if a given physical system is acting as a\ncomputer or not; leading to confusion over novel computational devices, and\neven claims that every physical event is a computation. In this paper we\nintroduce a formal framework that can be used to determine whether or not a\nphysical system is performing a computation. We demonstrate how the abstract\ncomputational level interacts with the physical device level, drawing the\ncomparison with the use of mathematical models to represent physical objects in\nexperimental science. This powerful formulation allows a precise description of\nthe similarities between experiments, computation, simulation, and technology,\nleading to our central conclusion: physical computing is the use of a physical\nsystem to predict the outcome of an abstract evolution. We give conditions that\nmust be satisfied in order for computation to be occurring, and illustrate\nthese with a range of non-standard computing scenarios. The framework also\ncovers broader computing contexts, where there is no obvious human computer\nuser. We define the critical notion of a 'computational entity', and show the\nrole this plays in defining when computing is taking place in physical systems.\n",
    "  The Bounded Negativity Conjecture predicts that for every complex projective\nsurface $X$ there exists a number $b(X)$ such that $C^2\\geq -b(X)$ holds for\nall reduced curves $C\\subset X$. For birational surfaces $f:Y\\to X$ there have\nbeen introduced certain invariants (Harbourne constants) relating to the effect\nthe numbers $b(X)$, $b(Y)$ and the complexity of the map $f$. These invariants\nhave been studied previously when $f$ is the blowup of all singular points of\nan arrangement of lines in ${\\mathbb P}^2$, of conics and of cubics. In the\npresent note we extend these considerations to blowups of ${\\mathbb P}^2$ at\nsingular points of arrangements of curves of arbitrary degree $d$. We also\nconsiderably generalize and modify the approach witnessed so far and study\ntransversal arrangements of sufficiently positive curves on arbitrary surfaces\nwith the non-negative Kodaira dimension.\n",
    "We propose to adapt segmentation networks with a constrained formulation,\nwhich embeds domain-invariant prior knowledge about the segmentation regions.\nSuch knowledge may take the form of simple anatomical information, e.g.,\nstructure size or shape, estimated from source samples or known a priori. Our\nmethod imposes domain-invariant inequality constraints on the network outputs\nof unlabeled target samples. It implicitly matches prediction statistics\nbetween target and source domains with permitted uncertainty of prior\nknowledge. We address our constrained problem with a differentiable penalty,\nfully suited for standard stochastic gradient descent approaches, removing the\nneed for computationally expensive Lagrangian optimization with dual\nprojections. Unlike current two-step adversarial training, our formulation is\nbased on a single loss in a single network, which simplifies adaptation by\navoiding extra adversarial steps, while improving convergence and quality of\ntraining.\n  The comparison of our approach with state-of-the-art adversarial methods\nreveals substantially better performance on the challenging task of adapting\nspine segmentation across different MRI modalities. Our results also show a\nrobustness to imprecision of size priors, approaching the accuracy of a fully\nsupervised model trained directly in a target domain.Our method can be readily\nused for various constraints and segmentation problems.",
    "  Functional integrals can be defined on topological groups in terms of\nfamilies of locally compact topological groups and their associated\nBanach-valued Haar integrals. The definition forgoes the goal of constructing a\ngenuine measure on a space of functions, and instead provides for a topological\nrealization of localization in the infinite-dimensional domain. This yields\nmeasurable subspaces that characterize meaningful functional integrals and a\nscheme that possesses significant potential for representing non-commutative\nBanach algebras suitable for mathematical physics applications. The framework\nincludes, within a broader structure, other successful approaches to define\nfunctional integrals in restricted cases, and it suggests new and potentially\nuseful functional integrals that go beyond the standard Gaussian case. In\nparticular, functional integrals based on skew-Hermitian and K\\\"{a}hler\nquadratic forms are defined and developed. Also defined are gamma-type and\nPoisson-type functional integrals based on linear forms suggested by the gamma\nprobability distribution. These are expected to play an important role in\ngenerating $C^\\ast$-algebras of quantum systems. Several applications and\nimplications are presented.\n",
    "In this work, we address the task of referring image segmentation (RIS),\nwhich aims at predicting a segmentation mask for the object described by a\nnatural language expression. Most existing methods focus on establishing\nunidirectional or directional relationships between visual and linguistic\nfeatures to associate two modalities together, while the multi-scale context is\nignored or insufficiently modeled. Multi-scale context is crucial to localize\nand segment those objects that have large scale variations during the\nmulti-modal fusion process. To solve this problem, we propose a simple yet\neffective Cascaded Multi-modal Fusion (CMF) module, which stacks multiple\natrous convolutional layers in parallel and further introduces a cascaded\nbranch to fuse visual and linguistic features. The cascaded branch can\nprogressively integrate multi-scale contextual information and facilitate the\nalignment of two modalities during the multi-modal fusion process. Experimental\nresults on four benchmark datasets demonstrate that our method outperforms most\nstate-of-the-art methods. Code is available at\nhttps://github.com/jianhua2022/CMF-Refseg.",
    "  We study the 3-algebraic structure involved in the recently shown M2-branes\nworldvolume gauge theories. We first extend an arbitrary finite dimensional\n3-algebra into an infinite dimensional 3-algebra by adding a mode number to\neach generator. A unique central charge in the algebra of gauge transformations\nappears naturally in this extension. We present an infinite dimensional\nextended 3-algebra with a general metric and also a different extension with a\nLorentzian metric. We then study ordinary finite dimensional 3-algebras with\ndifferent signatures of the metric, focusing on the cases with a negative\neigenvalue and the cases with a zero eigenvalue. In the latter cases we present\na new algebra, whose corresponding theory is a decoupled abelian gauge theory\ntogether with a free theory with global gauge symmetry, and there is no\nnegative kinetic term from this algebra.\n",
    "  We use Minkowski Functionals to explore the presence of non-Gaussian\nsignatures in simulated cosmic microwave background (CMB) maps. Precisely, we\nanalyse the non-Gaussianities produced from the angular power spectra emerging\nfrom a class of inflationary models with a primordial step-like potential. This\nclass of models are able to perform the best-fit of the low-$\\ell$ `features',\nrevealed first in the CMB angular power spectrum by the WMAP experiment and\nthen confirmed by the Planck collaboration maps. Indeed, such models generate\noscillatory features in the primordial power spectrum of scalar perturbations,\nthat are then imprinted in the large scales of the CMB field. Interestingly, we\ndiscover Gaussian deviations in the CMB maps simulated from the power spectra\nproduced by these models, as compared with Gaussian $\\Lambda$CDM maps.\nMoreover, we also show that the kind and level of the non-Gaussianities\nproduced in these simulated CMB maps are compatible with that found in the four\nforeground-cleaned Planck maps. Our results indicate that inflationary models\nwith a step-like potential are not only able to improve the best-fit respect to\nthe $\\Lambda$CDM model accounting well for the `features' observed in the CMB\nangular power spectrum, but also suggesting a possible origin for certain\nnon-Gaussian signatures observed in the Planck data.\n",
    "  We have extended classical pattern avoidance to a new structure: multiple\ntask-precedence posets whose Hasse diagrams have three levels, which we will\ncall diamonds. The vertices of each diamond are assigned labels which are\ncompatible with the poset. A corresponding permutation is formed by reading\nthese labels by increasing levels, and then from left to right. We used Sage to\nform enumerative conjectures for the associated permutations avoiding\ncollections of patterns of length three, which we then proved. We have\ndiscovered a bijection between diamonds avoiding 132 and certain generalized\nDyck paths. We have also found the generating function for descents, and\ntherefore the number of avoiders, in these permutations for the majority of\ncollections of patterns of length three. An interesting application of this\nwork (and the motivating example) can be found when task-precedence posets\nrepresent warehouse package fulfillment by robots, in which case avoidance of\nboth 231 and 321 ensures we never stack two heavier packages on top of a\nlighter package.\n",
    "The medical image is characterized by the inter-class indistinction, high\nvariability, and noise, where the recognition of pixels is challenging. Unlike\nprevious self-attention based methods that capture context information from one\nlevel, we reformulate the self-attention mechanism from the view of the\nhigh-order graph and propose a novel method, namely Hierarchical Attention\nNetwork (HANet), to address the problem of medical image segmentation.\nConcretely, an HA module embedded in the HANet captures context information\nfrom neighbors of multiple levels, where these neighbors are extracted from the\nhigh-order graph. In the high-order graph, there will be an edge between two\nnodes only if the correlation between them is high enough, which naturally\nreduces the noisy attention information caused by the inter-class\nindistinction. The proposed HA module is robust to the variance of input and\ncan be flexibly inserted into the existing convolution neural networks. We\nconduct experiments on three medical image segmentation tasks including optic\ndisc/cup segmentation, blood vessel segmentation, and lung segmentation.\nExtensive results show our method is more effective and robust than the\nexisting state-of-the-art methods.",
    "Image segmentation aims at identifying regions of interest within an image,\nby grouping pixels according to their properties. This task resembles the\nstatistical one of clustering, yet many standard clustering methods fail to\nmeet the basic requirements of image segmentation: segment shapes are often\nbiased toward predetermined shapes and their number is rarely determined\nautomatically. Nonparametric clustering is, in principle, free from these\nlimitations and turns out to be particularly suitable for the task of image\nsegmentation. This is also witnessed by several operational analogies, as, for\ninstance, the resort to topological data analysis and spatial tessellation in\nboth the frameworks. We discuss the application of nonparametric clustering to\nimage segmentation and provide an algorithm specific for this task. Pixel\nsimilarity is evaluated in terms of density of the color representation and the\nadjacency structure of the pixels is exploited to introduce a simple, yet\neffective method to identify image segments as disconnected high-density\nregions. The proposed method works both to segment an image and to detect its\nboundaries and can be seen as a generalization to color images of the class of\nthresholding methods.",
    "  The height of a piecewise-testable language $L$ is the maximum length of the\nwords needed to define $L$ by excluding and requiring given subwords. The\nheight of $L$ is an important descriptive complexity measure that has not yet\nbeen investigated in a systematic way. This article develops a series of new\ntechniques for bounding the height of finite languages and of languages\nobtained by taking closures by subwords, superwords and related operations.\n  As an application of these results, we show that\n$\\mathsf{FO}^2(A^*,\\sqsubseteq)$, the two-variable fragment of the first-order\nlogic of sequences with the subword ordering, can only express\npiecewise-testable properties and has elementary complexity.\n",
    "  It is well-known that simple type theory is complete with respect to\nnon-standard set-valued models. Completeness for standard models only holds\nwith respect to certain extended classes of models, e.g., the class of\ncartesian closed categories. Similarly, dependent type theory is complete for\nlocally cartesian closed categories. However, it is usually difficult to\nestablish the coherence of interpretations of dependent type theory, i.e., to\nshow that the interpretations of equal expressions are indeed equal. Several\nclasses of models have been used to remedy this problem. We contribute to this\ninvestigation by giving a semantics that is standard, coherent, and\nsufficiently general for completeness while remaining relatively easy to\ncompute with. Our models interpret types of Martin-L\\\"of's extensional\ndependent type theory as sets indexed over posets or, equivalently, as\nfibrations over posets. This semantics can be seen as a generalization to\ndependent type theory of the interpretation of intuitionistic first-order logic\nin Kripke models. This yields a simple coherent model theory, with respect to\nwhich simple and dependent type theory are sound and complete.\n",
    "Automated digital histopathology image segmentation is an important task to\nhelp pathologists diagnose tumors and cancer subtypes. For pathological\ndiagnosis of cancer subtypes, pathologists usually change the magnification of\nwhole-slide images (WSI) viewers. A key assumption is that the importance of\nthe magnifications depends on the characteristics of the input image, such as\ncancer subtypes. In this paper, we propose a novel semantic segmentation\nmethod, called Adaptive-Weighting-Multi-Field-of-View-CNN (AWMF-CNN), that can\nadaptively use image features from images with different magnifications to\nsegment multiple cancer subtype regions in the input image. The proposed method\naggregates several expert CNNs for images of different magnifications by\nadaptively changing the weight of each expert depending on the input image. It\nleverages information in the images with different magnifications that might be\nuseful for identifying the subtypes. It outperformed other state-of-the-art\nmethods in experiments.",
    "  The problem of multiple sensors simultaneously acquiring measurements of a\nsingle object can be found in many applications. In this paper, we present the\noptimal recovery guarantees for the recovery of compressible signals from\nmulti-sensor measurements using compressed sensing. In the first half of the\npaper, we present both uniform and nonuniform recovery guarantees for the\nconventional sparse signal model in a so-called distinct sensing scenario. In\nthe second half, using the so-called sparse and distributed signal model, we\npresent nonuniform recovery guarantees which effectively broaden the class of\nsensing scenarios for which optimal recovery is possible, including to the\nso-called identical sampling scenario. To verify our recovery guarantees we\nprovide several numerical results including phase transition curves and\nnumerically-computed bounds.\n",
    "  This paper introduces a class of mixed-effects models for joint modeling of\nspatially correlated intensity variation and warping variation in 2D images.\nSpatially correlated intensity variation and warp variation are modeled as\nrandom effects, resulting in a nonlinear mixed-effects model that enables\nsimultaneous estimation of template and model parameters by optimization of the\nlikelihood function. We propose an algorithm for fitting the model which\nalternates estimation of variance parameters and image registration. This\napproach avoids the potential estimation bias in the template estimate that\narises when treating registration as a preprocessing step. We apply the model\nto datasets of facial images and 2D brain magnetic resonance images to\nillustrate the simultaneous estimation and prediction of intensity and warp\neffects.\n",
    "Compared to the general semantic segmentation problem, portrait segmentation\nhas higher precision requirement on boundary area. However, this problem has\nnot been well studied in previous works. In this paper, we propose a\nboundary-sensitive deep neural network (BSN) for portrait segmentation. BSN\nintroduces three novel techniques. First, an individual boundary-sensitive\nkernel is proposed by dilating the contour line and assigning the boundary\npixels with multi-class labels. Second, a global boundary-sensitive kernel is\nemployed as a position sensitive prior to further constrain the overall shape\nof the segmentation map. Third, we train a boundary-sensitive attribute\nclassifier jointly with the segmentation network to reinforce the network with\nsemantic boundary shape information. We have evaluated BSN on the current\nlargest public portrait segmentation dataset, i.e, the PFCN dataset, as well as\nthe portrait images collected from other three popular image segmentation\ndatasets: COCO, COCO-Stuff, and PASCAL VOC. Our method achieves the superior\nquantitative and qualitative performance over state-of-the-arts on all the\ndatasets, especially on the boundary area.",
    "In this paper, we demonstrate the ability to discriminate between cultivated\nmaize plant and grass or grass-like weed image segments using the context\nsurrounding the image segments. While convolutional neural networks have\nbrought state of the art accuracies within object detection, errors arise when\nobjects in different classes share similar features. This scenario often occurs\nwhen objects in images are viewed at too small of a scale to discern distinct\ndifferences in features, causing images to be incorrectly classified or\nlocalized. To solve this problem, we will explore using context when\nclassifying image segments. This technique involves feeding a convolutional\nneural network a central square image along with a border of its direct\nsurroundings at train and test times. This means that although images are\nlabelled at a smaller scale to preserve accurate localization, the network\nclassifies the images and learns features that include the wider context. We\ndemonstrate the benefits of this context technique in the object detection task\nthrough a case study of grass (foxtail) and grass-like (yellow nutsedge) weed\ndetection in maize fields. In this standard situation, adding context alone\nnearly halved the error of the neural network from 7.1% to 4.3%. After only one\nepoch with context, the network also achieved a higher accuracy than the\nnetwork without context did after 50 epochs. The benefits of using the context\ntechnique are likely to particularly evident in agricultural contexts in which\nparts (such as leaves) of several plants may appear similar when not taking\ninto account the context in which those parts appear.",
    "  An information theoretic approach to bounds in superconformal field theories\nis proposed. It is proved that the supersymmetric R\\'enyi entropy $\\bar\nS_\\alpha$ is a monotonically decreasing function of $\\alpha$ and\n$(\\alpha-1)\\bar S_\\alpha$ is a concave function of $\\alpha$. Under the\nassumption that the thermal entropy associated with the \"replica trick\" time\ncircle is bounded from below by the charge at $\\alpha\\to\\infty$, it is further\nproved that both ${\\alpha-1\\over \\alpha}\\bar S_\\alpha$ and $(\\alpha-1)\\bar\nS_\\alpha$ monotonically increase as functions of $\\alpha$. Because $\\bar\nS_\\alpha$ enjoys universal relations with the Weyl anomaly coefficients in\neven-dimensional superconformal field theories, one therefore obtains a set of\nbounds on these coefficients by imposing the inequalities of $\\bar S_\\alpha$.\nSome of the bounds coincide with Hofman-Maldacena bounds and the others are\nnew. We also check the inequalities for examples in odd-dimensions.\n",
    "  In this brief overview we discuss the principal features of real space\npairing as expressed via corresponding low-energy (t-J or periodic\nAnderson-Kondo) effective Hamiltonian, as well as consider concrete properties\nof those unconventional superconductors. We also rise the basic question of\nstatistical consistency within the so-called renormalized mean-field theory. In\nparticular, we provide the phase diagrams encompassing the stable magnetic and\nsuperconducting states. We interpret real space pairing as correlated motion of\nfermion pair coupled by short-range exchange interaction of magnitude J\ncomparable to the particle renormalized band energy $\\sim tx$, where $x$ is the\ncarrier number per site. We also discuss briefly the difference between the\nreal-space and the paramagnon - mediated sources of superconductivity. The\npaper concentrates both on recent novel results obtained in our research group,\nas well as puts the theoretical concepts in a conceptual as well as historical\nperspective. No slave-bosons are required to formulate the present approach.\n",
    "Computer vision has shown promising results in medical image processing.\nPneumothorax is a deadly condition and if not diagnosed and treated at time\nthen it causes death. It can be diagnosed with chest X-ray images. We need an\nexpert and experienced radiologist to predict whether a person is suffering\nfrom pneumothorax or not by looking at the chest X-ray images. Everyone does\nnot have access to such a facility. Moreover, in some cases, we need quick\ndiagnoses. So we propose an image segmentation model to predict and give the\noutput a mask that will assist the doctor in taking this crucial decision. Deep\nLearning has proved their worth in many areas and outperformed man\nstate-of-the-art models. We want to use the power of these deep learning model\nto solve this problem. We have used U-net [13] architecture with ResNet [17] as\na backbone and achieved promising results. U-net [13] performs very well in\nmedical image processing and semantic segmentation. Our problem falls in the\nsemantic segmentation category.",
    "Background: Cardiac MRI derived biventricular mass and function parameters,\nsuch as end-systolic volume (ESV), end-diastolic volume (EDV), ejection\nfraction (EF), stroke volume (SV), and ventricular mass (VM) are clinically\nwell established. Image segmentation can be challenging and time-consuming, due\nto the complex anatomy of the human heart.\n  Objectives: This study introduces $\\nu$-net (/nju:n$\\varepsilon$t/) -- a deep\nlearning approach allowing for fully-automated high quality segmentation of\nright (RV) and left ventricular (LV) endocardium and epicardium for extraction\nof cardiac function parameters.\n  Methods: A set consisting of 253 manually segmented cases has been used to\ntrain a deep neural network. Subsequently, the network has been evaluated on 4\ndifferent multicenter data sets with a total of over 1000 cases.\n  Results: For LV EF the intraclass correlation coefficient (ICC) is 98, 95,\nand 80 % (95 %), and for RV EF 96, and 87 % (80 %) on the respective data sets\n(human expert ICCs reported in parenthesis). The LV VM ICC is 95, and 94 % (84\n%), and the RV VM ICC is 83, and 83 % (54 %). This study proposes a simple\nadjustment procedure, allowing for the adaptation to distinct segmentation\nphilosophies. $\\nu$-net exhibits state of-the-art performance in terms of dice\ncoefficient.\n  Conclusions: Biventricular mass and function parameters can be determined\nreliably in high quality by applying a deep neural network for cardiac MRI\nsegmentation, especially in the anatomically complex right ventricle. Adaption\nto individual segmentation styles by applying a simple adjustment procedure is\nviable, allowing for the processing of novel data without time-consuming\nadditional training.",
    "We present a method for reconstructing images viewed by observers based only\non their eye movements. By exploring the relationships between gaze patterns\nand image stimuli, the \"What Are You Looking At?\" (WAYLA) system learns to\nsynthesize photo-realistic images that are similar to the original pictures\nbeing viewed. The WAYLA approach is based on the Conditional Generative\nAdversarial Network (Conditional GAN) image-to-image translation technique of\nIsola et al. We consider two specific applications - the first, of\nreconstructing newspaper images from gaze heat maps, and the second, of\ndetailed reconstruction of images containing only text. The newspaper image\nreconstruction process is divided into two image-to-image translation\noperations, the first mapping gaze heat maps into image segmentations, and the\nsecond mapping the generated segmentation into a newspaper image. We validate\nthe performance of our approach using various evaluation metrics, along with\nhuman visual inspection. All results confirm the ability of our network to\nperform image generation tasks using eye tracking data.",
    "In the recent years, convolutional neural networks have transformed the field\nof medical image analysis due to their capacity to learn discriminative image\nfeatures for a variety of classification and regression tasks. However,\nsuccessfully learning these features requires a large amount of manually\nannotated data, which is expensive to acquire and limited by the available\nresources of expert image analysts. Therefore, unsupervised, weakly-supervised\nand self-supervised feature learning techniques receive a lot of attention,\nwhich aim to utilise the vast amount of available data, while at the same time\navoid or substantially reduce the effort of manual annotation. In this paper,\nwe propose a novel way for training a cardiac MR image segmentation network, in\nwhich features are learnt in a self-supervised manner by predicting anatomical\npositions. The anatomical positions serve as a supervisory signal and do not\nrequire extra manual annotation. We demonstrate that this seemingly simple task\nprovides a strong signal for feature learning and with self-supervised\nlearning, we achieve a high segmentation accuracy that is better than or\ncomparable to a U-net trained from scratch, especially at a small data setting.\nWhen only five annotated subjects are available, the proposed method improves\nthe mean Dice metric from 0.811 to 0.852 for short-axis image segmentation,\ncompared to the baseline U-net.",
    "Medical image segmentation plays an essential role in developing\ncomputer-assisted diagnosis and therapy systems, yet still faces many\nchallenges. In the past few years, the popular encoder-decoder architectures\nbased on CNNs (e.g., U-Net) have been successfully applied in the task of\nmedical image segmentation. However, due to the locality of convolution\noperations, they demonstrate limitations in learning global context and\nlong-range spatial relations. Recently, several researchers try to introduce\ntransformers to both the encoder and decoder components with promising results,\nbut the efficiency requires further improvement due to the high computational\ncomplexity of transformers. In this paper, we propose LeViT-UNet, which\nintegrates a LeViT Transformer module into the U-Net architecture, for fast and\naccurate medical image segmentation. Specifically, we use LeViT as the encoder\nof the LeViT-UNet, which better trades off the accuracy and efficiency of the\nTransformer block. Moreover, multi-scale feature maps from transformer blocks\nand convolutional blocks of LeViT are passed into the decoder via\nskip-connection, which can effectively reuse the spatial information of the\nfeature maps. Our experiments indicate that the proposed LeViT-UNet achieves\nbetter performance comparing to various competing methods on several\nchallenging medical image segmentation benchmarks including Synapse and ACDC.\nCode and models will be publicly available at\nhttps://github.com/apple1986/LeViT_UNet.",
    "We propose adversarial constrained-CNN loss, a new paradigm of\nconstrained-CNN loss methods, for weakly supervised medical image segmentation.\nIn the new paradigm, prior knowledge is encoded and depicted by reference\nmasks, and is further employed to impose constraints on segmentation outputs\nthrough adversarial learning with reference masks. Unlike pseudo label methods\nfor weakly supervised segmentation, such reference masks are used to train a\ndiscriminator rather than a segmentation network, and thus are not required to\nbe paired with specific images. Our new paradigm not only greatly facilitates\nimposing prior knowledge on network's outputs, but also provides stronger and\nhigher-order constraints, i.e., distribution approximation, through adversarial\nlearning. Extensive experiments involving different medical modalities,\ndifferent anatomical structures, different topologies of the object of\ninterest, different levels of prior knowledge and weakly supervised annotations\nwith different annotation ratios is conducted to evaluate our ACCL method.\nConsistently superior segmentation results over the size constrained-CNN loss\nmethod have been achieved, some of which are close to the results of full\nsupervision, thus fully verifying the effectiveness and generalization of our\nmethod. Specifically, we report an average Dice score of 75.4% with an average\nannotation ratio of 0.65%, surpassing the prior art, i.e., the size\nconstrained-CNN loss method, by a large margin of 11.4%. Our codes are made\npublicly available at https://github.com/PengyiZhang/ACCL.",
    "Pixel-wise segmentation is one of the most data and annotation hungry tasks\nin our field. Providing representative and accurate annotations is often\nmission-critical especially for challenging medical applications. In this\npaper, we propose a semi-weakly supervised segmentation algorithm to overcome\nthis barrier. Our approach is based on a new formulation of deep supervision\nand student-teacher model and allows for easy integration of different\nsupervision signals. In contrast to previous work, we show that care has to be\ntaken how deep supervision is integrated in lower layers and we present\nmulti-label deep supervision as the most important secret ingredient for\nsuccess. With our novel training regime for segmentation that flexibly makes\nuse of images that are either fully labeled, marked with bounding boxes, just\nglobal labels, or not at all, we are able to cut the requirement for expensive\nlabels by 94.22% - narrowing the gap to the best fully supervised baseline to\nonly 5% mean IoU. Our approach is validated by extensive experiments on retinal\nfluid segmentation and we provide an in-depth analysis of the anticipated\neffect each annotation type can have in boosting segmentation performance.",
    "In this paper we propose a CNN architecture for semantic image segmentation.\nWe introduce a new 'bilateral inception' module that can be inserted in\nexisting CNN architectures and performs bilateral filtering, at multiple\nfeature-scales, between superpixels in an image. The feature spaces for\nbilateral filtering and other parameters of the module are learned end-to-end\nusing standard backpropagation techniques. The bilateral inception module\naddresses two issues that arise with general CNN segmentation architectures.\nFirst, this module propagates information between (super) pixels while\nrespecting image edges, thus using the structured information of the problem\nfor improved results. Second, the layer recovers a full resolution segmentation\nresult from the lower resolution solution of a CNN. In the experiments, we\nmodify several existing CNN architectures by inserting our inception module\nbetween the last CNN (1x1 convolution) layers. Empirical results on three\ndifferent datasets show reliable improvements not only in comparison to the\nbaseline networks, but also in comparison to several dense-pixel prediction\ntechniques such as CRFs, while being competitive in time.",
    "  Monogamy is a defining feature of entanglement, having far reaching\napplications. Recently, Regula \\textit{et.al.} in Phys. Rev. Lett.\n\\textbf{113}, 110501(2014) have proposed a stronger version of monogamy\nrelation for concurrence. We have extended the strong monogamy inequality for\nanother entanglement measure, viz., negativity. In particular, we have\nconcentrated on four-qubit system and provided a detail study on the status of\nstrong monogamy on pure states. Further, we have analytically provided some\nclasses of states for which negativity and squared negativity satisfy strong\nmonogamy. Numerical evidences have also been shown in proper places. Our\nanalysis also provides cases where strong monogamy is violated.\n",
    "  This is a review on subgaussian sequences of random variables, prepared for\nthe Mediterranean Institute for the Mathematical Sciences (MIMS). We first\ndescribe the main examples of such sequences. Then we focus on examples coming\nfrom the harmonic analysis of Fourier series and we describe the connection of\nsubgaussian sequences of characters on the unidimensional torus (or any compact\nAbelian group) with Sidon sets. We explain the main combinatorial open problem\nconcerning such subgaussian sequences. We present the answer to the analogous\nquestion for subgaussian bounded mean oscillation (BMO) sequences on the unit\ncircle. Lastly, we describe several very recent results that provide a\ngeneralization of the preceding ones when the trigonometric system (or its\nanalogue on a compact Abelian group) is replaced by an arbitrary orthonormal\nsystem bounded in $L_\\infty$.\n",
    "  We develop normalisation by evaluation (NBE) for dependent types based on\npresheaf categories. Our construction is formulated in the metalanguage of type\ntheory using quotient inductive types. We use a typed presentation hence there\nare no preterms or realizers in our construction, and every construction\nrespects the conversion relation. NBE for simple types uses a logical relation\nbetween the syntax and the presheaf interpretation. In our construction, we\nmerge the presheaf interpretation and the logical relation into a\nproof-relevant logical predicate. We prove normalisation, completeness,\nstability and decidability of definitional equality. Most of the constructions\nwere formalized in Agda.\n",
    "The state-of-the-art method for automatically segmenting white matter bundles\nin diffusion-weighted MRI is tractography in conjunction with streamline\ncluster selection. This process involves long chains of processing steps which\nare not only computationally expensive but also complex to setup and tedious\nwith respect to quality control. Direct bundle segmentation methods treat the\ntask as a traditional image segmentation problem. While they so far did not\ndeliver competitive results, they can potentially mitigate many of the\nmentioned issues. We present a novel supervised approach for direct tract\nsegmentation that shows major performance gains. It builds upon a stacked U-Net\narchitecture which is trained on manual bundle segmentations from Human\nConnectome Project subjects. We evaluate our approach \\textit{in vivo} as well\nas \\textit{in silico} using the ISMRM 2015 Tractography Challenge phantom\ndataset. We achieve human segmentation performance and a major performance gain\nover previous pipelines. We show how the learned spatial priors efficiently\nguide the segmentation even at lower image qualities with little quality loss.",
    "Recently, Deep-Neural-Network (DNN) based edge prediction is progressing\nfast. Although the DNN based schemes outperform the traditional edge detectors,\nthey have much higher computational complexity. It could be that the DNN based\nedge detectors often adopt the neural net structures designed for high-level\ncomputer vision tasks, such as image segmentation and object recognition. Edge\ndetection is a rather local and simple job, the over-complicated architecture\nand massive parameters may be unnecessary. Therefore, we propose a traditional\nmethod inspired framework to produce good edges with minimal complexity. We\nsimplify the network architecture to include Feature Extractor, Enrichment, and\nSummarizer, which roughly correspond to gradient, low pass filter, and pixel\nconnection in the traditional edge detection schemes. The proposed structure\ncan effectively reduce the complexity and retain the edge prediction quality.\nOur TIN2 (Traditional Inspired Network) model has an accuracy higher than the\nrecent BDCN2 (Bi-Directional Cascade Network) but with a smaller model.",
    "Ferrograph image segmentation is of significance for obtaining features of\nwear particles. However, wear particles are usually overlapped in the form of\ndebris chains, which makes challenges to segment wear debris. An overlapping\nwear particle segmentation network (OWPSNet) is proposed in this study to\nsegment the overlapped debris chains. The proposed deep learning model includes\nthree parts: a region segmentation network, an edge detection network and a\nfeature refine module. The region segmentation network is an improved U shape\nnetwork, and it is applied to separate the wear debris form background of\nferrograph image. The edge detection network is used to detect the edges of\nwear particles. Then, the feature refine module combines low-level features and\nhigh-level semantic features to obtain the final results. In order to solve the\nproblem of sample imbalance, we proposed a square dice loss function to\noptimize the model. Finally, extensive experiments have been carried out on a\nferrograph image dataset. Results show that the proposed model is capable of\nseparating overlapping wear particles. Moreover, the proposed square dice loss\nfunction can improve the segmentation results, especially for the segmentation\nresults of wear particle edge.",
    "Automatic parsing of anatomical objects in X-ray images is critical to many\nclinical applications in particular towards image-guided invention and workflow\nautomation. Existing deep network models require a large amount of labeled\ndata. However, obtaining accurate pixel-wise labeling in X-ray images relies\nheavily on skilled clinicians due to the large overlaps of anatomy and the\ncomplex texture patterns. On the other hand, organs in 3D CT scans preserve\nclearer structures as well as sharper boundaries and thus can be easily\ndelineated. In this paper, we propose a novel model framework for learning\nautomatic X-ray image parsing from labeled CT scans. Specifically, a Dense\nImage-to-Image network (DI2I) for multi-organ segmentation is first trained on\nX-ray like Digitally Reconstructed Radiographs (DRRs) rendered from 3D CT\nvolumes. Then we introduce a Task Driven Generative Adversarial Network\n(TD-GAN) architecture to achieve simultaneous style transfer and parsing for\nunseen real X-ray images. TD-GAN consists of a modified cycle-GAN substructure\nfor pixel-to-pixel translation between DRRs and X-ray images and an added\nmodule leveraging the pre-trained DI2I to enforce segmentation consistency. The\nTD-GAN framework is general and can be easily adapted to other learning tasks.\nIn the numerical experiments, we validate the proposed model on 815 DRRs and\n153 topograms. While the vanilla DI2I without any adaptation fails completely\non segmenting the topograms, the proposed model does not require any topogram\nlabels and is able to provide a promising average dice of 85% which achieves\nthe same level accuracy of supervised training (88%).",
    "Contrastive Learning (CL) is a recent representation learning approach, which\nencourages inter-class separability and intra-class compactness in learned\nimage representations. Since medical images often contain multiple semantic\nclasses in an image, using CL to learn representations of local features (as\nopposed to global) is important. In this work, we present a novel\nsemi-supervised 2D medical segmentation solution that applies CL on image\npatches, instead of full images. These patches are meaningfully constructed\nusing the semantic information of different classes obtained via pseudo\nlabeling. We also propose a novel consistency regularization (CR) scheme, which\nworks in synergy with CL. It addresses the problem of confirmation bias, and\nencourages better clustering in the feature space. We evaluate our method on\nfour public medical segmentation datasets and a novel histopathology dataset\nthat we introduce. Our method obtains consistent improvements over\nstate-of-the-art semi-supervised segmentation approaches for all datasets.",
    "  In this paper, we numerically study the ground and first excited states of\nthe fractional Schrodinger equation in an infinite potential well. Due to the\nnon-locality of the fractional Laplacian, it is challenging to find the\neigenvalues and eigenfunctions of the fractional Schrodinger equation either\nanalytically or numerically. We first introduce a fractional gradient flow with\ndiscrete normalization and then discretize it by using the trapezoidal type\nquadrature rule in space and the semi-implicit Euler method in time. Our method\ncan be used to compute the ground and first excited states not only in the\nlinear cases but also in the nonlinear cases. Moreover, it can be generalized\nto solve the fractional partial differential equations (PDEs) with Riesz\nfractional derivatives in space. Our numerical results suggest that the\neigenfunctions of the fractional Schrodinger equation in an infinite potential\nwell are significantly different from those of the standard (non-fractional)\nSchrodinger equation. In addition, we find that the strong nonlocal\ninteractions represented by the fractional Laplacian can lead to a large\nscattering of particles inside of the potential well. Compared to the ground\nstates, the scattering of particles in the first excited states is larger.\nFurthermore, boundary layers emerge in the ground states and additionally inner\nlayers exist in the first excited states of the fractional nonlinear\nSchrodinger equation.\n",
    "  We define a weakly threshold sequence to be a degree sequence\n$d=(d_1,\\dots,d_n)$ of a graph having the property that $\\sum_{i \\leq k} d_i\n\\geq k(k-1)+\\sum_{i > k} \\min\\{k,d_i\\} - 1$ for all positive $k \\leq\n\\max\\{i:d_i \\geq i-1\\}$. The weakly threshold graphs are the realizations of\nthe weakly threshold sequences. The weakly threshold graphs properly include\nthe threshold graphs and satisfy pleasing extensions of many properties of\nthreshold graphs. We demonstrate a majorization property of weakly threshold\nsequences and an iterative construction algorithm for weakly threshold graphs,\nas well as a forbidden induced subgraph characterization. We conclude by\nexactly enumerating weakly threshold sequences and graphs.\n",
    "  The purpose of this study was to investigate the magnetotransport properties\nof the Ge(0.743)Pb(0.183)Mn(0.074)Te mixed crystal. The results of\nmagnetization measurements indicated that the compound is a spin-glass-like\ndiluted magnetic semiconductor with critical temperature TSG = 97.5 K.\nNanoclusters in the sample are observed. Both, matrix and clusters are\nmagnetically active. Resistivity as a function of temperature has a minimum at\n30 K. Below the minimum a variable-range hopping is observed, while above the\nminimum a metallic-like behavior occurs. The crystal has high hole\nconcentration, p = 6.6E20 cm-3, temperature-independent. Magnetoresistance\namplitude changes from -0.78 to 1.18% with increase of temperature. In the\nmagnetotransport measurements we observed the anomalous Hall effect (AHE) with\nhysteresis loops. Calculated AHE coefficient, RS = 2.0E6 m3/C, is temperature\nindependent. The analysis indicates the extrinsic skew scattering mechanism to\nbe the main physical mechanism responsible for AHE in\nGe(0.743)Pb(0.183)Mn(0.074)Te alloy.\n",
    "Recent state-of-the-art image segmentation algorithms are mostly based on\ndeep neural networks, thanks to their high performance and fast computation\ntime. However, these methods are usually trained in a supervised manner, which\nrequires large number of high quality ground-truth segmentation masks. On the\nother hand, classical image segmentation approaches such as level-set methods\nare formulated in a self-supervised manner by minimizing energy functions such\nas Mumford-Shah functional, so they are still useful to help generation of\nsegmentation masks without labels. Unfortunately, these algorithms are usually\ncomputationally expensive and often have limitation in semantic segmentation.\nIn this paper, we propose a novel loss function based on Mumford-Shah\nfunctional that can be used in deep-learning based image segmentation without\nor with small labeled data. This loss function is based on the observation that\nthe softmax layer of deep neural networks has striking similarity to the\ncharacteristic function in the Mumford-Shah functional. We show that the new\nloss function enables semi-supervised and unsupervised segmentation. In\naddition, our loss function can be also used as a regularized function to\nenhance supervised semantic segmentation algorithms. Experimental results on\nmultiple datasets demonstrate the effectiveness of the proposed method.",
    "  Advances in reflectarrays and array lenses with electronic beam-forming\ncapabilities are enabling a host of new possibilities for these\nhigh-performance, low-cost antenna architectures. This paper reviews enabling\ntechnologies and topologies of reconfigurable reflectarray and array lens\ndesigns, and surveys a range of experimental implementations and achievements\nthat have been made in this area in recent years. The paper describes the\nfundamental design approaches employed in realizing reconfigurable designs, and\nexplores advanced capabilities of these nascent architectures, such as\nmulti-band operation, polarization manipulation, frequency agility, and\namplification. Finally, the paper concludes by discussing future challenges and\npossibilities for these antennas.\n",
    "  Here, we study noisy transitional flows in imperfect millimeter-scale\nchannels. For probing the flows, we use microcantilever sensors embedded in the\nchannel walls. We perform experiments in two nominally identical channels. The\ndifferent set of imperfections in the two channels result in two random flows\nin which high-order moments of near-wall fluctuations differ by orders of\nmagnitude. Surprisingly however, the lowest order statistics in both cases\nappear qualitatively similar and can be described by a proposed noisy Landau\nequation for a slow mode. The noise, regardless of its origin, regularizes the\nLandau singularity of the relaxation time and makes transitions driven by\ndifferent noise sources appear similar.\n",
    "Learning long-term spatial-temporal features are critical for many video\nanalysis tasks. However, existing video segmentation methods predominantly rely\non static image segmentation techniques, and methods capturing temporal\ndependency for segmentation have to depend on pretrained optical flow models,\nleading to suboptimal solutions for the problem. End-to-end sequential learning\nto explore spatialtemporal features for video segmentation is largely limited\nby the scale of available video segmentation datasets, i.e., even the largest\nvideo segmentation dataset only contains 90 short video clips. To solve this\nproblem, we build a new large-scale video object segmentation dataset called\nYouTube Video Object Segmentation dataset (YouTube-VOS). Our dataset contains\n4,453 YouTube video clips and 94 object categories. This is by far the largest\nvideo object segmentation dataset to our knowledge and has been released at\nhttp://youtube-vos.org. We further evaluate several existing state-of-the-art\nvideo object segmentation algorithms on this dataset which aims to establish\nbaselines for the development of new algorithms in the future.",
    "Video-based eye tracking is a valuable technique in various research fields.\nNumerous open-source eye tracking algorithms have been developed in recent\nyears, primarily designed for general application with many different camera\ntypes. These algorithms do not, however, capitalize on the high frame rate of\neye tracking cameras often employed in psychophysical studies. We present a\npupil detection method that utilizes this high-speed property to obtain\nreliable predictions through recursive estimation about certain pupil\ncharacteristics in successive camera frames. These predictions are subsequently\nused to carry out novel image segmentation and classification routines to\nimprove pupil detection performance. Based on results from hand-labelled eye\nimages, our approach was found to have a greater detection rate, accuracy and\nspeed compared to other recently published open-source pupil detection\nalgorithms. The program's source code, together with a graphical user\ninterface, can be downloaded at https://github.com/tbrouns/eyestalker",
    "  We describe a revised collection of the number of sunspot groups from 1610 to\nthe present. This new collection is based on the work of Hoyt and Schatten\n(Solar Phys. 179, 189, 1998). The main changes are the elimination of a\nconsiderable number of observations during the Maunder Minimum (hereafter, MM)\nand the inclusion of several long series of observations. Numerous minor\nchanges are also described. Moreover, we have calculated the active-day\npercentage during the MM from this new collection as a reliable index of the\nsolar activity. Thus, the level of solar activity obtained in this work is\ngreater than the level obtained using the original Hoyt and Schatten data,\nalthough it remains compatible with a grand minimum of solar activity. The new\ncollection is available in digital format.\n",
    "  Energy-efficient communication using a class of spatial modulation (SM) that\nencodes the source information entirely in the antenna indices is considered in\nthis paper. The energy-efficient modulation design is formulated as a convex\noptimization problem, where minimum achievable average symbol power consumption\nis derived with rate, performance, and hardware constraints. The theoretical\nresult bounds any modulation scheme of this class, and encompasses the existing\nspace shift keying (SSK), generalized SSK (GSSK), and Hamming code-aided SSK\n(HSSK) schemes as special cases. The theoretical optimum is achieved by the\nproposed practical energy-efficient HSSK (EE-HSSK) scheme that incorporates a\nnovel use of the Hamming code and Huffman code techniques in the alphabet and\nbit-mapping designs. Experimental studies demonstrate that EE-HSSK\nsignificantly outperforms existing schemes in achieving near-optimal energy\nefficiency. An analytical exposition of key properties of the existing GSSK\n(including SSK) modulation that motivates a fundamental consideration for the\nproposed energy-efficient modulation design is also provided.\n",
    "  Given an arbitrary non-zero simplicial cycle and a generic vector coloring of\nits vertices, there is a way to produce a graded Poincare duality algebra\nassociated with these data. The procedure relies on the theory of volume\npolynomials and multi-fans. This construction includes many important examples,\nsuch as cohomology of toric varieties and quasitoric manifolds, and Gorenstein\nalgebras of triangulated homology manifolds, introduced by Novik and Swartz. In\nall these examples the dimensions of graded components of such duality algebras\ndo not depend on the vector coloring. It was conjectured that the same holds\nfor any simplicial cycle. We disprove this conjecture by showing that the\ncolors of singular points of the cycle may affect the dimensions. However, the\ncolors of smooth points are irrelevant. By using bistellar moves we show that\nthe number of different dimension vectors arising on a given 3-dimensional\npseudomanifold with isolated singularities is a topological invariant. This\ninvariant is trivial on manifolds, but nontrivial in general.\n",
    "In Computer Vision, edge detection is one of the favored approaches for\nfeature and object detection in images since it provides information about\ntheir objects boundaries. Other region-based approaches use probabilistic\nanalysis such as clustering and Markov random fields, but those methods cannot\nbe used to analyze edges and their interaction. In fact, only image\nsegmentation can produce regions based on edges, but it requires thresholding\nby simply separating the regions into binary in-out information. Hence, there\nis currently a gap between edge-based and region-based algorithms, since edges\ncannot be used to study the properties of a region and vice versa. The\nobjective of this paper is to present a novel spatial probability analysis that\nallows determining the probability of inclusion inside a set of partial\ncontours (strokes). To answer this objective, we developed a new approach that\nuses electromagnetic convolutions and repulsion optimization to compute the\nrequired probabilities. Hence, it becomes possible to generate a continuous\nspace of probability based only on the edge information, thus bridging the gap\nbetween the edge-based methods and the region-based methods. The developed\nmethod is consistent with the fundamental properties of inclusion probabilities\nand its results are validated by comparing an image with the probability-based\nestimation given by our algorithm. The method can also be generalized to take\ninto consideration the intensity of the edges or to be used for 3D shapes. This\nis the first documented method that allows computing a space of probability\nbased on interacting edges, which opens the path to broader applications such\nas image segmentation and contour completion.",
    "America has a massive railway system. As of 2006, U.S. freight railroads have\n140,490 route- miles of standard gauge, but maintaining such a huge system and\neliminating any dangers, like reduced track stability and poor drainage, caused\nby railway ballast degradation require huge amount of labor. The traditional\nway to quantify the degradation of ballast is to use an index called Fouling\nIndex (FI) through ballast sampling and sieve analysis. However, determining\nthe FI values in lab is very time-consuming and laborious, but with the help of\nrecent development in the field of computer vision, a novel method for a\npotential machine-vison based ballast inspection system can be employed that\ncan hopefully replace the traditional mechanical method. The new machine-vision\napproach analyses the images of the in-service ballasts, and then utilizes\nimage segmentation algorithm to get ballast segments. By comparing the segment\nresults and their corresponding FI values, this novel method produces a\nmachine-vision-based index that has the best-fit relation with FI. The\nimplementation details of how this algorithm works are discussed in this\nreport.",
    "This paper aims at developing an integrated system of clothing co-parsing, in\norder to jointly parse a set of clothing images (unsegmented but annotated with\ntags) into semantic configurations. We propose a data-driven framework\nconsisting of two phases of inference. The first phase, referred as \"image\nco-segmentation\", iterates to extract consistent regions on images and jointly\nrefines the regions over all images by employing the exemplar-SVM (E-SVM)\ntechnique [23]. In the second phase (i.e. \"region co-labeling\"), we construct a\nmulti-image graphical model by taking the segmented regions as vertices, and\nincorporate several contexts of clothing configuration (e.g., item location and\nmutual interactions). The joint label assignment can be solved using the\nefficient Graph Cuts algorithm. In addition to evaluate our framework on the\nFashionista dataset [30], we construct a dataset called CCP consisting of 2098\nhigh-resolution street fashion photos to demonstrate the performance of our\nsystem. We achieve 90.29% / 88.23% segmentation accuracy and 65.52% / 63.89%\nrecognition rate on the Fashionista and the CCP datasets, respectively, which\nare superior compared with state-of-the-art methods.",
    "Color and intensity are two important components in an image. Usually, groups\nof image pixels, which are similar in color or intensity, are an informative\nrepresentation for an object. They are therefore particularly suitable for\ncomputer vision tasks, such as saliency detection and object proposal\ngeneration. However, image pixels, which share a similar real-world color, may\nbe quite different since colors are often distorted by intensity. In this\npaper, we reinvestigate the affinity matrices originally used in image\nsegmentation methods based on spectral clustering. A new affinity matrix, which\nis robust to color distortions, is formulated for object discovery. Moreover, a\nCohesion Measurement (CM) for object regions is also derived based on the\nformulated affinity matrix. Based on the new Cohesion Measurement, a novel\nobject discovery method is proposed to discover objects latent in an image by\nutilizing the eigenvectors of the affinity matrix. Then we apply the proposed\nmethod to both saliency detection and object proposal generation. Experimental\nresults on several evaluation benchmarks demonstrate that the proposed CM based\nmethod has achieved promising performance for these two tasks.",
    "The automated segmentation of buildings in remote sensing imagery is a\nchallenging task that requires the accurate delineation of multiple building\ninstances over typically large image areas. Manual methods are often laborious\nand current deep-learning-based approaches fail to delineate all building\ninstances and do so with adequate accuracy. As a solution, we present Trainable\nDeep Active Contours (TDACs), an automatic image segmentation framework that\nintimately unites Convolutional Neural Networks (CNNs) and Active Contour\nModels (ACMs). The Eulerian energy functional of the ACM component includes\nper-pixel parameter maps that are predicted by the backbone CNN, which also\ninitializes the ACM. Importantly, both the ACM and CNN components are fully\nimplemented in TensorFlow and the entire TDAC architecture is end-to-end\nautomatically differentiable and backpropagation trainable without user\nintervention. TDAC yields fast, accurate, and fully automatic simultaneous\ndelineation of arbitrarily many buildings in the image. We validate the model\non two publicly available aerial image datasets for building segmentation, and\nour results demonstrate that TDAC establishes a new state-of-the-art\nperformance.",
    "We present a method combining affinity prediction with region agglomeration,\nwhich improves significantly upon the state of the art of neuron segmentation\nfrom electron microscopy (EM) in accuracy and scalability. Our method consists\nof a 3D U-NET, trained to predict affinities between voxels, followed by\niterative region agglomeration. We train using a structured loss based on\nMALIS, encouraging topologically correct segmentations obtained from affinity\nthresholding. Our extension consists of two parts: First, we present a\nquasi-linear method to compute the loss gradient, improving over the original\nquadratic algorithm. Second, we compute the gradient in two separate passes to\navoid spurious gradient contributions in early training stages. Our predictions\nare accurate enough that simple learning-free percentile-based agglomeration\noutperforms more involved methods used earlier on inferior predictions. We\npresent results on three diverse EM datasets, achieving relative improvements\nover previous results of 27%, 15%, and 250%. Our findings suggest that a single\nmethod can be applied to both nearly isotropic block-face EM data and\nanisotropic serial sectioned EM data. The runtime of our method scales linearly\nwith the size of the volume and achieves a throughput of about 2.6 seconds per\nmegavoxel, qualifying our method for the processing of very large datasets.",
    "  A single crystal of isovalently substituted Ba(Fe$_{1-x}$Ru$_{x}$)$_2$As$_2$\n($x=0.24$) was sequentially irradiated with 2.5 MeV electrons up to a maximum\ndose of $2.1 \\times 10^{19}$ electrons/cm^2. The electrical resistivity was\nmeasured \\textit{in - situ} at $T=$22 K during the irradiation and \\textit{ex -\nsitu} as a function of temperature between subsequent irradiation runs. Upon\nirradiation, the superconducting transition temperature, $T_c$, decreases and\nthe residual resistivity, $\\rho_0$, increases. We find that electron\nirradiation leads to the fastest suppression of $T_c$ compared to other types\nof artificially introduced disorder, probably due to the strong short-range\npotential of the point-like irradiation defects. A more detailed analysis\nwithin a multiband scenario with variable scattering potential strength shows\nthat the observed $T_c$ vs. $\\rho_0$ is fully compatible with $s_\\pm$ pairing,\nin contrast to earlier claims that this model leads to a too rapid a\nsuppression of $T_c$ with scattering.\n",
    "  A Short-Baseline Neutrino (SBN) physics program of three LAr-TPC detectors\nlocated along the Booster Neutrino Beam (BNB) at Fermilab is presented. This\nnew SBN Program will deliver a rich and compelling physics opportunity,\nincluding the ability to resolve a class of experimental anomalies in neutrino\nphysics and to perform the most sensitive search to date for sterile neutrinos\nat the eV mass-scale through both appearance and disappearance oscillation\nchannels. Using data sets of 6.6e20 protons on target (P.O.T.) in the LAr1-ND\nand ICARUS T600 detectors plus 13.2e20 P.O.T. in the MicroBooNE detector, we\nestimate that a search for muon neutrino to electron neutrino appearance can be\nperformed with ~5 sigma sensitivity for the LSND allowed (99% C.L.) parameter\nregion. In this proposal for the SBN Program, we describe the physics analysis,\nthe conceptual design of the LAr1-ND detector, the design and refurbishment of\nthe T600 detector, the necessary infrastructure required to execute the\nprogram, and a possible reconfiguration of the BNB target and horn system to\nimprove its performance for oscillation searches.\n",
    "Image foreground extraction is a classical problem in image processing and\nvision, with a large range of applications. In this dissertation, we focus on\nthe extraction of text and graphics in mixed-content images, and design novel\napproaches for various aspects of this problem.\n  We first propose a sparse decomposition framework, which models the\nbackground by a subspace containing smooth basis vectors, and foreground as a\nsparse and connected component. We then formulate an optimization framework to\nsolve this problem, by adding suitable regularizations to the cost function to\npromote the desired characteristics of each component. We present two\ntechniques to solve the proposed optimization problem, one based on alternating\ndirection method of multipliers (ADMM), and the other one based on robust\nregression. Promising results are obtained for screen content image\nsegmentation using the proposed algorithm.\n  We then propose a robust subspace learning algorithm for the representation\nof the background component using training images that could contain both\nbackground and foreground components, as well as noise. With the learnt\nsubspace for the background, we can further improve the segmentation results,\ncompared to using a fixed subspace. Lastly, we investigate a different class of\nsignal/image decomposition problem, where only one signal component is active\nat each signal element. In this case, besides estimating each component, we\nneed to find their supports, which can be specified by a binary mask. We\npropose a mixed-integer programming problem, that jointly estimates the two\ncomponents and their supports through an alternating optimization scheme. We\nshow the application of this algorithm on various problems, including image\nsegmentation, video motion segmentation, and also separation of text from\ntextured images.",
    "  We develop a system for measurements of power spectra of transmitted light\nintensity fluctuations, in which the extraneous noise, including shot noise, is\nreduced. In essence, we just apply light, measure the power of the transmitted\nlight and derive its power spectrum. We use this to observe the spontaneous\nnoise spectra of photon atom interactions. Applying light with frequency\nmodulation, we can also observe the spontaneous noise reflecting the coherence\nbetween the hyperfine levels in the excited state. There are two in novel\ncomponents in the measurement system, the noise reduction scheme and the\nstabilization of the laser system. The noise reduction mechanism can be used to\nreduce the shot noise contribution to arbitrarily low levels through averaging,\nin principle. This is combined with differential detection to keep unwanted\nnoise at low levels. The laser system is stabilized to obtain spectral width\nbelow 1\\,kHz without high frequency ($\\gtrsim10\\,$MHz) noise. These methods are\ndescribed systematically and the performance of the asurement system is\nexamined through experimental results.\n",
    "  We propose a new class of models specifically tailored for spatio-temporal\ndata analysis. To this end, we generalize the spatial autoregressive model with\nautoregressive and heteroskedastic disturbances, i.e. SARAR(1,1), by exploiting\nthe recent advancements in Score Driven (SD) models typically used in time\nseries econometrics. In particular, we allow for time-varying spatial\nautoregressive coefficients as well as time-varying regressor coefficients and\ncross-sectional standard deviations. We report an extensive Monte Carlo\nsimulation study in order to investigate the finite sample properties of the\nMaximum Likelihood estimator for the new class of models as well as its\nflexibility in explaining several dynamic spatial dependence processes. The new\nproposed class of models are found to be economically preferred by rational\ninvestors through an application in portfolio optimization.\n",
    "The performance of deep networks for semantic image segmentation largely\ndepends on the availability of large-scale training images which are labelled\nat the pixel level. Typically, such pixel-level image labellings are obtained\nmanually by a labour-intensive process. To alleviate the burden of manual image\nlabelling, we propose an interesting learning approach to generate pixel-level\nimage labellings automatically. A Guided Filter Network (GFN) is first\ndeveloped to learn the segmentation knowledge from a source domain, and such\nGFN then transfers such segmentation knowledge to generate coarse object masks\nin the target domain. Such coarse object masks are treated as pseudo labels and\nthey are further integrated to optimize/refine the GFN iteratively in the\ntarget domain. Our experiments on six image sets have demonstrated that our\nproposed approach can generate fine-grained object masks (i.e., pixel-level\nobject labellings), whose quality is very comparable to the manually-labelled\nones. Our proposed approach can also achieve better performance on semantic\nimage segmentation than most existing weakly-supervised approaches.",
    "Tensor networks provide an efficient approximation of operations involving\nhigh dimensional tensors and have been extensively used in modelling quantum\nmany-body systems. More recently, supervised learning has been attempted with\ntensor networks, primarily focused on tasks such as image classification. In\nthis work, we propose a novel formulation of tensor networks for supervised\nimage segmentation which allows them to operate on high resolution medical\nimages. We use the matrix product state (MPS) tensor network on non-overlapping\npatches of a given input image to predict the segmentation mask by learning a\npixel-wise linear classification rule in a high dimensional space. The proposed\nmodel is end-to-end trainable using backpropagation. It is implemented as a\nStrided Tensor Network to reduce the parameter complexity. The performance of\nthe proposed method is evaluated on two public medical imaging datasets and\ncompared to relevant baselines. The evaluation shows that the strided tensor\nnetwork yields competitive performance compared to CNN-based models while using\nfewer resources. Additionally, based on the experiments we discuss the\nfeasibility of using fully linear models for segmentation tasks.",
    "  A path in an edge-colored graph $G$ is rainbow if no two edges of it are\ncolored the same. The graph $G$ is rainbow-connected if there is a rainbow path\nbetween every pair of vertices. If there is a rainbow shortest path between\nevery pair of vertices, the graph $G$ is strongly rainbow-connected. The\nminimum number of colors needed to make $G$ rainbow-connected is known as the\nrainbow connection number of $G$, and is denoted by $\\text{rc}(G)$. Similarly,\nthe minimum number of colors needed to make $G$ strongly rainbow-connected is\nknown as the strong rainbow connection number of $G$, and is denoted by\n$\\text{src}(G)$. We prove that for every $k \\geq 3$, deciding whether\n$\\text{src}(G) \\leq k$ is NP-complete for split graphs, which form a subclass\nof chordal graphs. Furthermore, there exists no polynomial-time algorithm for\napproximating the strong rainbow connection number of an $n$-vertex split graph\nwith a factor of $n^{1/2-\\epsilon}$ for any $\\epsilon > 0$ unless P = NP. We\nthen turn our attention to block graphs, which also form a subclass of chordal\ngraphs. We determine the strong rainbow connection number of block graphs, and\nshow it can be computed in linear time. Finally, we provide a polynomial-time\ncharacterization of bridgeless block graphs with rainbow connection number at\nmost 4.\n",
    "Panoramic segmentation is a scene where image segmentation tasks is more\ndifficult. With the development of CNN networks, panoramic segmentation tasks\nhave been sufficiently developed.However, the current panoramic segmentation\nalgorithms are more concerned with context semantics, but the details of image\nare not processed enough. Moreover, they cannot solve the problems which\ncontains the accuracy of occluded object segmentation,little object\nsegmentation,boundary pixel in object segmentation etc. Aiming to address these\nissues, this paper presents some useful tricks. (a) By changing the basic\nsegmentation model, the model can take into account the large objects and the\nboundary pixel classification of image details. (b) Modify the loss function so\nthat it can take into account the boundary pixels of multiple objects in the\nimage. (c) Use a semi-supervised approach to regain control of the training\nprocess. (d) Using multi-scale training and reasoning. All these operations\nnamed AinnoSeg, AinnoSeg can achieve state-of-art performance on the well-known\ndataset ADE20K.",
    "Over the past few years, state-of-the-art image segmentation algorithms are\nbased on deep convolutional neural networks. To render a deep network with the\nability to understand a concept, humans need to collect a large amount of\npixel-level annotated data to train the models, which is time-consuming and\ntedious. Recently, few-shot segmentation is proposed to solve this problem.\nFew-shot segmentation aims to learn a segmentation model that can be\ngeneralized to novel classes with only a few training images. In this paper, we\npropose a cross-reference network (CRNet) for few-shot segmentation. Unlike\nprevious works which only predict the mask in the query image, our proposed\nmodel concurrently make predictions for both the support image and the query\nimage. With a cross-reference mechanism, our network can better find the\nco-occurrent objects in the two images, thus helping the few-shot segmentation\ntask. We also develop a mask refinement module to recurrently refine the\nprediction of the foreground regions. For the $k$-shot learning, we propose to\nfinetune parts of networks to take advantage of multiple labeled support\nimages. Experiments on the PASCAL VOC 2012 dataset show that our network\nachieves state-of-the-art performance.",
    "We propose a method for high-performance semantic image segmentation (or\nsemantic pixel labelling) based on very deep residual networks, which achieves\nthe state-of-the-art performance. A few design factors are carefully considered\nto this end.\n  We make the following contributions. (i) First, we evaluate different\nvariations of a fully convolutional residual network so as to find the best\nconfiguration, including the number of layers, the resolution of feature maps,\nand the size of field-of-view. Our experiments show that further enlarging the\nfield-of-view and increasing the resolution of feature maps are typically\nbeneficial, which however inevitably leads to a higher demand for GPU memories.\nTo walk around the limitation, we propose a new method to simulate a high\nresolution network with a low resolution network, which can be applied during\ntraining and/or testing. (ii) Second, we propose an online bootstrapping method\nfor training. We demonstrate that online bootstrapping is critically important\nfor achieving good accuracy. (iii) Third we apply the traditional dropout to\nsome of the residual blocks, which further improves the performance. (iv)\nFinally, our method achieves the currently best mean intersection-over-union\n78.3\\% on the PASCAL VOC 2012 dataset, as well as on the recent dataset\nCityscapes.",
    "  The current flow of high accuracy astrophysical data, among which are the\nCosmic Microwave Background (CMB) measurements by the Planck satellite, offers\nan unprecedented opportunity to constrain the inflationary theory. This is\nhowever a challenging project given the size of the inflationary landscape\nwhich contains hundreds of different scenarios. Given that there is currently\nno observational evidence for primordial non-Gaussianities, isocurvature\nperturbations or any other non-minimal extension of the inflationary paradigm,\na reasonable approach is to consider the simplest models first, namely the\nslow-roll single field models with minimal kinetic terms. This still leaves us\nwith a very populated landscape, the exploration of which requires new and\nefficient strategies. It has been customary to tackle this problem by means of\napproximate model independent methods while a more ambitious alternative is to\nstudy the inflationary scenarios one by one. We have developed the new publicly\navailable runtime library ASPIC to implement this last approach. The ASPIC code\nprovides all routines needed to quickly derive reheating consistent observable\npredictions within this class of scenarios. ASPIC has been designed as an\nevolutive code which presently supports 118 different models, a number that may\nbe compared with three or four representing the present state of the art. In\nthis paper, for each of the ASPIC models, we present and collect new results in\na systematic manner, thereby constituting the first Encyclopaedia\nInflationaris.\n",
    "  In classical logic, \"P implies Q\" is equivalent to \"not-P or Q\". It is well\nknown that the equivalence is problematic. Actually, from \"P implies Q\", \"not-P\nor Q\" can be inferred (\"Implication-to-disjunction\" is valid), while from\n\"not-P or Q\", \"P implies Q\" cannot be inferred in general\n(\"Disjunction-to-implication\" is not valid), so the equivalence between them is\ninvalid. This work aims to remove exactly the incorrect\nDisjunction-to-implication from classical logic (CL). The paper proposes a\nlogical system (IRL), which has the properties (1) adding\nDisjunction-to-implication to IRL is simply CL, and (2)\nDisjunction-to-implication is independent of IRL, i.e. either\nDisjunction-to-implication or its negation cannot be derived in IRL. In other\nwords, IRL is just the sub-system of CL with Disjunction-to-implication being\nexactly removed.\n",
    "While convolutional neural networks (CNNs) trained by back-propagation have\nseen unprecedented success at semantic segmentation tasks, they are known to\nstruggle on out-of-distribution data. Markov random fields (MRFs) on the other\nhand, encode simpler distributions over labels that, although less flexible\nthan UNets, are less prone to over-fitting. In this paper, we propose to fuse\nboth strategies by computing the product of distributions of a UNet and an MRF.\nAs this product is intractable, we solve for an approximate distribution using\nan iterative mean-field approach. The resulting MRF-UNet is trained jointly by\nback-propagation. Compared to other works using conditional random fields\n(CRFs), the MRF has no dependency on the imaging data, which should allow for\nless over-fitting. We show on 3D neuroimaging data that this novel network\nimproves generalisation to out-of-distribution samples. Furthermore, it allows\nthe overall number of parameters to be reduced while preserving high accuracy.\nThese results suggest that a classic MRF smoothness prior can allow for less\nover-fitting when principally integrated into a CNN model. Our implementation\nis available at https://github.com/balbasty/nitorch.",
    "  Directional infrared emission at 1367 and 5230 nm is generated in Rb vapours\nthat are step-wise excited by low-power resonant light. The mid-infrared\nradiation originating from amplified spontaneous emission on the 5D-6P\ntransition consists of forward- and backward-directed components with\ndistinctive spectral and spatial properties. Diffraction limited near-infrared\nlight at 1367 nm generated in the co-propagating direction only is a product of\nparametric wave mixing around the 5P-5D-6P-6S-5P transition loop. This highly\nnon-degenerate mixing process involves one externally applied and two\ninternally generated optical fields. Similarities between wave mixing generated\nblue and near-IR light are demonstrated.\n",
    "  Efficient generation of cluster states is crucial for engineering large-scale\nmeasurement-based quantum computers. Hybrid matter-optical systems offer a\nrobust, scalable path to this goal. Such systems have an ancilla which acts as\na bus connecting the qubits. We show that by generating smaller cluster \"Lego\nbricks\", reusing one ancilla per brick, the cluster can be produced with\nmaximal efficiency, requiring fewer than half the operations compared with no\nbus reuse. By reducing the time required to prepare sections of the cluster,\nbus reuse more than doubles the size of the computational workspace that can be\nused before decoherence effects dominate. A row of buses in parallel provides\nfully scalable cluster state generation requiring only 20 CPhase gates per bus\nuse.\n",
    "  We investigate the gradual emergence of the disorder-related phenomena in\nintermediate regimes between a deterministic periodic Bragg grating and a fully\nrandom grating and highlight two critical properties of partially disordered\nBragg gratings. First, the integral of the logarithm of the transmittance over\nthe reciprocal wavevector space is a conserved quantity. Therefore, adding\ndisorder merely redistributes the transmittance over the reciprocal space.\nSecond, for any amount of disorder, the average transmittance decays\nexponentially with the number of grating layers in the simple form of\n$\\exp(-\\eta N)$ for sufficiently large $N$, where $\\eta$ is a constant and $N$\nis the number of layers. Conversely, the simple exponential decay form does not\nhold for small $N$ except for a highly disordered system. Implications of these\nfindings are demonstrated.\n",
    "  We present a numerical strategy to design fiber based dual pulse light\nsources exhibiting two predefined spectral peaks in the anomalous group\nvelocity dispersion regime. The frequency conversion is based on the soliton\nfission and soliton self-frequency shift occurring during supercontinuum\ngeneration. The optimization process is carried out by a genetic algorithm that\nprovides the optimum input pulse parameters: wavelength, temporal width and\npeak power. This algorithm is implemented in a Grid platform in order to take\nadvantage of distributed computing. These results are useful for optical\ncoherence tomography applications where bell-shaped pulses located in the\nsecond near-infrared window are needed.\n",
    "  Flexible grid optical networks allow a better exploitation of fiber capacity,\nby enabling a denser frequency allocation. A tighter channel spacing, however,\nrequires narrower filters, which increase linear intersymbol interference\n(ISI), and may dramatically reduce system reach. Commercial coherent receivers\nare based on symbol by symbol detectors, which are quite sensitive to ISI. In\nthis context, Nyquist spacing is considered as the ultimate limit to\nwavelength-division multiplexing (WDM) packing.\n  In this paper, we show that by introducing a limited-complexity trellis\nprocessing at the receiver, either the reach of Nyquist WDM flexi-grid networks\ncan be significantly extended, or a denser-than-Nyquist channel packing (i.e.,\na higher spectral efficiency (SE)) is possible at equal reach. By adopting\nwell-known information-theoretic techniques, we design a limited-complexity\ntrellis processing and quantify its SE gain in flexi-grid architectures where\nwavelength selective switches over a frequency grid of 12.5GHz are employed.\n",
    "We introduce DatasetGAN: an automatic procedure to generate massive datasets\nof high-quality semantically segmented images requiring minimal human effort.\nCurrent deep networks are extremely data-hungry, benefiting from training on\nlarge-scale datasets, which are time consuming to annotate. Our method relies\non the power of recent GANs to generate realistic images. We show how the GAN\nlatent code can be decoded to produce a semantic segmentation of the image.\nTraining the decoder only needs a few labeled examples to generalize to the\nrest of the latent space, resulting in an infinite annotated dataset generator!\nThese generated datasets can then be used for training any computer vision\narchitecture just as real datasets are. As only a few images need to be\nmanually segmented, it becomes possible to annotate images in extreme detail\nand generate datasets with rich object and part segmentations. To showcase the\npower of our approach, we generated datasets for 7 image segmentation tasks\nwhich include pixel-level labels for 34 human face parts, and 32 car parts. Our\napproach outperforms all semi-supervised baselines significantly and is on par\nwith fully supervised methods, which in some cases require as much as 100x more\nannotated data as our method.",
    "  In this paper, we have considered a Block-Basu type bivariate Pareto\ndistribution. Here in the standard manner, first Marshall-Olkin type singular\nbivariate distribution has been constructed, and then by taking away the\nsingular component similar to the Block and Basu model, an absolute continuous\nBB-BVPA model has been constructed. Further, the location and scale parameters\nalso have been introduced. Therefore, the model has seven parameters. Different\nproperties of this absolutely continuous distribution are derived. Since the\nmaximum likelihood estimators of the parameters cannot be expressed in a closed\nform, we propose to use an EM algorithm to compute the estimators of the model\nparameters. Some simulation experiments have been performed for illustrative\npurposes. The model is fitted to rainfall data in the context of landslide risk\nestimation.\n",
    "Semantic image segmentation is an important computer vision task that is\ndifficult because it consists of both recognition and segmentation. The task is\noften cast as a structured output problem on an exponentially large\noutput-space, which is typically modeled by a discrete probabilistic model. The\nbest segmentation is found by inferring the Maximum a-Posteriori (MAP) solution\nover the output distribution defined by the model. Due to limitations in\noptimization, the model cannot be arbitrarily complex. This leads to a\ntrade-off: devise a more accurate model that incorporates rich high-order\ninteractions between image elements at the cost of inaccurate and possibly\nintractable optimization OR leverage a tractable model which produces less\naccurate MAP solutions but may contain high quality solutions as other modes of\nits output distribution.\n  This thesis investigates the latter and presents a two stage approach to\nsemantic segmentation. In the first stage a tractable segmentation model\noutputs a set of high probability segmentations from the underlying\ndistribution that are not just minor perturbations of each other. Critically\nthe output of this stage is a diverse set of plausible solutions and not just a\nsingle one. In the second stage, a discriminatively trained re-ranking model\nselects the best segmentation from this set. The re-ranking stage can use much\nmore complex features than what could be tractably used in the segmentation\nmodel, allowing a better exploration of the solution space than simply\nreturning the MAP solution. The formulation is agnostic to the underlying\nsegmentation model (e.g. CRF, CNN, etc.) and optimization algorithm, which\nmakes it applicable to a wide range of models and inference methods. Evaluation\nof the approach on a number of semantic image segmentation benchmark datasets\nhighlight its superiority over inferring the MAP solution.",
    "Automatic medical image segmentation has made great progress benefit from the\ndevelopment of deep learning. However, most existing methods are based on\nconvolutional neural networks (CNNs), which fail to build long-range\ndependencies and global context connections due to the limitation of receptive\nfield in convolution operation. Inspired by the success of Transformer in\nmodeling the long-range contextual information, some researchers have expended\nconsiderable efforts in designing the robust variants of Transformer-based\nU-Net. Moreover, the patch division used in vision transformers usually ignores\nthe pixel-level intrinsic structural features inside each patch. To alleviate\nthese problems, we propose a novel deep medical image segmentation framework\ncalled Dual Swin Transformer U-Net (DS-TransUNet), which might be the first\nattempt to concurrently incorporate the advantages of hierarchical Swin\nTransformer into both encoder and decoder of the standard U-shaped architecture\nto enhance the semantic segmentation quality of varying medical images. Unlike\nmany prior Transformer-based solutions, the proposed DS-TransUNet first adopts\ndual-scale encoder subnetworks based on Swin Transformer to extract the coarse\nand fine-grained feature representations of different semantic scales. As the\ncore component for our DS-TransUNet, a well-designed Transformer Interactive\nFusion (TIF) module is proposed to effectively establish global dependencies\nbetween features of different scales through the self-attention mechanism.\nFurthermore, we also introduce the Swin Transformer block into decoder to\nfurther explore the long-range contextual information during the up-sampling\nprocess. Extensive experiments across four typical tasks for medical image\nsegmentation demonstrate the effectiveness of DS-TransUNet, and show that our\napproach significantly outperforms the state-of-the-art methods.",
    "  It has been known for over 70 years that there is an asymptotic transition of\nCharlier polynomials to Hermite polynomials. This transition, which is still\npresented in its classical form in modern reference works, is valid if and only\nif a certain parameter is integer. In this light, it is surprising that a much\nmore powerful transition exists from Charlier polynomials to the Hermite\nfunction, valid for any real value of the parameter. This greatly strengthens\nthe asymptotic connections between Charlier polynomials and special functions,\nwith applications for instance in queueing theory.\n  It is shown in this paper that the convergence is uniform in bounded\nintervals, and a sharp rate bound is proved. It is also shown that there is a\ntransition of derivatives of Charlier polynomials to the derivative of the\nHermite function, again with a sharp rate bound. Finally, it is proved that\nzeros of Charlier polynomials converge to zeros of the Hermite function. While\nrigorous, the proofs use only elementary techniques.\n",
    "This paper proposes a novel approach for uncertainty quantification in dense\nConditional Random Fields (CRFs). The presented approach, called\nPerturb-and-MPM, enables efficient, approximate sampling from dense multi-label\nCRFs via random perturbations. An analytic error analysis was performed which\nidentified the main cause of approximation error as well as showed that the\nerror is bounded. Spatial uncertainty maps can be derived from the\nPerturb-and-MPM model, which can be used to visualize uncertainty in image\nsegmentation results. The method is validated on synthetic and clinical\nMagnetic Resonance Imaging data. The effectiveness of the approach is\ndemonstrated on the challenging problem of segmenting the tumor core in\nglioblastoma. We found that areas of high uncertainty correspond well to\nwrongly segmented image regions. Furthermore, we demonstrate the potential use\nof uncertainty maps to refine imaging biomarkers in the case of extent of\nresection and residual tumor volume in brain tumor patients.",
    "  Entanglement does not describe all quantum correlations and several authors\nhave shown the need to go beyond entanglement when dealing with mixed states.\nVarious different measures have sprung up in the literature, for a variety of\nreasons, to describe bipartite and multipartite quantum correlations; some are\nknown under the collective name quantum discord. Yet, in the same sprit as the\ncriteria for entanglement measures, there is no general mechanism that\ndetermines whether a measure of quantum and classical correlations is a proper\nmeasure of correlations. This is partially due to the fact that the answer is a\nbit muddy. In this article we attempt tackle this muddy topic by writing down\nseveral criteria for a \"good\" measure of correlations. We breakup our list into\nnecessary, reasonable, and debatable conditions. We then proceed to prove\nseveral of these conditions for generalized measures of quantum correlations.\nHowever, not all conditions are met by all measures; we show this via several\nexamples. The reasonable conditions are related to continuity of correlations,\nwhich has not been previously discussed. Continuity is an important quality if\none wants to probe quantum correlations in the laboratory. We show that most\ntypes of quantum discord are continuous but none are continuous with respect to\nthe measurement basis used for optimization.\n",
    "  Electron dynamics in crystalline semiconductors is described by\ndistinguishing between an instantaneous velocity related to electron's momentum\nand an average velocity related to its quasi-momentum in a periodic potential.\nIt is shown that the electron velocity used in the theory of electron transport\nand free-carrier optics is the average electron velocity, not the instantaneous\nvelocity. An effective mass of charge carriers in solids is considered and it\nis demonstrated that, in contrast to the \"acceleration\" mass introduced in\ntextbooks, it is a \"velocity\" mass relating carrier velocity to its\nquasi-momentum that is a much more useful physical quantity. Among other\nadvantages, the velocity mass is a scalar for spherical but nonparabolic energy\nbands $\\epsilon(k)$, whereas the acceleration mass is not a scalar. Important\napplications of the velocity mass are indicated. A two-band ${\\bm k}\\cdot {\\bm\n\\hp}$ model is introduced as the simplest example of a band structure that\nstill keeps track of the periodic lattice potential. It is remarked that the\ntwo-band model, adequately describing narrow-gap semiconductors (including\nzero-gap graphene), strongly resembles the special theory of relativity.\nInstructive examples of the \"semi-relativistic\" analogy are given. The\npresentation has both scientific and pedagogical aspects.\n",
    "  In this report we have analyzed a simple effective model for a description of\nmagnetically ordered insulators. The Hamiltonian considered consists of the\neffective on-site interaction (U) and the intersite Ising-like magnetic\nexchange interaction (J) between nearest neighbors. For the first time the\nphase diagrams of this model have been determined within Monte Carlo simulation\non 2D-square lattice. They have been compared with results obtained within\nvariational approach, which treats the on-site term exactly and the intersite\ninteractions within mean-field approximation. We show within both approaches\nthat, depending on the values of interaction parameters and the electron\nconcentration, the system can exhibit not only homogeneous phases:\n(anti-)ferromagnetic (F) and nonordered (NO), but also phase separated states\n(PS: F-NO).\n",
    "Cloud based medical image analysis has become popular recently due to the\nhigh computation complexities of various deep neural network (DNN) based\nframeworks and the increasingly large volume of medical images that need to be\nprocessed. It has been demonstrated that for medical images the transmission\nfrom local to clouds is much more expensive than the computation in the clouds\nitself. Towards this, 3D image compression techniques have been widely applied\nto reduce the data traffic. However, most of the existing image compression\ntechniques are developed around human vision, i.e., they are designed to\nminimize distortions that can be perceived by human eyes. In this paper we will\nuse deep learning based medical image segmentation as a vehicle and demonstrate\nthat interestingly, machine and human view the compression quality differently.\nMedical images compressed with good quality w.r.t. human vision may result in\ninferior segmentation accuracy. We then design a machine vision oriented 3D\nimage compression framework tailored for segmentation using DNNs. Our method\nautomatically extracts and retains image features that are most important to\nthe segmentation. Comprehensive experiments on widely adopted segmentation\nframeworks with HVSMR 2016 challenge dataset show that our method can achieve\nsignificantly higher segmentation accuracy at the same compression rate, or\nmuch better compression rate under the same segmentation accuracy, when\ncompared with the existing JPEG 2000 method. To the best of the authors'\nknowledge, this is the first machine vision guided medical image compression\nframework for segmentation in the clouds.",
    "The joint use of multiple imaging modalities for medical image segmentation\nhas been widely studied in recent years. The fusion of information from\ndifferent modalities has demonstrated to improve the segmentation accuracy,\nwith respect to mono-modal segmentations, in several applications. However,\nacquiring multiple modalities is usually not possible in a clinical setting due\nto a limited number of physicians and scanners, and to limit costs and scan\ntime. Most of the time, only one modality is acquired. In this paper, we\npropose KD-Net, a framework to transfer knowledge from a trained multi-modal\nnetwork (teacher) to a mono-modal one (student). The proposed method is an\nadaptation of the generalized distillation framework where the student network\nis trained on a subset (1 modality) of the teacher's inputs (n modalities). We\nillustrate the effectiveness of the proposed framework in brain tumor\nsegmentation with the BraTS 2018 dataset. Using different architectures, we\nshow that the student network effectively learns from the teacher and always\noutperforms the baseline mono-modal network in terms of segmentation accuracy.",
    "Image segmentation with a volume constraint is an important prior for many\nreal applications. In this work, we present a novel volume preserving image\nsegmentation algorithm, which is based on the framework of entropic regularized\noptimal transport theory. The classical Total Variation (TV) regularizer and\nvolume preserving are integrated into a regularized optimal transport model,\nand the volume and classification constraints can be regarded as two measures\npreserving constraints in the optimal transport problem. By studying the dual\nproblem, we develop a simple and efficient dual algorithm for our model.\nMoreover, to be different from many variational based image segmentation\nalgorithms, the proposed algorithm can be directly unrolled to a new Volume\nPreserving and TV regularized softmax (VPTV-softmax) layer for semantic\nsegmentation in the popular Deep Convolution Neural Network (DCNN). The\nexperiment results show that our proposed model is very competitive and can\nimprove the performance of many semantic segmentation nets such as the popular\nU-net.",
    "Several supermodular losses have been shown to improve the perceptual quality\nof image segmentation in a discriminative framework such as a structured output\nsupport vector machine (SVM). These loss functions do not necessarily have the\nsame structure as the one used by the segmentation inference algorithm, and in\ngeneral, we may have to resort to generic submodular minimization algorithms\nfor loss augmented inference. Although these come with polynomial time\nguarantees, they are not practical to apply to image scale data. Many\nsupermodular losses come with strong optimization guarantees, but are not\nreadily incorporated in a loss augmented graph cuts procedure. This motivates\nour strategy of employing the alternating direction method of multipliers\n(ADMM) decomposition for loss augmented inference. In doing so, we create a new\nAPI for the structured SVM that separates the maximum a posteriori (MAP)\ninference of the model from the loss augmentation during training. In this way,\nwe gain computational efficiency, making new choices of loss functions\npractical for the first time, while simultaneously making the inference\nalgorithm employed during training closer to the test time procedure. We show\nimprovement both in accuracy and computational performance on the Microsoft\nResearch Grabcut database and a brain structure segmentation task, empirically\nvalidating the use of several supermodular loss functions during training, and\nthe improved computational properties of the proposed ADMM approach over the\nFujishige-Wolfe minimum norm point algorithm.",
    "In this paper, we propose to tackle the problem of reducing discrepancies\nbetween multiple domains referred to as multi-source domain adaptation and\nconsider it under the target shift assumption: in all domains we aim to solve a\nclassification problem with the same output classes, but with labels'\nproportions differing across them. This problem, generally ignored in the vast\nmajority papers on domain adaptation papers, is nevertheless critical in\nreal-world applications, and we theoretically show its impact on the adaptation\nsuccess. To address this issue, we design a method based on optimal transport,\na theory that has been successfully used to tackle adaptation problems in\nmachine learning. Our method performs multi-source adaptation and target shift\ncorrection simultaneously by learning the class probabilities of the unlabeled\ntarget sample and the coupling allowing to align two (or more) probability\ndistributions. Experiments on both synthetic and real-world data related to\nsatellite image segmentation task show the superiority of the proposed method\nover the state-of-the-art.",
    "Generative Adversarial Networks (GANs) have the capability of synthesizing\nimages, which have been successfully applied to medical image synthesis tasks.\nHowever, most of existing methods merely consider the global contextual\ninformation and ignore the fine foreground structures, e.g., vessel, skeleton,\nwhich may contain diagnostic indicators for medical image analysis. Inspired by\nhuman painting procedure, which is composed of stroking and color rendering\nsteps, we propose a Sketching-rendering Unconditional Generative Adversarial\nNetwork (SkrGAN) to introduce a sketch prior constraint to guide the medical\nimage generation. In our SkrGAN, a sketch guidance module is utilized to\ngenerate a high quality structural sketch from random noise, then a color\nrender mapping is used to embed the sketch-based representations and resemble\nthe background appearances. Experimental results show that the proposed SkrGAN\nachieves the state-of-the-art results in synthesizing images for various image\nmodalities, including retinal color fundus, X-Ray, Computed Tomography (CT) and\nMagnetic Resonance Imaging (MRI). In addition, we also show that the\nperformances of medical image segmentation method have been improved by using\nour synthesized images as data augmentation.",
    "  We consider a branching-selection system in $\\mathbb {R}$ with $N$ particles\nwhich give birth independently at rate 1 and where after each birth the\nleftmost particle is erased, keeping the number of particles constant. We show\nthat, as $N\\to\\infty$, the empirical measure process associated to the system\nconverges in distribution to a deterministic measure-valued process whose\ndensities solve a free boundary integro-differential equation. We also show\nthat this equation has a unique traveling wave solution traveling at speed $c$\nor no such solution depending on whether $c\\geq a$ or $c<a$, where $a$ is the\nasymptotic speed of the branching random walk obtained by ignoring the removal\nof the leftmost particles in our process. The traveling wave solutions\ncorrespond to solutions of Wiener-Hopf equations.\n",
    "  We extend the Wigner-Weyl-Moyal phase-space formulation of quantum mechanics\nto general curved configuration spaces. The underlying phase space is based on\nthe chosen coordinates of the manifold and their canonically conjugate momenta.\nThe resulting Wigner function displays the axioms of a quasiprobability\ndistribution, and any Weyl-ordered operator gets associated with the\ncorresponding phase-space function, even in the absence of continuous\nsymmetries. The corresponding quantum Liouville equation reduces to the\nclassical curved space Liouville equation in the semiclassical limit. We\ndemonstrate the formalism for a point particle moving on two-dimensional\nmanifolds, such as a paraboloid or the surface of a sphere. The latter\nclarifies the treatment of compact coordinate spaces as well as the relation of\nthe presented phase-space representation to symmetry groups of the\nconfiguration space.\n",
    "Semantic image segmentation is one of the most challenged tasks in computer\nvision. In this paper, we propose a highly fused convolutional network, which\nconsists of three parts: feature downsampling, combined feature upsampling and\nmultiple predictions. We adopt a strategy of multiple steps of upsampling and\ncombined feature maps in pooling layers with its corresponding unpooling\nlayers. Then we bring out multiple pre-outputs, each pre-output is generated\nfrom an unpooling layer by one-step upsampling. Finally, we concatenate these\npre-outputs to get the final output. As a result, our proposed network makes\nhighly use of the feature information by fusing and reusing feature maps. In\naddition, when training our model, we add multiple soft cost functions on\npre-outputs and final outputs. In this way, we can reduce the loss reduction\nwhen the loss is back propagated. We evaluate our model on three major\nsegmentation datasets: CamVid, PASCAL VOC and ADE20K. We achieve a\nstate-of-the-art performance on CamVid dataset, as well as considerable\nimprovements on PASCAL VOC dataset and ADE20K dataset",
    "  The high beam current and sub-angstrom resolution of aberration-corrected\nscanning transmission electron microscopes has enabled electron energy loss\nspectroscopic (EELS) mapping with atomic resolution. These spectral maps are\noften dose-limited and spatially oversampled, leading to low counts/channel and\nare thus highly sensitive to errors in background estimation. However, by\ntaking advantage of redundancy in the dataset map one can improve background\nestimation and increase chemical sensitivity. We consider two such approaches-\nlinear combination of power laws and local background averaging-that reduce\nbackground error and improve signal extraction. Principal components analysis\n(PCA) can also be used to analyze spectrum images, but the poor\npeak-to-background ratio in EELS can lead to serious artifacts if raw EELS data\nis PCA filtered. We identify common artifacts and discuss alternative\napproaches. These algorithms are implemented within the Cornell Spectrum\nImager, an open source software package for spectroscopic analysis.\n",
    "  Computing problems that handle large amounts of data necessitate the use of\nlossless data compression for efficient storage and transmission. We present a\nnovel lossless universal data compression algorithm that uses parallel\ncomputational units to increase the throughput. The length-$N$ input sequence\nis partitioned into $B$ blocks. Processing each block independently of the\nother blocks can accelerate the computation by a factor of $B$, but degrades\nthe compression quality. Instead, our approach is to first estimate the minimum\ndescription length (MDL) context tree source underlying the entire input, and\nthen encode each of the $B$ blocks in parallel based on the MDL source. With\nthis two-pass approach, the compression loss incurred by using more parallel\nunits is insignificant. Our algorithm is work-efficient, i.e., its\ncomputational complexity is $O(N/B)$. Its redundancy is approximately\n$B\\log(N/B)$ bits above Rissanen's lower bound on universal compression\nperformance, with respect to any context tree source whose maximal depth is at\nmost $\\log(N/B)$. We improve the compression by using different quantizers for\nstates of the context tree based on the number of symbols corresponding to\nthose states. Numerical results from a prototype implementation suggest that\nour algorithm offers a better trade-off between compression and throughput than\ncompeting universal data compression algorithms.\n",
    "  Grebinski and Kucherov (1998) and Alon et al. (2004-2005) study the problem\nof learning a hidden graph for some especial cases, such as hamiltonian cycle,\ncliques, stars, and matchings. This problem is motivated by problems in\nchemical reactions, molecular biology and genome sequencing.\n  In this paper, we present a generalization of this problem. Precisely, we\nconsider a graph G and a subgraph H of G and we assume that G contains exactly\none defective subgraph isomorphic to H. The goal is to find the defective\nsubgraph by testing whether an induced subgraph contains an edge of the\ndefective subgraph, with the minimum number of tests. We present an upper bound\nfor the number of tests to find the defective subgraph by using the symmetric\nand high probability variation of Lov\\'asz Local Lemma.\n",
    "  Solving the single-impurity Anderson model (SIAM) is a basic problem of solid\nstate physics. The SIAM model is very important, at present it is also used for\nsystems with quantum impurities, e.g. semiconductor quantum dots and molecular\ntransistors. Its main application is in the scheme of dynamical mean field\ntheory (DMFT) describing strong correlation electron systems. To solve the SIAM\nproblem we use the equation of motion (EOM) Green function approach. In this\nreport we present the novel EOM approximation in which we differentiate the\nGreen function over both time variables. This differs from the commonly used\nEOM solution by Appelbaum, Penn and Lacroix where the authors take time\nderivative only over primary time variable. After extending calculations to\nhigher order Green functions we find the new approximate dynamical solution of\nSIAM. The results are compared with the solutions to the SIAM problem at\nintermediate Coulomb repulsion U such as the Modified Iterative Perturbation\nTheory. Our approach is suitable for describing quantum dots.\n",
    "Purpose: To improve kidney segmentation in clinical ultrasound (US) images,\nwe develop a new graph cuts based method to segment kidney US images by\nintegrating original image intensity information and texture feature maps\nextracted using Gabor filters. Methods: To handle large appearance variation\nwithin kidney images and improve computational efficiency, we build a graph of\nimage pixels close to kidney boundary instead of building a graph of the whole\nimage. To make the kidney segmentation robust to weak boundaries, we adopt\nlocalized regional information to measure similarity between image pixels for\ncomputing edge weights to build the graph of image pixels. The localized graph\nis dynamically updated and the GC based segmentation iteratively progresses\nuntil convergence. The proposed method has been evaluated and compared with\nstate of the art image segmentation methods based on clinical kidney US images\nof 85 subjects. We randomly selected US images of 20 subjects as training data\nfor tuning the parameters, and validated the methods based on US images of the\nremaining 65 subjects. The segmentation results have been quantitatively\nanalyzed using 3 metrics, including Dice Index, Jaccard Index, and Mean\nDistance. Results: Experiment results demonstrated that the proposed method\nobtained segmentation results for bilateral kidneys of 65 subjects with average\nDice index of 0.9581, Jaccard index of 0.9204, and Mean Distance of 1.7166,\nbetter than other methods under comparison (p<10-19, paired Wilcoxon rank sum\ntests). Conclusions: The proposed method achieved promising performance for\nsegmenting kidneys in US images, better than segmentation methods that built on\nany single channel of image information. This method will facilitate extraction\nof kidney characteristics that may predict important clinical outcomes such\nprogression chronic kidney disease.",
    "Many computer vision problems can be formulated as binary quadratic programs\n(BQPs). Two classic relaxation methods are widely used for solving BQPs,\nnamely, spectral methods and semidefinite programming (SDP), each with their\nown advantages and disadvantages. Spectral relaxation is simple and easy to\nimplement, but its bound is loose. Semidefinite relaxation has a tighter bound,\nbut its computational complexity is high for large scale problems. We present a\nnew SDP formulation for BQPs, with two desirable properties. First, it has a\nsimilar relaxation bound to conventional SDP formulations. Second, compared\nwith conventional SDP methods, the new SDP formulation leads to a significantly\nmore efficient and scalable dual optimization approach, which has the same\ndegree of complexity as spectral methods. Extensive experiments on various\napplications including clustering, image segmentation, co-segmentation and\nregistration demonstrate the usefulness of our SDP formulation for solving\nlarge-scale BQPs.",
    "The goal of this paper is to present a new efficient image segmentation\nmethod based on evolutionary computation which is a model inspired from human\nbehavior. Based on this model, a four layer process for image segmentation is\nproposed using the split/merge approach. In the first layer, an image is split\ninto numerous regions using the watershed algorithm. In the second layer, a\nco-evolutionary process is applied to form centers of finals segments by\nmerging similar primary regions. In the third layer, a meta-heuristic process\nuses two operators to connect the residual regions to their corresponding\ndetermined centers. In the final layer, an evolutionary algorithm is used to\ncombine the resulted similar and neighbor regions. Different layers of the\nalgorithm are totally independent, therefore for certain applications a\nspecific layer can be changed without constraint of changing other layers. Some\nproperties of this algorithm like the flexibility of its method, the ability to\nuse different feature vectors for segmentation (grayscale, color, texture,\netc), the ability to control uniformity and the number of final segments using\nfree parameters and also maintaining small regions, makes it possible to apply\nthe algorithm to different applications. Moreover, the independence of each\nregion from other regions in the second layer, and the independence of centers\nin the third layer, makes parallel implementation possible. As a result the\nalgorithm speed will increase. The presented algorithm was tested on a standard\ndataset (BSDS 300) of images, and the region boundaries were compared with\ndifferent people segmentation contours. Results show the efficiency of the\nalgorithm and its improvement to similar methods. As an instance, in 70% of\ntested images, results are better than ACT algorithm, besides in 100% of tested\nimages, we had better results in comparison with VSP algorithm.",
    "One popular approach to interactively segment the foreground object of\ninterest from an image is to annotate a bounding box that covers the foreground\nobject. Then, a binary labeling is performed to achieve a refined segmentation.\nOne major issue of the existing algorithms for such interactive image\nsegmentation is their preference of an input bounding box that tightly encloses\nthe foreground object. This increases the annotation burden, and prevents these\nalgorithms from utilizing automatically detected bounding boxes. In this paper,\nwe develop a new LooseCut algorithm that can handle cases where the input\nbounding box only loosely covers the foreground object. We propose a new Markov\nRandom Fields (MRF) model for segmentation with loosely bounded boxes,\nincluding a global similarity constraint to better distinguish the foreground\nand background, and an additional energy term to encourage consistent labeling\nof similar-appearance pixels. This MRF model is then solved by an iterated\nmax-flow algorithm. In the experiments, we evaluate LooseCut in three\npublicly-available image datasets, and compare its performance against several\nstate-of-the-art interactive image segmentation algorithms. We also show that\nLooseCut can be used for enhancing the performance of unsupervised video\nsegmentation and image saliency detection.",
    "Automatic face recognition has received significant performance improvement\nby developing specialised facial image representations. On the other hand,\ngeneric object recognition has rarely been applied to the face recognition.\nSpatial pyramid pooling of features encoded by an over-complete dictionary has\nbeen the key component of many state-of-the-art image classification systems.\nInspired by its success, in this work we develop a new face image\nrepresentation method inspired by the second-order pooling in Carreira et al.\n[1], which was originally proposed for image segmentation. The proposed method\ndiffers from the previous methods in that, we encode the densely extracted\nlocal patches by a small-size dictionary; and the facial image signatures are\nobtained by pooling the second-order statistics of the encoded features. We\nshow the importance of pooling on encoded features, which is bypassed by the\noriginal second-order pooling method to avoid the high computational cost.\nEquipped with a simple linear classifier, the proposed method outperforms the\nstate-of-the-art face identification performance by large margins. For example,\non the LFW databases, the proposed method performs better than the previous\nbest by around 13% accuracy.",
    "  Traditionally, the Bayesian optimal auction design problem has been\nconsidered either when the bidder values are i.i.d., or when each bidder is\nindividually identifiable via her value distribution. The latter is a\nreasonable approach when the bidders can be classified into a few categories,\nbut there are many instances where the classification of bidders is a\ncontinuum. For example, the classification of the bidders may be based on their\nannual income, their propensity to buy an item based on past behavior, or in\nthe case of ad auctions, the click through rate of their ads. We introduce an\nalternate model that captures this aspect, where bidders are \\emph{a priori}\nidentical, but can be distinguished based (only) on some side information the\nauctioneer obtains at the time of the auction.\n  We extend the sample complexity approach of Dhangwatnotai, Roughgarden, and\nYan (2014) and Cole and Roughgarden (2014) to this model and obtain almost\nmatching upper and lower bounds. As an aside, we obtain a revenue monotonicity\nlemma which may be of independent interest. We also show how to use Empirical\nRisk Minimization techniques to improve the sample complexity bound of Cole and\nRoughgarden (2014) for the non-identical but independent value distribution\ncase.\n",
    "  Graded posets frequently arise throughout combinatorics, where it is natural\nto try to count the number of elements of a fixed rank. These counting problems\nare often $\\#\\textbf{P}$-complete, so we consider approximation algorithms for\ncounting and uniform sampling. We show that for certain classes of posets,\nbiased Markov chains that walk along edges of their Hasse diagrams allow us to\napproximately generate samples with any fixed rank in expected polynomial time.\nOur arguments do not rely on the typical proofs of log-concavity, which are\nused to construct a stationary distribution with a specific mode in order to\ngive a lower bound on the probability of outputting an element of the desired\nrank. Instead, we infer this directly from bounds on the mixing time of the\nchains through a method we call $\\textit{balanced bias}$.\n  A noteworthy application of our method is sampling restricted classes of\ninteger partitions of $n$. We give the first provably efficient Markov chain\nalgorithm to uniformly sample integer partitions of $n$ from general restricted\nclasses. Several observations allow us to improve the efficiency of this chain\nto require $O(n^{1/2}\\log(n))$ space, and for unrestricted integer partitions,\nexpected $O(n^{9/4})$ time. Related applications include sampling permutations\nwith a fixed number of inversions and lozenge tilings on the triangular lattice\nwith a fixed average height.\n",
    "Semantic segmentation is one of the basic, yet essential scene understanding\ntasks for an autonomous agent. The recent developments in supervised machine\nlearning and neural networks have enjoyed great success in enhancing the\nperformance of the state-of-the-art techniques for this task. However, their\nsuperior performance is highly reliant on the availability of a large-scale\nannotated dataset. In this paper, we propose a novel fully unsupervised\nsemantic segmentation method, the so-called Information Maximization and\nAdversarial Regularization Segmentation (InMARS). Inspired by human perception\nwhich parses a scene into perceptual groups, rather than analyzing each pixel\nindividually, our proposed approach first partitions an input image into\nmeaningful regions (also known as superpixels). Next, it utilizes\nMutual-Information-Maximization followed by an adversarial training strategy to\ncluster these regions into semantically meaningful classes. To customize an\nadversarial training scheme for the problem, we incorporate adversarial pixel\nnoise along with spatial perturbations to impose photometrical and geometrical\ninvariance on the deep neural network. Our experiments demonstrate that our\nmethod achieves the state-of-the-art performance on two commonly used\nunsupervised semantic segmentation datasets, COCO-Stuff, and Potsdam.",
    "  Reactive Turing machines extend classical Turing machines with a facility to\nmodel observable interactive behaviour. We call a behaviour (finitely)\nexecutable if, and only if, it is equivalent to the behaviour of a (finite)\nreactive Turing machine. In this paper, we study the relationship between\nexecutable behaviour and behaviour that can be specified in the $\\pi$-calculus.\nWe establish that every finitely executable behaviour can be specified in the\n$\\pi$-calculus up to divergence-preserving branching bisimilarity. The\nconverse, however, is not true due to (intended) limitations of the model of\nreactive Turing machines. That is, the $\\pi$-calculus allows the specification\nof behaviour that is not finitely executable up to divergence-preserving\nbranching bisimilarity. We shall prove, however, that if the finiteness\nrequirement on reactive Turing machines and the associated notion of\nexecutability is relaxed to orbit-finiteness, then the $\\pi$-calculus is\nexecutable up to (divergence-insensitive) branching bisimilarity.\n",
    "  Let $k$ a field of characteristic zero. Let $X$ be a smooth, projective,\ngeometrically rational $k$-surface. Let $\\mathcal{T}$ be a universal torsor\nover $X$ with a $k$-point et $\\mathcal{T}^c$ a smooth compactification of\n$\\mathcal{T}$. There is an open question: is $\\mathcal{T}^c$ $k$-birationally\nequivalent to a projective space? We know that the unramified cohomology groups\nof degree 1 and 2 of $\\mathcal{T}$ and $\\mathcal{T}^c$ are reduced to their\nconstant part. For the analogue of the third cohomology groups, we give a\nsufficient condition using the Galois structure of the geometrical Picard group\nof $X$. This enables us to show that\n$H^{3}_{nr}(\\mathcal{T}^{c},\\mathbb{Q}/\\mathbb{Z}(2))/H^3(k,\\mathbb{Q}/\\mathbb{Z}(2))$\nvanishes if $X$ is a generalised Ch\\^atelet surface and that this group is\nreduced to its $2$-primary part if $X$ is a del Pezzo surface of degree at\nleast 2.\n",
    "At present, adversarial attacks are designed in a task-specific fashion.\nHowever, for downstream computer vision tasks such as image captioning, image\nsegmentation etc., the current deep learning systems use an image classifier\nlike VGG16, ResNet50, Inception-v3 etc. as a feature extractor. Keeping this in\nmind, we propose Mimic and Fool, a task agnostic adversarial attack. Given a\nfeature extractor, the proposed attack finds an adversarial image which can\nmimic the image feature of the original image. This ensures that the two images\ngive the same (or similar) output regardless of the task. We randomly select\n1000 MSCOCO validation images for experimentation. We perform experiments on\ntwo image captioning models, Show and Tell, Show Attend and Tell and one VQA\nmodel, namely, end-to-end neural module network (N2NMN). The proposed attack\nachieves success rate of 74.0%, 81.0% and 87.1% for Show and Tell, Show Attend\nand Tell and N2NMN respectively. We also propose a slight modification to our\nattack to generate natural-looking adversarial images. In addition, we also\nshow the applicability of the proposed attack for invertible architecture.\nSince Mimic and Fool only requires information about the feature extractor of\nthe model, it can be considered as a gray-box attack.",
    "Machine learning has been widely adopted for medical image analysis in recent\nyears given its promising performance in image segmentation and classification\ntasks. As a data-driven science, the success of machine learning, in particular\nsupervised learning, largely depends on the availability of manually annotated\ndatasets. For medical imaging applications, such annotated datasets are not\neasy to acquire. It takes a substantial amount of time and resource to curate\nan annotated medical image set. In this paper, we propose an efficient\nannotation framework for brain tumour images that is able to suggest\ninformative sample images for human experts to annotate. Our experiments show\nthat training a segmentation model with only 19% suggestively annotated patient\nscans from BraTS 2019 dataset can achieve a comparable performance to training\na model on the full dataset for whole tumour segmentation task. It demonstrates\na promising way to save manual annotation cost and improve data efficiency in\nmedical imaging applications.",
    "  This paper aims at constructing a good graph for discovering intrinsic data\nstructures in a semi-supervised learning setting. Firstly, we propose to build\na non-negative low-rank and sparse (referred to as NNLRS) graph for the given\ndata representation. Specifically, the weights of edges in the graph are\nobtained by seeking a nonnegative low-rank and sparse matrix that represents\neach data sample as a linear combination of others. The so-obtained NNLRS-graph\ncan capture both the global mixture of subspaces structure (by the low\nrankness) and the locally linear structure (by the sparseness) of the data,\nhence is both generative and discriminative. Secondly, as good features are\nextremely important for constructing a good graph, we propose to learn the data\nembedding matrix and construct the graph jointly within one framework, which is\ntermed as NNLRS with embedded features (referred to as NNLRS-EF). Extensive\nexperiments on three publicly available datasets demonstrate that the proposed\nmethod outperforms the state-of-the-art graph construction method by a large\nmargin for both semi-supervised classification and discriminative analysis,\nwhich verifies the effectiveness of our proposed method.\n",
    "  All quantum gates with one and two qubits may be described by elements of\n$Spin$ groups due to isomorphisms $Spin(3) \\simeq SU(2)$ and $Spin(6) \\simeq\nSU(4)$. However, the group of $n$-qubit gates $SU(2^n)$ for $n > 2$ has bigger\ndimension than $Spin(3n)$. A quantum circuit with one- and two-qubit gates may\nbe used for construction of arbitrary unitary transformation $SU(2^n)$.\nAnalogously, the `$Spin(3n)$ circuits' are introduced in this work as products\nof elements associated with one- and two-qubit gates with respect to the\nabove-mentioned isomorphisms.\n  The matrix tensor product implementation of the $Spin(3n)$ group together\nwith relevant models by usual quantum circuits with $2n$ qubits are\ninvestigated in such a framework. A certain resemblance with well-known sets of\nnon-universal quantum gates e.g., matchgates, noninteracting-fermion quantum\ncircuits) related with $Spin(2n)$ may be found in presented approach. Finally,\na possibility of the classical simulation of such circuits in polynomial time\nis discussed.\n",
    "We introduce $\\textit{InExtremIS}$, a weakly supervised 3D approach to train\na deep image segmentation network using particularly weak train-time\nannotations: only 6 extreme clicks at the boundary of the objects of interest.\nOur fully-automatic method is trained end-to-end and does not require any\ntest-time annotations. From the extreme points, 3D bounding boxes are extracted\naround objects of interest. Then, deep geodesics connecting extreme points are\ngenerated to increase the amount of \"annotated\" voxels within the bounding\nboxes. Finally, a weakly supervised regularised loss derived from a Conditional\nRandom Field formulation is used to encourage prediction consistency over\nhomogeneous regions. Extensive experiments are performed on a large open\ndataset for Vestibular Schwannoma segmentation. $\\textit{InExtremIS}$ obtained\ncompetitive performance, approaching full supervision and outperforming\nsignificantly other weakly supervised techniques based on bounding boxes.\nMoreover, given a fixed annotation time budget, $\\textit{InExtremIS}$\noutperforms full supervision. Our code and data are available online.",
    "Hourglass networks such as the U-Net and V-Net are popular neural\narchitectures for medical image segmentation and counting problems. Typical\ninstances of hourglass networks contain shortcut connections between mirroring\nlayers. These shortcut connections improve the performance and it is\nhypothesized that this is due to mitigating effects on the vanishing gradient\nproblem and the ability of the model to combine feature maps from earlier and\nlater layers. We propose a method for not only combining feature maps of\nmirroring layers but also feature maps of layers with different spatial\ndimensions. For instance, the method enables the integration of the bottleneck\nfeature map with those of the reconstruction layers. The proposed approach is\napplicable to any hourglass architecture. We evaluated the contextual hourglass\nnetworks on image segmentation and object counting problems in the medical\ndomain. We achieve competitive results outperforming popular hourglass networks\nby up to 17 percentage points.",
    "Image segmentation is the process of partitioning the image into significant\nregions easier to analyze. Nowadays, segmentation has become a necessity in\nmany practical medical imaging methods as locating tumors and diseases. Hidden\nMarkov Random Field model is one of several techniques used in image\nsegmentation. It provides an elegant way to model the segmentation process.\nThis modeling leads to the minimization of an objective function. Conjugate\nGradient algorithm (CG) is one of the best known optimization techniques. This\npaper proposes the use of the Conjugate Gradient algorithm (CG) for image\nsegmentation, based on the Hidden Markov Random Field. Since derivatives are\nnot available for this expression, finite differences are used in the CG\nalgorithm to approximate the first derivative. The approach is evaluated using\na number of publicly available images, where ground truth is known. The Dice\nCoefficient is used as an objective criterion to measure the quality of\nsegmentation. The results show that the proposed CG approach compares favorably\nwith other variants of Hidden Markov Random Field segmentation algorithms.",
    "  The aim of this note is to introduce the notion of a $\\operatorname{D}$-Lie\nalgebra and to prove some elementary properties of $\\operatorname{D}$-Lie\nalgebras, the category of $\\operatorname{D}$-Lie algebras, the category of\nmodules on a $\\operatorname{D}$-Lie algebra and extensions of\n$\\operatorname{D}$-Lie algebras. A $\\operatorname{D}$-Lie algebra is an\n$A/k$-Lie-Rinehart algebra equipped with an $A\\otimes_k A$-module structure and\na canonical central element $D$ and a compatibility property between the\n$k$-Lie algebra structure and the $A\\otimes_k A$-module structure. Several\nauthors have studied non-abelian extensions of Lie algebras, super Lie\nalgebras, Lie algebroids and holomorphic Lie algebroids and we give in this\nnote an explicit constructions of all non-abelian extensions a\n$\\operatorname{D}$-Lie algebra $\\tilde{L}$ by an $A$-Lie algebra $(W,[,])$\nwhere $\\tilde{L}$ is projective as left $A$-module and $W$ is an $A\\otimes_k\nA$-module with $IW=0$ for $I$ the kernel of the multiplication map. As a\ncorollary we get an explicit construction of all non-abelian extensions of an\n$A/k$-Lie-Rinehart algebra $(L,\\alpha)$ by an $A$-Lie algebra $(W,[,])$ where\n$L$ is projective as left $A$-module.\n",
    "This work explores the use of computer vision for image segmentation and\nclassification of medical fluid samples in transparent containers (for example,\ntubes, syringes, infusion bags). Handling fluids such as infusion fluids,\nblood, and urine samples is a significant part of the work carried out in\nmedical labs and hospitals. The ability to accurately identify and segment the\nliquids and the vessels that contain them from images can help in automating\nsuch processes. Modern computer vision typically involves training deep neural\nnets on large datasets of annotated images. This work presents a new dataset\ncontaining 1,300 annotated images of medical samples involving vessels\ncontaining liquids and solid material. The images are annotated with the type\nof liquid (e.g., blood, urine), the phase of the material (e.g., liquid, solid,\nfoam, suspension), the type of vessel (e.g., syringe, tube, cup, infusion\nbottle/bag), and the properties of the vessel (transparent, opaque). In\naddition, vessel parts such as corks, labels, spikes, and valves are annotated.\nRelations and hierarchies between vessels and materials are also annotated,\nsuch as which vessel contains which material or which vessels are linked or\ncontain each other. Three neural networks are trained on the dataset: One\nnetwork learns to detect vessels, a second net detects the materials and parts\ninside each vessel, and a third net identifies relationships and connectivity\nbetween vessels.",
    "  The Efficient Market Hypothesis (EMH) is widely accepted to hold true under\ncertain assumptions. One of its implications is that the prediction of stock\nprices at least in the short run cannot outperform the random walk model. Yet,\nrecently many studies stressing the psychological and social dimension of\nfinancial behavior have challenged the validity of the EMH. Towards this aim,\nover the last few years, internet-based communication platforms and search\nengines have been used to extract early indicators of social and economic\ntrends. Here, we used Twitter's social networking platform to model and\nforecast the EUR/USD exchange rate in a high-frequency intradaily trading\nscale. Using time series and trading simulations analysis, we provide some\nevidence that the information provided in social microblogging platforms such\nas Twitter can in certain cases enhance the forecasting efficiency regarding\nthe very short (intradaily) forex.\n",
    "We present the 2017 Visual Domain Adaptation (VisDA) dataset and challenge, a\nlarge-scale testbed for unsupervised domain adaptation across visual domains.\nUnsupervised domain adaptation aims to solve the real-world problem of domain\nshift, where machine learning models trained on one domain must be transferred\nand adapted to a novel visual domain without additional supervision. The\nVisDA2017 challenge is focused on the simulation-to-reality shift and has two\nassociated tasks: image classification and image segmentation. The goal in both\ntracks is to first train a model on simulated, synthetic data in the source\ndomain and then adapt it to perform well on real image data in the unlabeled\ntest domain. Our dataset is the largest one to date for cross-domain object\nclassification, with over 280K images across 12 categories in the combined\ntraining, validation and testing domains. The image segmentation dataset is\nalso large-scale with over 30K images across 18 categories in the three\ndomains. We compare VisDA to existing cross-domain adaptation datasets and\nprovide a baseline performance analysis using various domain adaptation models\nthat are currently popular in the field.",
    "Deep learning techniques for 3D brain vessel image segmentation have not been\nas successful as in the segmentation of other organs and tissues. This can be\nexplained by two factors. First, deep learning techniques tend to show poor\nperformances at the segmentation of relatively small objects compared to the\nsize of the full image. Second, due to the complexity of vascular trees and the\nsmall size of vessels, it is challenging to obtain the amount of annotated\ntraining data typically needed by deep learning methods. To address these\nproblems, we propose a novel annotation-efficient deep learning vessel\nsegmentation framework. The framework avoids pixel-wise annotations, only\nrequiring weak patch-level labels to discriminate between vessel and non-vessel\n2D patches in the training set, in a setup similar to the CAPTCHAs used to\ndifferentiate humans from bots in web applications. The user-provided weak\nannotations are used for two tasks: 1) to synthesize pixel-wise pseudo-labels\nfor vessels and background in each patch, which are used to train a\nsegmentation network, and 2) to train a classifier network. The classifier\nnetwork allows to generate additional weak patch labels, further reducing the\nannotation burden, and it acts as a noise filter for poor quality images. We\nuse this framework for the segmentation of the cerebrovascular tree in\nTime-of-Flight angiography (TOF) and Susceptibility-Weighted Images (SWI). The\nresults show that the framework achieves state-of-the-art accuracy, while\nreducing the annotation time by ~77% w.r.t. learning-based segmentation methods\nusing pixel-wise labels for training.",
    "Dense 3D visual mapping estimates as many as possible pixel depths, for each\nimage. This results in very dense point clouds that often contain redundant and\nnoisy information, especially for surfaces that are roughly planar, for\ninstance, the ground or the walls in the scene. In this paper we leverage on\nsemantic image segmentation to discriminate which regions of the scene require\nsimplification and which should be kept at high level of details. We propose\nfour different point cloud simplification methods which decimate the perceived\npoint cloud by relying on class-specific local and global statistics still\nmaintaining more points in the proximity of class boundaries to preserve the\ninfra-class edges and discontinuities. 3D dense model is obtained by fusing the\npoint clouds in a 3D Delaunay Triangulation to deal with variable point cloud\ndensity. In the experimental evaluation we have shown that, by leveraging on\nsemantics, it is possible to simplify the model and diminish the noise\naffecting the point clouds.",
    "The task of medical image segmentation commonly involves an image\nreconstruction step to convert acquired raw data to images before any analysis.\nHowever, noises, artifacts and loss of information due to the reconstruction\nprocess are almost inevitable, which compromises the final performance of\nsegmentation. We present a novel learning framework that performs magnetic\nresonance brain image segmentation directly from k-space data. The end-to-end\nframework consists of a unique task-driven attention module that recurrently\nutilizes intermediate segmentation estimation to facilitate image-domain\nfeature extraction from the raw data, thus closely bridging the reconstruction\nand the segmentation tasks. In addition, to address the challenge of manual\nlabeling, we introduce a novel workflow to generate labeled training data for\nsegmentation by exploiting imaging modality simulators and digital phantoms.\nExtensive experimental results show that the proposed method outperforms\nseveral state-of-the-art methods.",
    "Fully convolutional neural networks (FCNNs) trained on a large number of\nimages with strong pixel-level annotations have become the new state of the art\nfor the semantic segmentation task. While there have been recent attempts to\nlearn FCNNs from image-level weak annotations, they need additional\nconstraints, such as the size of an object, to obtain reasonable performance.\nTo address this issue, we present motion-CNN (M-CNN), a novel FCNN framework\nwhich incorporates motion cues and is learned from video-level weak\nannotations. Our learning scheme to train the network uses motion segments as\nsoft constraints, thereby handling noisy motion information. When trained on\nweakly-annotated videos, our method outperforms the state-of-the-art EM-Adapt\napproach on the PASCAL VOC 2012 image segmentation benchmark. We also\ndemonstrate that the performance of M-CNN learned with 150 weak video\nannotations is on par with state-of-the-art weakly-supervised methods trained\nwith thousands of images. Finally, M-CNN substantially outperforms recent\napproaches in a related task of video co-localization on the YouTube-Objects\ndataset.",
    "We present MBIS (Multivariate Bayesian Image Segmentation tool), a clustering\ntool based on the mixture of multivariate normal distributions model. MBIS\nsupports multi-channel bias field correction based on a B-spline model. A\nsecond methodological novelty is the inclusion of graph-cuts optimization for\nthe stationary anisotropic hidden Markov random field model. Along with MBIS,\nwe release an evaluation framework that contains three different experiments on\nmulti-site data. We first validate the accuracy of segmentation and the\nestimated bias field for each channel. MBIS outperforms a widely used\nsegmentation tool in a cross-comparison evaluation. The second experiment\ndemonstrates the robustness of results on atlas-free segmentation of two image\nsets from scan-rescan protocols on 21 healthy subjects. Multivariate\nsegmentation is more replicable than the monospectral counterpart on\nT1-weighted images. Finally, we provide a third experiment to illustrate how\nMBIS can be used in a large-scale study of tissue volume change with increasing\nage in 584 healthy subjects. This last result is meaningful as multivariate\nsegmentation performs robustly without the need for prior knowledge",
    "  In this paper, we briefly review most of accomplished research in Riemann\nZeta function and Riemann hypothesis since Riemann's age including Riemann\nhypothesis equivalences as well. We then make use of Robin and Lagarias'\ncriteria to prove Riemann hypothesis. The goal is, using Lagarias criterion for\n$n\\geq 1$ since Lagarias criterion states that Riemann hypothesis holds if and\nonly if the inequality $\\sum_{d|n}d\\leq H_{n}+\\exp(H_{n})\\log(H_{n})$ holds for\nall $n\\geq 1$. Although, Robin's criterion is used as well. Our approach breaks\nup the set of the natural numbers into three main subsets. The first subset is\n$\\{n\\in \\mathbb{N}| ~ 1\\leq n\\leq 5040\\}$. The second one is $\\{n\\in\n\\mathbb{N}| ~ 5041\\leq n\\leq 19685\\}$ and the third one is $\\{n\\in \\mathbb{N}|\n~ n\\geq 19686\\}$. In our proof, the third subset for even integers is broken up\ninto odd integer class number sets. Then, mathematical arguments are stated for\neach odd integer class number set. Odd integer class number set is introduced\nin this paper. Since the Lagarias criterion holds for the first subset\nregarding computer aided computations, we do prove it using both Lagarias and\nRobin's criteria for the second and third subsets and mathematical arguments\naccompanied by a large volume of computer language programs. It then follows\nthat Riemann hypothesis holds as well.\n",
    "Single encoder-decoder methodologies for semantic segmentation are reaching\ntheir peak in terms of segmentation quality and efficiency per number of\nlayers. To address these limitations, we propose a new architecture based on a\ndecoder which uses a set of shallow networks for capturing more information\ncontent. The new decoder has a new topology of skip connections, namely\nbackward and stacked residual connections. In order to further improve the\narchitecture we introduce a weight function which aims to re-balance classes to\nincrease the attention of the networks to under-represented objects. We carried\nout an extensive set of experiments that yielded state-of-the-art results for\nthe CamVid, Gatech and Freiburg Forest datasets. Moreover, to further prove the\neffectiveness of our decoder, we conducted a set of experiments studying the\nimpact of our decoder to state-of-the-art segmentation techniques.\nAdditionally, we present a set of experiments augmenting semantic segmentation\nwith optical flow information, showing that motion clues can boost pure image\nbased semantic segmentation approaches.",
    "Today's success of state of the art methods for semantic segmentation is\ndriven by large datasets. Data is considered an important asset that needs to\nbe protected, as the collection and annotation of such datasets comes at\nsignificant efforts and associated costs. In addition, visual data might\ncontain private or sensitive information, that makes it equally unsuited for\npublic release. Unfortunately, recent work on membership inference in the\nbroader area of adversarial machine learning and inference attacks on machine\nlearning models has shown that even black box classifiers leak information on\nthe dataset that they were trained on. We show that such membership inference\nattacks can be successfully carried out on complex, state of the art models for\nsemantic segmentation. In order to mitigate the associated risks, we also study\na series of defenses against such membership inference attacks and find\neffective counter measures against the existing risks with little effect on the\nutility of the segmentation method. Finally, we extensively evaluate our\nattacks and defenses on a range of relevant real-world datasets: Cityscapes,\nBDD100K, and Mapillary Vistas.",
    "  We present a coarse-graining strategy that we test for aqueous mixtures. The\nmethod uses pair-wise cumulative coordination as a target function within an\niterative Boltzmann inversion (IBI) like protocol. We name this method\ncoordination iterative Boltzmann inversion ($\\mathcal {C}-$IBI). While the\nunderlying coarse-grained model is still structure based and, thus, preserves\npair-wise solution structure, our method also reproduces solvation\nthermodynamics of binary and/or ternary mixtures. Additionally, we observe much\nfaster convergence within $\\mathcal {C}-$IBI compared to IBI. To validate the\nrobustness, we apply $\\mathcal {C}-$IBI to study test cases of solvation\nthermodynamics of aqueous urea and a triglycine solvation in aqueous urea.\n",
    "  We show that one-way quantum one-counter automaton with zero-error is more\npowerful than its probabilistic counterpart on promise problems. Then, we\nobtain a similar separation result between Las Vegas one-way probabilistic\none-counter automaton and one-way deterministic one-counter automaton.\n  We also obtain new results on classical counter automata regarding language\nrecognition. It was conjectured that one-way probabilistic one blind-counter\nautomata cannot recognize Kleene closure of equality language [A. Yakaryilmaz:\nSuperiority of one-way and realtime quantum machines. RAIRO - Theor. Inf. and\nApplic. 46(4): 615-641 (2012)]. We show that this conjecture is false, and also\nshow several separation results for blind/non-blind counter automata.\n",
    "The segmentation of digital images is one of the essential steps in image\nprocessing or a computer vision system. It helps in separating the pixels into\ndifferent regions according to their intensity level. A large number of\nsegmentation techniques have been proposed, and a few of them use complex\ncomputational operations. Among all, the most straightforward procedure that\ncan be easily implemented is thresholding. In this paper, we present a unique\nheuristic approach for image segmentation that automatically determines\nmultilevel thresholds by sampling the histogram of a digital image. Our\napproach emphasis on selecting a valley as optimal threshold values. We\ndemonstrated that our approach outperforms the popular Otsu's method in terms\nof CPU computational time. We demonstrated that our approach outperforms the\npopular Otsu's method in terms of CPU computational time. We observed a maximum\nspeed-up of 35.58x and a minimum speed-up of 10.21x on popular image processing\nbenchmarks. To demonstrate the correctness of our approach in determining\nthreshold values, we compute PSNR, SSIM, and FSIM values to compare with the\nvalues obtained by Otsu's method. This evaluation shows that our approach is\ncomparable and better in many cases as compared to well known Otsu's method.",
    "A multi-scale greedy-based object proposal generation approach is presented.\nBased on the multi-scale nature of objects in images, our approach is built on\ntop of a hierarchical segmentation. We first identify the representative and\ndiverse exemplar clusters within each scale by using a diversity ranking\nalgorithm. Object proposals are obtained by selecting a subset from the\nmulti-scale segment pool via maximizing a submodular objective function, which\nconsists of a weighted coverage term, a single-scale diversity term and a\nmulti-scale reward term. The weighted coverage term forces the selected set of\nobject proposals to be representative and compact; the single-scale diversity\nterm encourages choosing segments from different exemplar clusters so that they\nwill cover as many object patterns as possible; the multi-scale reward term\nencourages the selected proposals to be discriminative and selected from\nmultiple layers generated by the hierarchical image segmentation. The\nexperimental results on the Berkeley Segmentation Dataset and PASCAL VOC2012\nsegmentation dataset demonstrate the accuracy and efficiency of our object\nproposal model. Additionally, we validate our object proposals in simultaneous\nsegmentation and detection and outperform the state-of-art performance.",
    "  Light trapping in sub-wavelength semiconductor nanowires (NWs) offers a\npromising approach to simultaneously reducing material consumption and\nenhancing photovoltaic performance. Nevertheless, the absorption efficiency of\na NW, defined by the ratio of optical absorption cross section to the NW\ndiameter, lingers around 1 in existing NW photonic devices, and the absorption\nenhancement suffers from a narrow spectral width. Here, we show that the\nabsorption efficiency can be significantly improved in NWs with higher\nrefractive indices, by an experimental observation of up to 350% external\nquantum efficiency (EQE) in lead sulfide (PbS) NW resonators, a 3-fold increase\ncompared to Si NWs. Furthermore, broadband absorption enhancement is achieved\nin single tapered NWs, where light of various wavelengths is absorbed at\nsegments with different diameters analogous to a tandem solar cell. Overall,\nthe single NW Schottky junction solar cells benefit from optical resonance,\nnear bandgap open circuit voltage, and long minority carrier diffusion length,\ndemonstrating power conversion efficiency (PCE) comparable to single Si NW\ncoaxial p-n junction cells11, but with much simpler fabrication processes.\n",
    "We present a Deep Differentiable Simplex Layer (DDSL) for neural networks for\ngeometric deep learning. The DDSL is a differentiable layer compatible with\ndeep neural networks for bridging simplex mesh-based geometry representations\n(point clouds, line mesh, triangular mesh, tetrahedral mesh) with raster images\n(e.g., 2D/3D grids). The DDSL uses Non-Uniform Fourier Transform (NUFT) to\nperform differentiable, efficient, anti-aliased rasterization of simplex-based\nsignals. We present a complete theoretical framework for the process as well as\nan efficient backpropagation algorithm. Compared to previous differentiable\nrenderers and rasterizers, the DDSL generalizes to arbitrary simplex degrees\nand dimensions. In particular, we explore its applications to 2D shapes and\nillustrate two applications of this method: (1) mesh editing and optimization\nguided by neural network outputs, and (2) using DDSL for a differentiable\nrasterization loss to facilitate end-to-end training of polygon generators. We\nare able to validate the effectiveness of gradient-based shape optimization\nwith the example of airfoil optimization, and using the differentiable\nrasterization loss to facilitate end-to-end training, we surpass state of the\nart for polygonal image segmentation given ground-truth bounding boxes.",
    "The task of counting eucalyptus trees from aerial images collected by\nunmanned aerial vehicles (UAVs) has been frequently explored by techniques of\nestimation of the basal area, i.e, by determining the expected number of trees\nbased on sampling techniques. An alternative is the use of machine learning to\nidentify patterns that represent a tree unit, and then search for the\noccurrence of these patterns throughout the image. This strategy depends on a\nsupervised image segmentation step to define predefined interest regions. Thus,\nit is possible to automate the counting of eucalyptus trees in these images,\nthereby increasing the efficiency of the eucalyptus forest inventory\nmanagement. In this paper, we evaluated 20 different classifiers for the image\nsegmentation task. A real sample was used to analyze the counting trees task\nconsidering a practical environment. The results show that it possible to\nautomate this task with 0.7% counting error, in particular, by using strategies\nbased on a combination of classifiers. Moreover, we present some performance\nconsiderations about each classifier that can be useful as a basis for\ndecision-making in future tasks.",
    "  Transverse oscillatory motions and recurrence behavior in the chromospheric\njets observed by Hinode/SOT are studied. A comparison is considered with the\nbehavior that was noticed in coronal X-ray jets observed by Hinode/XRT. A jet\nlike bundle observed at the limb in Ca II H line appears to show a magnetic\ntopology that is similar to X-ray jets (i.e., the Eiffel tower shape). The\nappearance of such magnetic topology is usually assumed to be caused by\nmagnetic reconnection near a null point. Transverse motions of the jet axis are\nrecorded but no clear evidence of twist is appearing from the highly processed\nmovie. The aim is to investigate the dynamical behavior of an incompressible\nmagnetic X-point occurring during the magnetic reconnection in the jet\nformation region. The viscous effect is specially considered in the closed\nline-tied magnetic X-shape nulls. We perform the MHD numerical simulation in\n2-D by solving the visco-resistive MHD equations with the tracing of velocity\nand magnetic field. A qualitative agreement with Hinode observations is found\nfor the oscillatory and non-oscillatory behaviors of the observed solar jets in\nboth the chromosphere and the corona. Our results suggest that the viscous\neffect contributes to the excitation of the magnetic reconnection by generating\noscillations that we observed at least inside this Ca II H line cool solar jet\nbundle.\n",
    "  The problem of determining the number of \"flooding operations\" required to\nmake a given coloured graph monochromatic in the one-player combinatorial game\nFlood-It has been studied extensively from an algorithmic point of view, but\nbasic questions about the maximum number of moves that might be required in the\nworst case remain unanswered. We begin a systematic investigation of such\nquestions, with the goal of determining, for a given graph, the maximum number\nof moves that may be required, taken over all possible colourings. We give\nseveral upper and lower bounds on this quantity for arbitrary graphs and show\nthat all of the bounds are tight for trees; we also investigate how much the\nupper bounds can be improved if we restrict our attention to graphs with higher\nedge-density.\n",
    "  This paper presents a detailed modeling and analysis regarding the dispersion\ncharacteristics of multilayered open coaxial waveguides. The study is motivated\nby the need of improved modeling and an increased physical understanding about\nthe wave propagation phenomena on very long power cables which has a potential\nindustrial application with fault localization and monitoring. The\nelectromagnetic model is based on a layer recursive computation of\naxial-symmetric fields in connection with a magnetic frill generator excitation\nthat can be calibrated to the current measured at the input of the cable. The\nlayer recursive formulation enables a stable and efficient numerical\ncomputation of the related dispersion functions as well as a detailed analysis\nregarding the analytic and asymptotic properties of the associated\ndeterminants. Modal contributions as well as the contribution from the\nassociated branch-cut (non-discrete radiating modes) are defined and analyzed.\nMeasurements and modeling of pulse propagation on an 82 km long HVDC power\ncable are presented as a concrete example. In this example, it is concluded\nthat the contribution from the second TM mode as well as from the branch-cut is\nnegligible for all practical purposes. However, it is also shown that for\nextremely long power cables the contribution from the branch-cut can in fact\ndominate over the quasi-TEM mode for some frequency intervals. The main\ncontribution of this paper is to provide the necessary analysis tools for a\nquantitative study of these phenomena.\n",
    "To improve the classification performance in the context of hyperspectral\nimage processing, many works have been developed based on two common\nstrategies, namely the spatial-spectral information integration and the\nutilization of neural networks. However, both strategies typically require more\ntraining data than the classical algorithms, aggregating the shortage of\nlabeled samples. In this letter, we propose a novel framework that organically\ncombines the spectrum-based deep metric learning model and the conditional\nrandom field algorithm. The deep metric learning model is supervised by the\ncenter loss to produce spectrum-based features that gather more tightly in\nEuclidean space within classes. The conditional random field with Gaussian edge\npotentials, which is firstly proposed for image segmentation tasks, is\nintroduced to give the pixel-wise classification over the hyperspectral image\nby utilizing both the geographical distances between pixels and the Euclidean\ndistances between the features produced by the deep metric learning model. The\nproposed framework is trained by spectral pixels at the deep metric learning\nstage and utilizes the half handcrafted spatial features at the conditional\nrandom field stage. This settlement alleviates the shortage of training data to\nsome extent. Experiments on two real hyperspectral images demonstrate the\nadvantages of the proposed method in terms of both classification accuracy and\ncomputation cost.",
    "In this chapter we review the main literature related to kernel spectral\nclustering (KSC), an approach to clustering cast within a kernel-based\noptimization setting. KSC represents a least-squares support vector machine\nbased formulation of spectral clustering described by a weighted kernel PCA\nobjective. Just as in the classifier case, the binary clustering model is\nexpressed by a hyperplane in a high dimensional space induced by a kernel. In\naddition, the multi-way clustering can be obtained by combining a set of binary\ndecision functions via an Error Correcting Output Codes (ECOC) encoding scheme.\nBecause of its model-based nature, the KSC method encompasses three main steps:\ntraining, validation, testing. In the validation stage model selection is\nperformed to obtain tuning parameters, like the number of clusters present in\nthe data. This is a major advantage compared to classical spectral clustering\nwhere the determination of the clustering parameters is unclear and relies on\nheuristics. Once a KSC model is trained on a small subset of the entire data,\nit is able to generalize well to unseen test points. Beyond the basic\nformulation, sparse KSC algorithms based on the Incomplete Cholesky\nDecomposition (ICD) and $L_0$, $L_1, L_0 + L_1$, Group Lasso regularization are\nreviewed. In that respect, we show how it is possible to handle large scale\ndata. Also, two possible ways to perform hierarchical clustering and a soft\nclustering method are presented. Finally, real-world applications such as image\nsegmentation, power load time-series clustering, document clustering and big\ndata learning are considered.",
    "  For some monoids, we give a method of composing invertibility preserving maps\nassociated to \"partial involutions.\" Also, we define the notion of\n\"determinants for finite dimensional algebras over a field.\" As examples, we\ngive invertibility preserving maps for Clifford algebras into a field and\ndeterminants for Clifford algebras into a field, where we assume that the\nalgebras are generated by less than or equal to 5 generators over the field. On\nthe other hand, \"determinant formulas for Clifford algebras\" are known. We\nunderstand these formulas as an expression that connects invertibility\npreserving maps for Clifford algebras and determinants for Clifford algebras.\nAs a result, we have a better sense of determinant formulas. In addition, we\nshow that there is not such a determinant formula for Clifford algebras\ngenerated by greater than 5 generators.\n",
    "  We introduce a parametrized version of the Wadge game for functions and show\nthat each lower cone in the Weihrauch degrees is characterized by such a game.\nThese parametrized Wadge games subsume the original Wadge game, the eraser and\nbacktrack games as well as Semmes's tree games. In particular, we propose that\nthe lower cones in the Weihrauch degrees are the answer to Andretta's question\non which classes of functions admit game characterizations.\n  We then discuss some applications of such parametrized Wadge games. Using\nmachinery from Weihrauch reducibility theory, we introduce games characterizing\nevery (transfinite) level of the Baire hierarchy via an iteration of a pruning\nderivative on countably branching trees.\n",
    "  This document is an introduction to the use of the point-centered quarter\nmethod. It briefly outlines its history, its methodology, and some of the\npractical issues (and modifications) that inevitably arise with its use in the\nfield. Additionally this paper shows how data collected using point-centered\nquarter method sampling may be used to determine importance values of different\nspecies of trees and describes and derives several methods of estimating plant\ndensity and corresponding confidence intervals.\n  New to this version is a revision of Appendix D which now includes R Shiny\nApps to carry out many of these calculations. References to data sets in the\nprevious version that are no longer publicly available have been removed. These\nhave been replaced with examples and exercises which demonstrate the use of the\nR Shiny Apps and the earlier R scripts.\n",
    "Standard segmentation of medical images based on full-supervised\nconvolutional networks demands accurate dense annotations. Such learning\nframework is built on laborious manual annotation with restrict demands for\nexpertise, leading to insufficient high-quality labels. To overcome such\nlimitation and exploit massive weakly labeled data, we relaxed the rigid\nlabeling requirement and developed a semi-supervised learning framework based\non a teacher-student fashion for organ and lesion segmentation with partial\ndense-labeled supervision and supplementary loose bounding-box supervision\nwhich are easier to acquire. Observing the geometrical relation of an organ and\nits inner lesions in most cases, we propose a hierarchical organ-to-lesion\n(O2L) attention module in a teacher segmentor to produce pseudo-labels. Then a\nstudent segmentor is trained with combinations of manual-labeled and\npseudo-labeled annotations. We further proposed a localization branch realized\nvia an aggregation of high-level features in a deep decoder to predict\nlocations of organ and lesion, which enriches student segmentor with precise\nlocalization information. We validated each design in our model on LiTS\nchallenge datasets by ablation study and showed its state-of-the-art\nperformance compared with recent methods. We show our model is robust to the\nquality of bounding box and achieves comparable performance compared with\nfull-supervised learning methods.",
    "Even though convolutional neural networks (CNNs) are driving progress in\nmedical image segmentation, standard models still have some drawbacks. First,\nthe use of multi-scale approaches, i.e., encoder-decoder architectures, leads\nto a redundant use of information, where similar low-level features are\nextracted multiple times at multiple scales. Second, long-range feature\ndependencies are not efficiently modeled, resulting in non-optimal\ndiscriminative feature representations associated with each semantic class. In\nthis paper we attempt to overcome these limitations with the proposed\narchitecture, by capturing richer contextual dependencies based on the use of\nguided self-attention mechanisms. This approach is able to integrate local\nfeatures with their corresponding global dependencies, as well as highlight\ninterdependent channel maps in an adaptive manner. Further, the additional loss\nbetween different modules guides the attention mechanisms to neglect irrelevant\ninformation and focus on more discriminant regions of the image by emphasizing\nrelevant feature associations. We evaluate the proposed model in the context of\nsemantic segmentation on three different datasets: abdominal organs,\ncardiovascular structures and brain tumors. A series of ablation experiments\nsupport the importance of these attention modules in the proposed architecture.\nIn addition, compared to other state-of-the-art segmentation networks our model\nyields better segmentation performance, increasing the accuracy of the\npredictions while reducing the standard deviation. This demonstrates the\nefficiency of our approach to generate precise and reliable automatic\nsegmentations of medical images. Our code is made publicly available at\nhttps://github.com/sinAshish/Multi-Scale-Attention",
    "Deep learning based models, generally, require a large number of samples for\nappropriate training, a requirement that is difficult to satisfy in the medical\nfield. This issue can usually be avoided with a proper initialization of the\nweights. On the task of medical image segmentation in general, two techniques\nare oftentimes employed to tackle the training of a deep network $f_T$. The\nfirst one consists in reusing some weights of a network $f_S$ pre-trained on a\nlarge scale database ($e.g.$ ImageNet). This procedure, also known as\n$transfer$ $learning$, happens to reduce the flexibility when it comes to new\nnetwork design since $f_T$ is constrained to match some parts of $f_S$. The\nsecond commonly used technique consists in working on image patches to benefit\nfrom the large number of available patches. This paper brings together these\ntwo techniques and propose to train $arbitrarily$ $designed$ $networks$ that\nsegment an image in one forward pass, with a focus on relatively small\ndatabases. An experimental work have been carried out on the tasks of retinal\nblood vessel segmentation and the optic disc one, using four publicly available\ndatabases. Furthermore, three types of network are considered, going from a\nvery light weighted network to a densely connected one. The final results show\nthe efficiency of the proposed framework along with state of the art results on\nall the databases.",
    "  Recently, in Ref.\\cite{moh1}, we introduced exited-de Sitter modes to study\nthe power spectrum which was finite in Krein space quantization and the\ntrans-Plankian corrections due to the exited modes were non-linear. It was\nshown that the de Sitter limit of corrections reduces to what obtained via the\nseveral previous conventional methods, moreover, with such modes the space-time\nsymmetry becomes manifest. In this paper, inspired by Krein method and using\nexited-de Sitter modes as the fundamental initial states during the inflation,\nwe calculate particle creation in the spatially flat Robertson-Walker\nspace-time. It is shown that in de Sitter and Minkowski space-time in the far\npast time limit, our results coincides to the standard results.\n",
    "Generalising deep models to new data from new centres (termed here domains)\nremains a challenge. This is largely attributed to shifts in data statistics\n(domain shifts) between source and unseen domains. Recently, gradient-based\nmeta-learning approaches where the training data are split into meta-train and\nmeta-test sets to simulate and handle the domain shifts during training have\nshown improved generalisation performance. However, the current fully\nsupervised meta-learning approaches are not scalable for medical image\nsegmentation, where large effort is required to create pixel-wise annotations.\nMeanwhile, in a low data regime, the simulated domain shifts may not\napproximate the true domain shifts well across source and unseen domains. To\naddress this problem, we propose a novel semi-supervised meta-learning\nframework with disentanglement. We explicitly model the representations related\nto domain shifts. Disentangling the representations and combining them to\nreconstruct the input image allows unlabeled data to be used to better\napproximate the true domain shifts for meta-learning. Hence, the model can\nachieve better generalisation performance, especially when there is a limited\namount of labeled data. Experiments show that the proposed method is robust on\ndifferent segmentation tasks and achieves state-of-the-art generalisation\nperformance on two public benchmarks.",
    "  We compute the relative-order-v^4 contribution to gluon fragmentation into\nquarkonium in the 3S1 color-singlet channel, using the nonrelativistic QCD\n(NRQCD) factorization approach. The QCD fragmentation process contains infrared\ndivergences that produce single and double poles in epsilon in 4-2epsilon\ndimensions. We devise subtractions that isolate the pole contributions, which\nultimately are absorbed into long-distance NRQCD matrix elements in the NRQCD\nmatching procedure. The matching procedure involves two-loop renormalizations\nof the NRQCD operators. The subtractions are integrated over the phase space\nanalytically in 4-2epsilon dimensions, and the remainder is integrated over the\nphase-space numerically. We find that the order-v^4 contribution is enhanced\nrelative to the order-v^0 contribution. However, the order-v^4 contribution is\nnot important numerically at the current level of precision of\nquarkonium-hadroproduction phenomenology. We also estimate the contribution to\nhadroproduction from gluon fragmentation into quarkonium in the 3PJ color-octet\nchannel and find that it is significant in comparison to the complete\nnext-to-leading-order-in-alpha_s contribution in that channel.\n",
    "  Fix coprime $s,t\\ge1$. We re-prove, without Ehrhart reciprocity, a conjecture\nof Armstrong (recently verified by Johnson) that the finitely many simultaneous\n$(s,t)$-cores have average size $\\frac{1}{24}(s-1)(t-1)(s+t+1)$, and that the\nsubset of self-conjugate cores has the same average (first shown by\nChen--Huang--Wang). We similarly prove a recent conjecture of Fayers that the\naverage weighted by an inverse stabilizer---giving the \"expected size of the\n$t$-core of a random $s$-core\"---is $\\frac{1}{24}(s-1)(t^2-1)$. We also prove\nFayers' conjecture that the analogous self-conjugate average is the same if $t$\nis odd, but instead $\\frac{1}{24}(s-1)(t^2+2)$ if $t$ is even. In principle,\nour explicit methods---or implicit variants thereof---extend to averages of\narbitrary powers.\n  The main new observation is that the stabilizers appearing in Fayers'\nconjectures have simple formulas in Johnson's $z$-coordinates parameterization\nof $(s,t)$-cores.\n  We also observe that the $z$-coordinates extend to parameterize general\n$t$-cores. As an example application with $t := s+d$, we count the number of\n$(s,s+d,s+2d)$-cores for coprime $s,d\\ge1$, verifying a recent conjecture of\nAmdeberhan and Leven.\n",
    "Separating and labeling each instance of a nucleus (instance-aware\nsegmentation) is the key challenge in segmenting single cell nuclei on\nfluorescence microscopy images. Deep Neural Networks can learn the implicit\ntransformation of a nuclear image into a probability map indicating the class\nmembership of each pixel (nucleus or background), but the use of\npost-processing steps to turn the probability map into a labeled object mask is\nerror-prone. This especially accounts for nuclear images of tissue sections and\nnuclear images across varying tissue preparations. In this work, we aim to\nevaluate the performance of state-of-the-art deep learning architectures to\nsegment nuclei in fluorescence images of various tissue origins and sample\npreparation types without post-processing. We compare architectures that\noperate on pixel to pixel translation and an architecture that operates on\nobject detection and subsequent locally applied segmentation. In addition, we\npropose a novel strategy to create artificial images to extend the training\nset. We evaluate the influence of ground truth annotation quality, image scale\nand segmentation complexity on segmentation performance. Results show that\nthree out of four deep learning architectures (U-Net, U-Net with ResNet34\nbackbone, Mask R-CNN) can segment fluorescent nuclear images on most of the\nsample preparation types and tissue origins with satisfactory segmentation\nperformance. Mask R-CNN, an architecture designed to address instance aware\nsegmentation tasks, outperforms other architectures. Equal nuclear mean size,\nconsistent nuclear annotations and the use of artificially generated images\nresult in overall acceptable precision and recall across different tissues and\nsample preparation types.",
    "  We present in-situ Raman measurements of laser-induced oxidation in\nexfoliated single-layer graphene. By using high-power laser irradiation, we can\nselectively and in a controlled way initiate the oxidation process and\ninvestigate its evolution over time. Our results show that the laser-induced\noxidation process is divided into two separate stages, namely tensile strain\ndue to heating and subsequent $p$-type doping due to oxygen binding. We discuss\nthe temporal evolution of the $D/G$-mode ratio during oxidation and explain the\nunexpected steady decrease of the defect-induced $D$ mode at long irradiation\ntimes. Our results provide a deeper understanding of the oxidation process in\nsingle-layer graphene and demonstrate the possibility of sub-$\\mu$m patterning\nof graphene by an optical method.\n",
    "  An evacuation process is simulated within the Social Force Model. Thousand\npedestrians are leaving a room by one exit. We investigate the stationarity of\nthe distribution of time lags between instants when two successive pedestrians\ncross the exit. The exponential tail of the distribution is shown to gradually\nvanish. Taking fluctuations apart, the time lags decrease in time till there\nare only about 50 pedestrians in the room, then they start to increase. This\nsuggests that at the last stage the flow is laminar. In the first stage,\nclogging events slow the evacuation down. As they are more likely for larger\ncrowds, the flow is not stationary. The data are investigated with detrended\nfluctuation analysis.\n",
    "  In this work we study the dynamical features of editorial wars in Wikipedia\n(WP). Based on our previously established algorithm, we build up samples of\ncontroversial and peaceful articles and analyze the temporal characteristics of\nthe activity in these samples. On short time scales, we show that there is a\nclear correspondence between conflict and burstiness of activity patterns, and\nthat memory effects play an important role in controversies. On long time\nscales, we identify three distinct developmental patterns for the overall\nbehavior of the articles. We are able to distinguish cases eventually leading\nto consensus from those cases where a compromise is far from achievable.\nFinally, we analyze discussion networks and conclude that edit wars are mainly\nfought by few editors only.\n",
    "  Phases of matter are conventionally characterized by order parameters\ndescribing the type and degree of order in a system. For example, crystals\nconsist of spatially ordered arrays of atoms, an order that is lost as the\ncrystal melts. Like- wise in ferromagnets, the magnetic moments of the\nconstituent particles align only below the Curie temperature, TC. These two\nexamples reflect two classes of phase transitions: the melting of a crystal is\na first-order phase transition (the crystalline order vanishes abruptly) and\nthe onset of magnetism is a second- order phase transition (the magnetization\nincreases continuously from zero as the temperature falls below TC). Such\nmagnetism is robust in systems with localized magnetic particles, and yet rare\nin model itinerant systems where the particles are free to move about. Here for\nthe first time, we explore the itinerant magnetic phases present in a spin-1\nspin-orbit coupled atomic Bose gas; in this system, itinerant ferromagnetic\norder is stabilized by the spin-orbit coupling, vanishing in its absence. We\nfirst located a second-order phase transition that continuously stiffens until,\nat a tricritical point, it transforms into a first- order transition (with\nobserved width as small as h x 4 Hz). We then studied the long-lived metastable\nstates associated with the first-order transition. These measurements are all\nin agreement with theory.\n",
    "  Barrett, Hardy, and Kent have shown in 2005 that protocols for quantum key\nagreement exist the security of which can be proven under the assumption that\nquantum or relativity theory is correct. More precisely, this is based on the\nnon-local behavior of certain quantum systems, combined with the non-signaling\npostulate from relativity. An advantage is that the resulting security is\nindependent of what (quantum) systems the legitimate parties' devices operate\non: they do not have to be trusted. Unfortunately, the protocol proposed by\nBarrett et al. cannot tolerate any errors caused by noise in the quantum\nchannel. Furthermore, even in the error-free case it is inefficient: its\ncommunication complexity is Theta(1/epsilon) when forcing the attacker's\ninformation below epsilon, even if only a single key bit is generated.\nPotentially, the problem can be solved by privacy amplification of relativistic\n- or non-signaling - secrecy. We show, however, that such privacy amplification\nis impossible with respect to the most important form of non-local behavior,\nand application of arbitrary hash functions.\n",
    "  We extend the well-known Cont-Bouchaud model to include a hierarchical\ntopology of agent's interactions. The influence of hierarchy on system dynamics\nis investigated by two models. The first one is based on a multi-level, nested\nErdos-Renyi random graph and individual decisions by agents according to Potts\ndynamics. This approach does not lead to a broad return distribution outside a\nparameter regime close to the original Cont-Bouchaud model. In the second model\nwe introduce a limited hierarchical Erdos-Renyi graph, where merging of\nclusters at a level h+1 involves only clusters that have merged at the previous\nlevel h and we use the original Cont-Bouchaud agent dynamics on resulting\nclusters. The second model leads to a heavy-tail distribution of cluster sizes\nand relative price changes in a wide range of connection densities, not only\nclose to the percolation threshold.\n",
    "This report provides an overview of the current state of the art deep\nlearning architectures and optimisation techniques, and uses the ADNI\nhippocampus MRI dataset as an example to compare the effectiveness and\nefficiency of different convolutional architectures on the task of patch-based\n3-dimensional hippocampal segmentation, which is important in the diagnosis of\nAlzheimer's Disease. We found that a slightly unconventional \"stacked 2D\"\napproach provides much better classification performance than simple 2D patches\nwithout requiring significantly more computational power. We also examined the\npopular \"tri-planar\" approach used in some recently published studies, and\nfound that it provides much better results than the 2D approaches, but also\nwith a moderate increase in computational power requirement. Finally, we\nevaluated a full 3D convolutional architecture, and found that it provides\nmarginally better results than the tri-planar approach, but at the cost of a\nvery significant increase in computational power requirement.",
    "  We show that, contrary to simple predictions, most AGNs show at best only a\nsmall increase of lags in the J, H, K, and L bands with increasing wavelength.\nWe suggest that a possible cause of this near simultaneity of the variability\nfrom the near-IR to the mid-IR is that the hot dust is in a hollow bi-conical\noutflow of which we only see the near side. Although most AGNs show near\nsimultaneity of IR variability, there was at least one epoch when NGC 4151\nshowed the sharply increasing IR lag with the increase of the wavelength. This\nbehaviour might also be present in GQ Comae. We discuss these results briefly.\nThe relative wavelength independence of IR lags simplifies the use of IR lags\nfor estimating cosmological parameters.\n",
    "Despite the state-of-the-art performance for medical image segmentation, deep\nconvolutional neural networks (CNNs) have rarely provided uncertainty\nestimations regarding their segmentation outputs, e.g., model (epistemic) and\nimage-based (aleatoric) uncertainties. In this work, we analyze these different\ntypes of uncertainties for CNN-based 2D and 3D medical image segmentation\ntasks. We additionally propose a test-time augmentation-based aleatoric\nuncertainty to analyze the effect of different transformations of the input\nimage on the segmentation output. Test-time augmentation has been previously\nused to improve segmentation accuracy, yet not been formulated in a consistent\nmathematical framework. Hence, we also propose a theoretical formulation of\ntest-time augmentation, where a distribution of the prediction is estimated by\nMonte Carlo simulation with prior distributions of parameters in an image\nacquisition model that involves image transformations and noise. We compare and\ncombine our proposed aleatoric uncertainty with model uncertainty. Experiments\nwith segmentation of fetal brains and brain tumors from 2D and 3D Magnetic\nResonance Images (MRI) showed that 1) the test-time augmentation-based\naleatoric uncertainty provides a better uncertainty estimation than calculating\nthe test-time dropout-based model uncertainty alone and helps to reduce\noverconfident incorrect predictions, and 2) our test-time augmentation\noutperforms a single-prediction baseline and dropout-based multiple\npredictions.",
    "The design and performance of computer vision algorithms are greatly\ninfluenced by the hardware on which they are implemented. CPUs, multi-core\nCPUs, FPGAs and GPUs have inspired new algorithms and enabled existing ideas to\nbe realized. This is notably the case with GPUs, which has significantly\nchanged the landscape of computer vision research through deep learning. As the\nend of Moores law approaches, researchers and hardware manufacturers are\nexploring alternative hardware computing paradigms. Quantum computers are a\nvery promising alternative and offer polynomial or even exponential speed-ups\nover conventional computing for some problems. This paper presents a novel\napproach to image segmentation that uses new quantum computing hardware.\nSegmentation is formulated as a graph cut problem that can be mapped to the\nquantum approximate optimization algorithm (QAOA). This algorithm can be\nimplemented on current and near-term quantum computers. Encouraging results are\npresented on artificial and medical imaging data. This represents an important,\npractical step towards leveraging quantum computers for computer vision.",
    "  We demonstrate that a self-complementary checkerboard-like metasurface works\nas a broadband coherent perfect absorber (CPA) when symmetrically illuminated\nby two counter-propagating incident waves. A theoretical analysis based on wave\ninterference and results of numerical simulations of the proposed metasurface\nare provided. In addition, we experimentally demonstrate the proposed CPA in\nthe terahertz regime by using a time-domain spectroscopy technique. We observe\nthat the metasurface can work as a CPA below its lowest diffraction frequency.\nThe size of the absorptive areas of the proposed CPA can be much smaller than\nthe incident wavelength. Unlike conventional CPAs, the presented one\nsimultaneously achieves the broadband operation and energy concentration of\nelectromagnetic waves at the deep-subwavelength scale.\n",
    "  We investigate the computational power and unified resource use of hybrid\nquantum-classical computations, such as teleportation and measurement-based\ncomputing. We introduce a physically causal and local graphical calculus for\nquantum information theory, which enables high-level intuitive reasoning about\nquantum information processes. The graphical calculus defines a local\ninformation flow in a computation which satisfies conditions for physical\ncausality. We show how quantum and classical processing units can now be\nformally integrated, and give an analysis of the joint resources used in a\ntypical measurement-based computation. Finally, we discuss how this picture may\nbe used to give a high-level unified model for hybrid quantum computing.\n",
    "Fluorescence microscopy images play the critical role of capturing spatial or\nspatiotemporal information of biomedical processes in life sciences. Their\nsimple structures and semantics provide unique advantages in elucidating\nlearning behavior of deep neural networks (DNNs). It is generally assumed that\naccurate image annotation is required to train DNNs for accurate image\nsegmentation. In this study, however, we find that DNNs trained by label images\nin which nearly half (49%) of the binary pixel labels are randomly flipped\nprovide largely the same segmentation performance. This suggests that DNNs\nlearn high-level structures rather than pixel-level labels per se to segment\nfluorescence microscopy images. We refer to these structures as\nmeta-structures. In support of the existence of the meta-structures, when DNNs\nare trained by a series of label images with progressively less meta-structure\ninformation, we find progressive degradation in their segmentation performance.\nMotivated by the learning behavior of DNNs trained by random labels and the\ncharacteristics of meta-structures, we propose an unsupervised segmentation\nmodel. Experiments show that it achieves remarkably competitive performance in\ncomparison to supervised segmentation models.",
    "Incorporating multi-scale features in fully convolutional neural networks\n(FCNs) has been a key element to achieving state-of-the-art performance on\nsemantic image segmentation. One common way to extract multi-scale features is\nto feed multiple resized input images to a shared deep network and then merge\nthe resulting features for pixelwise classification. In this work, we propose\nan attention mechanism that learns to softly weight the multi-scale features at\neach pixel location. We adapt a state-of-the-art semantic image segmentation\nmodel, which we jointly train with multi-scale input images and the attention\nmodel. The proposed attention model not only outperforms average- and\nmax-pooling, but allows us to diagnostically visualize the importance of\nfeatures at different positions and scales. Moreover, we show that adding extra\nsupervision to the output at each scale is essential to achieving excellent\nperformance when merging multi-scale features. We demonstrate the effectiveness\nof our model with extensive experiments on three challenging datasets,\nincluding PASCAL-Person-Part, PASCAL VOC 2012 and a subset of MS-COCO 2014.",
    "Sparse decomposition has been widely used for different applications, such as\nsource separation, image classification and image denoising. This paper\npresents a new algorithm for segmentation of an image into background and\nforeground text and graphics using sparse decomposition. First, the background\nis represented using a suitable smooth model, which is a linear combination of\na few smoothly varying basis functions, and the foreground text and graphics\nare modeled as a sparse component overlaid on the smooth background. Then the\nbackground and foreground are separated using a sparse decomposition framework\nand imposing some prior information, which promote the smoothness of\nbackground, and the sparsity and connectivity of foreground pixels. This\nalgorithm has been tested on a dataset of images extracted from HEVC standard\ntest sequences for screen content coding, and is shown to outperform prior\nmethods, including least absolute deviation fitting, k-means clustering based\nsegmentation in DjVu, and shape primitive extraction and coding algorithm.",
    "This paper presents a method for segmenting iris images obtained from the\ndeceased subjects, by training a deep convolutional neural network (DCNN)\ndesigned for the purpose of semantic segmentation. Post-mortem iris recognition\nhas recently emerged as an alternative, or additional, method useful in\nforensic analysis. At the same time it poses many new challenges from the\ntechnological standpoint, one of them being the image segmentation stage, which\nhas proven difficult to be reliably executed by conventional iris recognition\nmethods. Our approach is based on the SegNet architecture, fine-tuned with\n1,300 manually segmented post-mortem iris images taken from the\nWarsaw-BioBase-Post-Mortem-Iris v1.0 database. The experiments presented in\nthis paper show that this data-driven solution is able to learn specific\ndeformations present in post-mortem samples, which are missing from alive\nirises, and offers a considerable improvement over the state-of-the-art,\nconventional segmentation algorithm (OSIRIS): the Intersection over Union (IoU)\nmetric was improved from 73.6% (for OSIRIS) to 83% (for DCNN-based presented in\nthis paper) averaged over subject-disjoint, multiple splits of the data into\ntrain and test subsets. This paper offers the first known to us method of\nautomatic processing of post-mortem iris images. We offer source codes with the\ntrained DCNN that perform end-to-end segmentation of post-mortem iris images,\nas described in this paper. Also, we offer binary masks corresponding to manual\nsegmentation of samples from Warsaw-BioBase-Post-Mortem-Iris v1.0 database to\nfacilitate development of alternative methods for post-mortem iris\nsegmentation.",
    "Overfitting in deep learning has been the focus of a number of recent works,\nyet its exact impact on the behavior of neural networks is not well understood.\nThis study analyzes overfitting by examining how the distribution of logits\nalters in relation to how much the model overfits. Specifically, we find that\nwhen training with few data samples, the distribution of logit activations when\nprocessing unseen test samples of an under-represented class tends to shift\ntowards and even across the decision boundary, while the over-represented class\nseems unaffected. In image segmentation, foreground samples are often heavily\nunder-represented. We observe that sensitivity of the model drops as a result\nof overfitting, while precision remains mostly stable. Based on our analysis,\nwe derive asymmetric modifications of existing loss functions and regularizers\nincluding a large margin loss, focal loss, adversarial training and mixup,\nwhich specifically aim at reducing the shift observed when embedding unseen\nsamples of the under-represented class. We study the case of binary\nsegmentation of brain tumor core and show that our proposed simple\nmodifications lead to significantly improved segmentation performance over the\nsymmetric variants.",
    "Efficient and real time segmentation of color images has a variety of\nimportance in many fields of computer vision such as image compression, medical\nimaging, mapping and autonomous navigation. Being one of the most\ncomputationally expensive operation, it is usually done through software imple-\nmentation using high-performance processors. In robotic systems, however, with\nthe constrained platform dimensions and the need for portability, low power\nconsumption and simultaneously the need for real time image segmentation, we\nenvision hardware parallelism as the way forward to achieve higher\nacceleration. Field-programmable gate arrays (FPGAs) are among the best suited\nfor this task as they provide high computing power in a small physical area.\nThey exceed the computing speed of software based implementations by breaking\nthe paradigm of sequential execution and accomplishing more per clock cycle\noperations by enabling hardware level parallelization at an architectural\nlevel. In this paper, we propose three novel architectures of a well known\nEfficient Graph based Image Segmentation algorithm. These proposed\nimplementations optimizes time and power consumption when compared to software\nimplementations. The hybrid design proposed, has notable furtherance of\nacceleration capabilities delivering atleast 2X speed gain over other implemen-\ntations, which henceforth allows real time image segmentation that can be\ndeployed on Mobile Robotic systems.",
    "Unsupervised image segmentation algorithms aim at identifying disjoint\nhomogeneous regions in an image, and have been subject to considerable\nattention in the machine vision community. In this paper, a popular theoretical\nmodel with it's origins in statistical physics and social dynamics, known as\nthe Deffuant-Weisbuch model, is applied to the image segmentation problem. The\nDeffuant-Weisbuch model has been found to be useful in modelling the evolution\nof a closed system of interacting agents characterised by their opinions or\nbeliefs, leading to the formation of clusters of agents who share a similar\nopinion or belief at steady state. In the context of image segmentation, this\npaper considers a pixel as an agent and it's colour property as it's opinion,\nwith opinion updates as per the Deffuant-Weisbuch model. Apart from applying\nthe basic model to image segmentation, this paper incorporates adjacency and\nneighbourhood information in the model, which factors in the local similarity\nand smoothness properties of images. Convergence is reached when the number of\nunique pixel opinions, i.e., the number of colour centres, matches the\npre-specified number of clusters. Experiments are performed on a set of images\nfrom the Berkeley Image Segmentation Dataset and the results are analysed both\nqualitatively and quantitatively, which indicate that this simple and intuitive\nmethod is promising for image segmentation. To the best of the knowledge of the\nauthor, this is the first work where a theoretical model from statistical\nphysics and social dynamics has been successfully applied to image processing.",
    "  We present a proof of Rider's unpublished result that the union of two Sidon\nsets in the dual of a non-commutative compact group is Sidon, and that randomly\nSidon sets are Sidon. Most likely this proof is essentially the one announced\nby Rider and communicated in a letter to the author around 1979 (lost by him\nsince then). The key fact is a spectral gap property with respect to certain\nrepresentations of the unitary groups $U(n)$ that holds uniformly over $n$. The\nproof crucially uses Weyl's character formulae. We survey the results that we\nobtained 30 years ago using Rider's unpublished results. Using a recent\ndifferent approach valid for certain orthonormal systems of matrix valued\nfunctions, we give a new proof of the spectral gap property that is required to\nshow that the union of two Sidon sets is Sidon. The latter proof yields a\nrather good quantitative estimate. Several related results are discussed with\npossible applications to random matrix theory.\n",
    "Deep convolutional neural networks have significantly boosted the performance\nof fundus image segmentation when test datasets have the same distribution as\nthe training datasets. However, in clinical practice, medical images often\nexhibit variations in appearance for various reasons, e.g., different scanner\nvendors and image quality. These distribution discrepancies could lead the deep\nnetworks to over-fit on the training datasets and lack generalization ability\non the unseen test datasets. To alleviate this issue, we present a novel\nDomain-oriented Feature Embedding (DoFE) framework to improve the\ngeneralization ability of CNNs on unseen target domains by exploring the\nknowledge from multiple source domains. Our DoFE framework dynamically enriches\nthe image features with additional domain prior knowledge learned from\nmulti-source domains to make the semantic features more discriminative.\nSpecifically, we introduce a Domain Knowledge Pool to learn and memorize the\nprior information extracted from multi-source domains. Then the original image\nfeatures are augmented with domain-oriented aggregated features, which are\ninduced from the knowledge pool based on the similarity between the input image\nand multi-source domain images. We further design a novel domain code\nprediction branch to infer this similarity and employ an attention-guided\nmechanism to dynamically combine the aggregated features with the semantic\nfeatures. We comprehensively evaluate our DoFE framework on two fundus image\nsegmentation tasks, including the optic cup and disc segmentation and vessel\nsegmentation. Our DoFE framework generates satisfying segmentation results on\nunseen datasets and surpasses other domain generalization and network\nregularization methods.",
    "Robust cross-seasonal localization is one of the major challenges in\nlong-term visual navigation of autonomous vehicles. In this paper, we exploit\nrecent advances in semantic segmentation of images, i.e., where each pixel is\nassigned a label related to the type of object it represents, to attack the\nproblem of long-term visual localization. We show that semantically labeled 3-D\npoint maps of the environment, together with semantically segmented images, can\nbe efficiently used for vehicle localization without the need for detailed\nfeature descriptors (SIFT, SURF, etc.). Thus, instead of depending on\nhand-crafted feature descriptors, we rely on the training of an image\nsegmenter. The resulting map takes up much less storage space compared to a\ntraditional descriptor based map. A particle filter based semantic localization\nsolution is compared to one based on SIFT-features, and even with large\nseasonal variations over the year we perform on par with the larger and more\ndescriptive SIFT-features, and are able to localize with an error below 1 m\nmost of the time.",
    "  Based on the similarity of paraxial diffraction and dispersion mathematical\ndescriptions, the temporal imaging of optical pulses combines linear dispersive\nfilters and quadratic phase modulations operating as time lenses. We consider\nprogramming a dispersive filter near atomic resonance in rare earth ion doped\ncrystals, which leads to unprecedented high values of dispersive power. This\nfilter is used in an approximate imaging scheme, combining a single time lens\nand a single dispersive section and operating as a time reversing device, with\npotential applications in radio-frequency signal processing. This scheme is\nclosely related to three-pulse photon echo with chirped pulses but the\nconnection with temporal imaging and dispersive filtering emphasizes new\nfeatures.\n",
    "A large labeled dataset is a key to the success of supervised deep learning,\nbut for medical image segmentation, it is highly challenging to obtain\nsufficient annotated images for model training. In many scenarios, unannotated\nimages are abundant and easy to acquire. Self-supervised learning (SSL) has\nshown great potentials in exploiting raw data information and representation\nlearning. In this paper, we propose Hierarchical Self-Supervised Learning\n(HSSL), a new self-supervised framework that boosts medical image segmentation\nby making good use of unannotated data. Unlike the current literature on\ntask-specific self-supervised pretraining followed by supervised fine-tuning,\nwe utilize SSL to learn task-agnostic knowledge from heterogeneous data for\nvarious medical image segmentation tasks. Specifically, we first aggregate a\ndataset from several medical challenges, then pre-train the network in a\nself-supervised manner, and finally fine-tune on labeled data. We develop a new\nloss function by combining contrastive loss and classification loss and\npretrain an encoder-decoder architecture for segmentation tasks. Our extensive\nexperiments show that multi-domain joint pre-training benefits downstream\nsegmentation tasks and outperforms single-domain pre-training significantly.\nCompared to learning from scratch, our new method yields better performance on\nvarious tasks (e.g., +0.69% to +18.60% in Dice scores with 5% of annotated\ndata). With limited amounts of training data, our method can substantially\nbridge the performance gap w.r.t. denser annotations (e.g., 10% vs.~100% of\nannotated data).",
    "  Suppose we are given black-box access to a finite ring R, and a list of\ngenerators for an ideal I in R. We show how to find an additive basis\nrepresentation for I in poly(log |R|) time. This generalizes a quantum\nalgorithm of Arvind et al. which finds a basis representation for R itself. We\nthen show that our algorithm is a useful primitive allowing quantum computers\nto rapidly solve a wide variety of problems regarding finite rings. In\nparticular we show how to test whether two ideals are identical, find their\nintersection, find their quotient, prove whether a given ring element belongs\nto a given ideal, prove whether a given element is a unit, and if so find its\ninverse, find the additive and multiplicative identities, compute the order of\nan ideal, solve linear equations over rings, decide whether an ideal is\nmaximal, find annihilators, and test the injectivity and surjectivity of ring\nhomomorphisms. These problems appear to be hard classically.\n",
    "  By regarding the Lifshitz expression for the Casimir free energy on the real\nfrequency axis rather than the imaginary Matsubara frequencies as is customary,\nnew light is shed on the ongoing debate regarding the thermodynamical\nconsistency of this theory in combination with common permittivity models. It\nis argued that when permittivity is temperature independent over a temperature\ninterval including zero temperature, a cavity made of causal material with\ncontinuous dispersion properties separated by vacuum cannot violate Nernst's\ntheorem (the third law of thermodynamics). The purported violation of this\ntheorem pertains to divergencies in the double limit in which frequency and\ntemperature vanish simultaneously. While any model should abide by the laws of\nthermodynamics within its range of applicability, we emphasise that the Nernst\nheat theorem is a relevant criterion for choosing amongst candidate theories\nonly when these theories are fully applicable at zero temperature and\nfrequency.\n",
    "Convolutional neural networks (CNNs) have achieved state-of-the-art\nperformance for automatic medical image segmentation. However, they have not\ndemonstrated sufficiently accurate and robust results for clinical use. In\naddition, they are limited by the lack of image-specific adaptation and the\nlack of generalizability to previously unseen object classes. To address these\nproblems, we propose a novel deep learning-based framework for interactive\nsegmentation by incorporating CNNs into a bounding box and scribble-based\nsegmentation pipeline. We propose image-specific fine-tuning to make a CNN\nmodel adaptive to a specific test image, which can be either unsupervised\n(without additional user interactions) or supervised (with additional\nscribbles). We also propose a weighted loss function considering network and\ninteraction-based uncertainty for the fine-tuning. We applied this framework to\ntwo applications: 2D segmentation of multiple organs from fetal MR slices,\nwhere only two types of these organs were annotated for training; and 3D\nsegmentation of brain tumor core (excluding edema) and whole brain tumor\n(including edema) from different MR sequences, where only tumor cores in one MR\nsequence were annotated for training. Experimental results show that 1) our\nmodel is more robust to segment previously unseen objects than state-of-the-art\nCNNs; 2) image-specific fine-tuning with the proposed weighted loss function\nsignificantly improves segmentation accuracy; and 3) our method leads to\naccurate results with fewer user interactions and less user time than\ntraditional interactive segmentation methods.",
    "Compared with common image segmentation tasks targeted at low-resolution\nimages, higher resolution detailed image segmentation receives much less\nattention. In this paper, we propose and study a task named Meticulous Object\nSegmentation (MOS), which is focused on segmenting well-defined foreground\nobjects with elaborate shapes in high resolution images (e.g. 2k - 4k). To this\nend, we propose the MeticulousNet which leverages a dedicated decoder to\ncapture the object boundary details. Specifically, we design a Hierarchical\nPoint-wise Refining (HierPR) block to better delineate object boundaries, and\nreformulate the decoding process as a recursive coarse to fine refinement of\nthe object mask. To evaluate segmentation quality near object boundaries, we\npropose the Meticulosity Quality (MQ) score considering both the mask coverage\nand boundary precision. In addition, we collect a MOS benchmark dataset\nincluding 600 high quality images with complex objects. We provide\ncomprehensive empirical evidence showing that MeticulousNet can reveal\npixel-accurate segmentation boundaries and is superior to state-of-the-art\nmethods for high resolution object segmentation tasks.",
    "In medical imaging, the heterogeneity of multi-centre data impedes the\napplicability of deep learning-based methods and results in significant\nperformance degradation when applying models in an unseen data domain, e.g. a\nnew centreor a new scanner. In this paper, we propose an unsupervised domain\nadaptation framework for boosting image segmentation performance across\nmultiple domains without using any manual annotations from the new target\ndomains, but by re-calibrating the networks on few images from the target\ndomain. To achieve this, we enforce architectures to be adaptive to new data by\nrejecting improbable segmentation patterns and implicitly learning through\nsemantic and boundary information, thus to capture disease-specific spatial\npatterns in an adversarial optimization. The adaptation process needs\ncontinuous monitoring, however, as we cannot assume the presence of\nground-truth masks for the target domain, we propose two new metrics to monitor\nthe adaptation process, and strategies to train the segmentation algorithm in a\nstable fashion. We build upon well-established 2D and 3D architectures and\nperform extensive experiments on three cross-centre brain lesion segmentation\ntasks, involving multicentre public and in-house datasets. We demonstrate that\nrecalibrating the deep networks on a few unlabeled images from the target\ndomain improves the segmentation accuracy significantly.",
    "  The physical processes that control the partition of released magnetic energy\nbetween electrons and ions during reconnection is explored through\nparticle-in-cell simulations and analytical techniques. We demonstrate that the\ndevelopment of a large-scale parallel electric field and its associated\npotential controls the relative heating of electrons and ions. The potential\ndevelops to restrain heated exhaust electrons and enhances their heating by\nconfining electrons in the region where magnetic energy is released.\nSimultaneously the potential slows ions entering the exhaust below the\nAlfv\\'enic speed expected from the traditional counterstreaming picture of ion\nheating. Unexpectedly, the magnitude of the potential and therefore the\nrelative partition of energy between electrons and ions is not a constant but\nrather depends on the upstream parameters and specifically the upstream\nelectron normalized temperature (electron beta). These findings suggest that\nthe fraction of magnetic energy converted into the total thermal energy may be\nindependent of upstream parameters.\n",
    "Most existing black-box optimization methods assume that all variables in the\nsystem being optimized have equal cost and can change freely at each iteration.\nHowever, in many real world systems, inputs are passed through a sequence of\ndifferent operations or modules, making variables in earlier stages of\nprocessing more costly to update. Such structure imposes a cost on switching\nvariables in early parts of a data processing pipeline. In this work, we\npropose a new algorithm for switch cost-aware optimization called Lazy Modular\nBayesian Optimization (LaMBO). This method efficiently identifies the global\noptimum while minimizing cost through a passive change of variables in early\nmodules. The method is theoretical grounded and achieves vanishing regret when\naugmented with switching cost. We apply LaMBO to multiple synthetic functions\nand a three-stage image segmentation pipeline used in a neuroscience\napplication, where we obtain promising improvements over prevailing cost-aware\nBayesian optimization algorithms. Our results demonstrate that LaMBO is an\neffective strategy for black-box optimization that is capable of minimizing\nswitching costs in modular systems.",
    "  We consider Bloch oscillations of ultracold atoms stored in a one-dimensional\nvertical optical lattice and simultaneously interacting with a unidirectionally\npumped optical ring cavity whose vertical arm is collinear with the optical\nlattice. We find that the feedback provided by the cavity field on the atomic\nmotion synchronizes Bloch oscillations via a mode-locking mechanism, steering\nthe atoms to the lowest Bloch band. It also stabilizes Bloch oscillations\nagainst noise, and even suppresses dephasing due to atom-atom interactions.\nFurthermore, it generates periodic bursts of light emitted into the\ncounter-propagating cavity mode, providing a non-destructive monitor of the\natomic dynamics. All these features may be crucial for future improvements of\nthe design of atomic gravimeters based on recording Bloch oscillations.\n",
    "Volumetric image segmentation with convolutional neural networks (CNNs)\nencounters several challenges, which are specific to medical images. Among\nthese challenges are large volumes of interest, high class imbalances, and\ndifficulties in learning shape representations. To tackle these challenges, we\npropose to improve over traditional CNN-based volumetric image segmentation\nthrough point-wise classification of point clouds. The sparsity of point clouds\nallows processing of entire image volumes, balancing highly imbalanced\nsegmentation problems, and explicitly learning an anatomical shape. We build\nupon PointCNN, a neural network proposed to process point clouds, and propose\nhere to jointly encode shape and volumetric information within the point cloud\nin a compact and computationally effective manner. We demonstrate how this\napproach can then be used to refine CNN-based segmentation, which yields\nsignificantly improved results in our experiments on the difficult task of\nperipheral nerve segmentation from magnetic resonance neurography images. By\nsynthetic experiments, we further show the capability of our approach in\nlearning an explicit anatomical shape representation.",
    "  This work represents the final year project for BSc Physics with Astrophysics\ndegree and it mainly focuses on empirical investigation of the photometry of\nquasars in the Sloan Digital Sky Survey (SDSS) and the UK Infrared Telescope\n(UKIRT) Infrared Sky Survey (UKIDSS) systems. The studies include 5730 quasars\nmatched from both surveys and examine UV/optical/near-IR properties of the\npopulation. The sample covers the redshift and absolute magnitude ranges 0.01 <\nz < 3 and -29.3 < M i < -13.8 and 17 per cent of the SDSS quasars have matching\nsuccess to the UKIDSS data. The combination of SDSS ugriz with the JHK near-IR\nphotometry from UKIDSS over large areas of the sky has enormous potential for\nadvancing our understanding of quasar population, keeping in mind that these\nsurveys have not reached their terminations.\n",
    "Although spatial information of images usually enhance the robustness of the\nFuzzy C-Means (FCM) algorithm, it greatly increases the computational costs for\nimage segmentation. To achieve a sound trade-off between the segmentation\nperformance and the speed of clustering, we come up with a Kullback-Leibler\n(KL) divergence-based FCM algorithm by incorporating a tight wavelet frame\ntransform and a morphological reconstruction operation. To enhance FCM's\nrobustness, an observed image is first filtered by using the morphological\nreconstruction. A tight wavelet frame system is employed to decompose the\nobserved and filtered images so as to form their feature sets. Considering\nthese feature sets as data of clustering, an modified FCM algorithm is\nproposed, which introduces a KL divergence term in the partition matrix into\nits objective function. The KL divergence term aims to make membership degrees\nof each image pixel closer to those of its neighbors, which brings that the\nmembership partition becomes more suitable and the parameter setting of FCM\nbecomes simplified. On the basis of the obtained partition matrix and\nprototypes, the segmented feature set is reconstructed by minimizing the\ninverse process of the modified objective function. To modify abnormal features\nproduced in the reconstruction process, each reconstructed feature is\nreassigned to the closest prototype. As a result, the segmentation accuracy of\nKL divergence-based FCM is further improved. What's more, the segmented image\nis reconstructed by using a tight wavelet frame reconstruction operation.\nFinally, supporting experiments coping with synthetic, medical and color images\nare reported. Experimental results exhibit that the proposed algorithm works\nwell and comes with better segmentation performance than other comparative\nalgorithms. Moreover, the proposed algorithm requires less time than most of\nthe FCM-related algorithms.",
    "Efficient and easy segmentation of images and volumes is of great practical\nimportance. Segmentation problems that motivate our approach originate from\nmicroscopy imaging commonly used in materials science, medicine, and biology.\nWe formulate image segmentation as a probabilistic pixel classification\nproblem, and we apply segmentation as a step towards characterising image\ncontent. Our method allows the user to define structures of interest by\ninteractively marking a subset of pixels. Thanks to the real-time feedback, the\nuser can place new markings strategically, depending on the current outcome.\nThe final pixel classification may be obtained from a very modest user input.\nAn important ingredient of our method is a graph that encodes image content.\nThis graph is built in an unsupervised manner during initialisation and is\nbased on clustering of image features. Since we combine a limited amount of\nuser-labelled data with the clustering information obtained from the unlabelled\nparts of the image, our method fits in the general framework of semi-supervised\nlearning. We demonstrate how this can be a very efficient approach to\nsegmentation through pixel classification.",
    "In the last few years, Deep Learning (DL) has been showing superior\nperformance in different modalities of biomedical image analysis. Several DL\narchitectures have been proposed for classification, segmentation, and\ndetection tasks in medical imaging and computational pathology. In this paper,\nwe propose a new DL architecture, the NABLA-N network, with better feature\nfusion techniques in decoding units for dermoscopic image segmentation tasks.\nThe NABLA-N network has several advances for segmentation tasks. First, this\nmodel ensures better feature representation for semantic segmentation with a\ncombination of low to high-level feature maps. Second, this network shows\nbetter quantitative and qualitative results with the same or fewer network\nparameters compared to other methods. In addition, the Inception Recurrent\nResidual Convolutional Neural Network (IRRCNN) model is used for skin cancer\nclassification. The proposed NABLA-N network and IRRCNN models are evaluated\nfor skin cancer segmentation and classification on the benchmark datasets from\nthe International Skin Imaging Collaboration 2018 (ISIC-2018). The experimental\nresults show superior performance on segmentation tasks compared to the\nRecurrent Residual U-Net (R2U-Net). The classification model shows around 87%\ntesting accuracy for dermoscopic skin cancer classification on ISIC2018\ndataset.",
    "Polarimetric synthetic aperture radar (PolSAR) image segmentation is\ncurrently of great importance in image processing for remote sensing\napplications. However, it is a challenging task due to two main reasons.\nFirstly, the label information is difficult to acquire due to high annotation\ncosts. Secondly, the speckle effect embedded in the PolSAR imaging process\nremarkably degrades the segmentation performance. To address these two issues,\nwe present a contextual PolSAR image semantic segmentation method in this\npaper.With a newly defined channelwise consistent feature set as input, the\nthree-dimensional discrete wavelet transform (3D-DWT) technique is employed to\nextract discriminative multi-scale features that are robust to speckle noise.\nThen Markov random field (MRF) is further applied to enforce label smoothness\nspatially during segmentation. By simultaneously utilizing 3D-DWT features and\nMRF priors for the first time, contextual information is fully integrated\nduring the segmentation to ensure accurate and smooth segmentation. To\ndemonstrate the effectiveness of the proposed method, we conduct extensive\nexperiments on three real benchmark PolSAR image data sets. Experimental\nresults indicate that the proposed method achieves promising segmentation\naccuracy and preferable spatial consistency using a minimal number of labeled\npixels.",
    "We generalize a graph-based multiclass semi-supervised classification\ntechnique based on diffuse interface methods to multilayer graphs. Besides the\ntreatment of various applications with an inherent multilayer structure, we\npresent a very flexible approach that interprets high-dimensional data in a\nlow-dimensional multilayer graph representation. Highly efficient numerical\nmethods involving the spectral decomposition of the corresponding differential\ngraph operators as well as fast matrix-vector products based on the\nnonequispaced fast Fourier transform (NFFT) enable the rapid treatment of large\nand high-dimensional data sets. We perform various numerical tests putting a\nspecial focus on image segmentation. In particular, we test the performance of\nour method on data sets with up to 10 million nodes per layer as well as up to\n104 dimensions resulting in graphs with up to 52 layers. While all presented\nnumerical experiments can be run on an average laptop computer, the linear\ndependence per iteration step of the runtime on the network size in all stages\nof our algorithm makes it scalable to even larger and higher-dimensional\nproblems.",
    "  We prove geometric Ramsey-type statements on collections of lines in 3-space.\nThese statements give guarantees on the size of a clique or an independent set\nin (hyper)graphs induced by incidence relations between lines, points, and\nreguli in 3-space. Among other things, we prove that: (1) The intersection\ngraph of n lines in R^3 has a clique or independent set of size Omega(n^{1/3}).\n(2) Every set of n lines in R^3 has a subset of n^{1/2} lines that are all\nstabbed by one line, or a subset of Omega((n/log n)^{1/5}) such that no\n6-subset is stabbed by one line. (3) Every set of n lines in general position\nin R^3 has a subset of Omega(n^{2/3}) lines that all lie on a regulus, or a\nsubset of Omega(n^{1/3}) lines such that no 4-subset is contained in a regulus.\nThe proofs of these statements all follow from geometric incidence bounds --\nsuch as the Guth-Katz bound on point-line incidences in R^3 -- combined with\nTur\\'an-type results on independent sets in sparse graphs and hypergraphs.\nAlthough similar Ramsey-type statements can be proved using existing generic\nalgebraic frameworks, the lower bounds we get are much larger than what can be\nobtained with these methods. The proofs directly yield polynomial-time\nalgorithms for finding subsets of the claimed size.\n",
    "  We consider inference for misaligned multivariate functional data that\nrepresents the same underlying curve, but where the functional samples have\nsystematic differences in shape. In this paper we introduce a new class of\ngenerally applicable models where warping effects are modeled through nonlinear\ntransformation of latent Gaussian variables and systematic shape differences\nare modeled by Gaussian processes. To model cross-covariance between sample\ncoordinates we introduce a class of low-dimensional cross-covariance structures\nsuitable for modeling multivariate functional data. We present a method for\ndoing maximum-likelihood estimation in the models and apply the method to three\ndata sets. The first data set is from a motion tracking system where the\nspatial positions of a large number of body-markers are tracked in\nthree-dimensions over time. The second data set consists of height and weight\nmeasurements for Danish boys. The third data set consists of three-dimensional\nspatial hand paths from a controlled obstacle-avoidance experiment. We use the\ndeveloped method to estimate the cross-covariance structure, and use a\nclassification setup to demonstrate that the method outperforms\nstate-of-the-art methods for handling misaligned curve data.\n",
    "We propose a framework for top-down salient object detection that\nincorporates a tightly coupled image classification module. The classifier is\ntrained on novel category-aware sparse codes computed on object dictionaries\nused for saliency modeling. A misclassification indicates that the\ncorresponding saliency model is inaccurate. Hence, the classifier selects\nimages for which the saliency models need to be updated. The category-aware\nsparse coding produces better image classification accuracy as compared to\nconventional sparse coding with a reduced computational complexity. A\nsaliency-weighted max-pooling is proposed to improve image classification,\nwhich is further used to refine the saliency maps. Experimental results on\nGraz-02 and PASCAL VOC-07 datasets demonstrate the effectiveness of salient\nobject detection. Although the role of the classifier is to support salient\nobject detection, we evaluate its performance in image classification and also\nillustrate the utility of thresholded saliency maps for image segmentation.",
    "In applications of supervised learning applied to medical image segmentation,\nthe need for large amounts of labeled data typically goes unquestioned. In\nparticular, in the case of brain anatomy segmentation, hundreds or thousands of\nweakly-labeled volumes are often used as training data. In this paper, we first\nobserve that for many brain structures, a small number of training examples,\n(n=9), weakly labeled using Freesurfer 6.0, plus simple data augmentation,\nsuffice as training data to achieve high performance, achieving an overall mean\nDice coefficient of $0.84 \\pm 0.12$ compared to Freesurfer over 28 brain\nstructures in T1-weighted images of $\\approx 4000$ 9-10 year-olds from the\nAdolescent Brain Cognitive Development study. We then examine two varieties of\nheteroscedastic network as a method for improving classification results. An\nexisting proposal by Kendall and Gal, which uses Monte-Carlo inference to learn\nto predict the variance of each prediction, yields an overall mean Dice of\n$0.85 \\pm 0.14$ and showed statistically significant improvements over 25 brain\nstructures. Meanwhile a novel heteroscedastic network which directly learns the\nprobability that an example has been mislabeled yielded an overall mean Dice of\n$0.87 \\pm 0.11$ and showed statistically significant improvements over all but\none of the brain structures considered. The loss function associated to this\nnetwork can be interpreted as performing a form of learned label smoothing,\nwhere labels are only smoothed where they are judged to be uncertain.",
    "  In 1914, Kempner proved that the series 1/1 + 1/2 + ... + 1/8 + 1/10 + 1/11 +\n... + 1/18 + 1/20 + 1/21 + ... where the denominators are the positive integers\nthat do not contain the digit 9, converges to a sum less than 90. The actual\nsum is about 22.92068. In 1916, Irwin proved, among other things, that the sum\nof 1/n where n has at most a finite number of 9's is also a convergent series.\nWe show how to compute sums of Irwins' series to high precision. For example,\nthe sum of the series 1/9 + 1/19 + 1/29 + 1/39 + 1/49 + ... where the\ndenominators have exactly one 9, is about 23.04428 70807 47848 31968. Another\nexample: the sum of 1/n where n has exactly 100 zeros is about 10 ln(10) +\n1.00745 x 10^-197 ~ 23.02585; note that the first, and largest, term in this\nseries is the tiny 1/googol. Finally, we discuss a class of related series\nwhose summation algorithm has not yet been developed.\n",
    "  Let $k$ be a field, $\\tilde{G}$ a connected reductive $k$-group, and $\\Gamma$\na finite group. In a previous work, the authors defined what it means for a\nconnected reductive $k$-group $G$ to be \"parascopic\" for $(\\tilde{G},\\Gamma)$.\nRoughly, this is a simultaneous generalization of several settings. For\nexample, $\\Gamma$ could act on $\\tilde{G}$, and $G$ could be the connected part\nof the group of $\\Gamma$-fixed points in $\\tilde{G}$. Or $G$ could be an\nendoscopic group, a pseudo-Levi subgroup, or an isogenous image of $\\tilde{G}$.\nIf $G$ is such a group, and both $\\tilde{G}$ and $G$ are $k$-quasisplit, then\nwe constructed a map $\\hat{\\mathcal{N}}^{\\text{st}}$ from the set of stable\nsemisimple conjugacy classes in the dual $G^\\wedge(k)$ to the set of such\nclasses in $\\tilde{G}^\\wedge(k)$. When $k$ is finite, this implies a lifting\nfrom packets of representations of $G(k)$ to those of $\\tilde{G}(k)$.\n  In order to understand such a lifting better, here we describe two ways in\nwhich $\\hat{\\mathcal{N}}^{\\text{st}}$ can be made more explicit. First, we can\nexpress our map in the general case in terms of simpler cases. We do so by\nshowing that $\\hat{\\mathcal{N}}^{\\text{st}}$ is compatible with isogenies and\nwith Weil restriction, and also by expressing it as a composition of simpler\nmaps. Second, in many cases we can construct an explicit $k$-morphism $\\hat N\n\\colon G^\\wedge \\longrightarrow \\tilde{G}^\\wedge$ that agrees with\n$\\hat{\\mathcal{N}}^{\\text{st}}$. As a consequence, our lifting of\nrepresentations is seen to coincide with Shintani lifting in some important\ncases.\n",
    "  In recent years researchers have gravitated to social media platforms,\nespecially Twitter, as fertile ground for empirical analysis of social\nphenomena. Social media provides researchers access to trace data of\ninteractions and discourse that once went unrecorded in the offline world.\nResearchers have sought to use these data to explain social phenomena both\nparticular to social media and applicable to the broader social world. This\npaper offers a minireview of Twitter-based research on political crowd\nbehavior. This literature offers insight into particular social phenomena on\nTwitter, but often fails to use standardized methods that permit interpretation\nbeyond individual studies. Moreover, the literature fails to ground\nmethodologies and results in social or political theory, divorcing empirical\nresearch from the theory needed to interpret it. Rather, papers focus primarily\non methodological innovations for social media analyses, but these too often\nfail to sufficiently demonstrate the validity of such methodologies. This\nminireview considers a small number of selected papers; we analyze their (often\nlack of) theoretical approaches, review their methodological innovations, and\noffer suggestions as to the relevance of their results for political scientists\nand sociologists.\n",
    "Pap smear testing has been widely used for detecting cervical cancers based\non the morphology properties of cell nuclei in microscopic image. An accurate\nnuclei segmentation could thus improve the success rate of cervical cancer\nscreening. In this work, a method of automated cervical nuclei segmentation\nusing Deformable Multipath Ensemble Model (D-MEM) is proposed. The approach\nadopts a U-shaped convolutional network as a backbone network, in which dense\nblocks are used to transfer feature information more effectively. To increase\nthe flexibility of the model, we then use deformable convolution to deal with\ndifferent nuclei irregular shapes and sizes. To reduce the predictive bias, we\nfurther construct multiple networks with different settings, which form an\nensemble model. The proposed segmentation framework has achieved\nstate-of-the-art accuracy on Herlev dataset with Zijdenbos similarity index\n(ZSI) of 0.933, and has the potential to be extended for solving other medical\nimage segmentation tasks.",
    "  The article considers a way to compare large bulks of experimental data with\ntheoretical calculations, in which the quality of theoretical models is clearly\ndemonstrated graphically. The main idea of the method consists in grouping\nphysical observables, represented by experiment and theoretical calculation,\ninto samples, each of which characterizes a certain physical process. A further\nchoice of a convenient criterion for comparing measurements and calculations,\nits calculation and averaging within each sample and then over all samples,\nmakes it possible to choose the best theoretical model in the entire\nmeasurement area. Published theoretical data of the three-fluid dynamic model\n(3FD) applied to the experimental data from heavy-ion collisions at the energy\nrange $\\sqrt{s_{NN}}\\,=\\,2.7 - 63$ GeV are used as example of application of\nthe developed methodology. When analyzing the results, the quantum nature of\nthe fireball, created at heavy ion collisions, was taken into account. Thus,\neven at energy $\\sqrt{s_{NN}}\\,=\\,63$ GeV of central collisions of heavy ions,\nthere is a nonzero probability of fireball formation without ignition of the\nquark-gluon plasma (QGP). At the same time, QGP ignition at central collision\nenergies above at least $\\sqrt{s_{NN}}\\,=\\,12 GeV occurs through two competing\nprocesses, through a first-order phase transition and through a smooth\ncrossover. That is, in nature, these two possibilities are realized, which\noccur with approximately the same probabilities.\n",
    "Rapid growth in the field of quantitative digital image analysis is paving\nthe way for researchers to make precise measurements about objects in an image.\nTo compute quantities from the image such as the density of compressed\nmaterials or the velocity of a shockwave, we must determine object boundaries.\nImages containing regions that each have a spatial trend in intensity are of\nparticular interest. We present a supervised image segmentation method that\nincorporates spatial information to locate boundaries between regions with\noverlapping intensity histograms. The segmentation of a pixel is determined by\ncomparing its intensity to distributions from local, nearby pixel intensities.\nBecause of the statistical nature of the algorithm, we use maximum likelihood\nestimation theory to quantify uncertainty about each boundary. We demonstrate\nthe success of this algorithm on a radiograph of a multicomponent cylinder and\non an optical image of a laser-induced shockwave, and we provide final boundary\nlocations with associated bands of uncertainty.",
    "  The aim of this paper is twofold. First, we study eigenvalues and\neigenvectors of the adjacency matrix of a bond percolation graph when the base\ngraph is finite and well approximated locally by an infinite regular graph. We\nrelate quantitatively the empirical measure of the eigenvalues and the\ndelocalization of the eigenvectors to the spectrum of the adjacency operator of\nthe percolation on the infinite graph. Secondly, we prove that percolation on\nan infinite regular tree with degree at least $3$ preserves the existence of an\nabsolutely continuous spectrum if the removal probability is small enough.\nThese two results are notably relevant for bond percolation on a uniformly\nsampled regular graph or a Cayley graph with large girth.\n",
    "The ability of neural networks to continuously learn and adapt to new tasks\nwhile retaining prior knowledge is crucial for many applications. However,\ncurrent neural networks tend to forget previously learned tasks when trained on\nnew ones, i.e., they suffer from Catastrophic Forgetting (CF). The objective of\nContinual Learning (CL) is to alleviate this problem, which is particularly\nrelevant for medical applications, where it may not be feasible to store and\naccess previously used sensitive patient data. In this work, we propose a\nContinual Learning approach for brain segmentation, where a single network is\nconsecutively trained on samples from different domains. We build upon an\nimportance driven approach and adapt it for medical image segmentation.\nParticularly, we introduce learning rate regularization to prevent the loss of\nthe network's knowledge. Our results demonstrate that directly restricting the\nadaptation of important network parameters clearly reduces Catastrophic\nForgetting for segmentation across domains.",
    "Deep convolutional neural network (DCNN) is the state-of-the-art method for\nimage segmentation, which is one of key challenging computer vision tasks.\nHowever, DCNN requires a lot of training images with corresponding image masks\nto get a good segmentation result. Image annotation software which is easy to\nuse and allows fast image mask generation is in great demand. To the best of\nour knowledge, all existing image annotation software support only drawing\nbounding polygons, bounding boxes, or bounding ellipses to mark target objects.\nThese existing software are inefficient when targeting objects that have\nirregular shapes (e.g., defects in fabric images or tire images). In this paper\nwe design an easy-to-use image annotation software called Mask Editor for image\nmask generation. Mask Editor allows drawing any bounding curve to mark objects\nand improves efficiency to mark objects with irregular shapes. Mask Editor also\nsupports drawing bounding polygons, drawing bounding boxes, drawing bounding\nellipses, painting, erasing, super-pixel-marking, image cropping, multi-class\nmasks, mask loading, and mask modifying.",
    "  Given a commutative ring $A$, a \"formal $A$-module\" is a formal group\nequipped with an action of $A$. There exists a classifying ring $L^A$ of formal\n$A$-modules. This paper proves structural results about $L^A$ and about the\nmoduli stack $\\mathcal{M}_{fmA}$ of formal $A$-modules. We use these structural\nresults to aid in explicit calculations of flat cohomology groups of\n$\\mathcal{M}_{fmA}^{2-buds}$, the moduli stack of formal $A$-module $2$-buds.\nFor example, we find that a generator of the group\n$H^1_{fl}(\\mathcal{M}_{fm\\mathbb{Z}}; \\omega)$, which also generates (via the\nAdams-Novikov spectral sequence) the first stable homotopy group of spheres,\nalso yields a generator of the $A$-module $H^1_{fl}(\\mathcal{M}_{fmA}^{2-buds};\n\\omega)$ for any torsion-free Noetherian commutative ring $A$. We show that the\norder of the $A$-modules $H^1_{fl}(\\mathcal{M}_{fmA}^{2-buds}; \\omega)$ and\n$H^2_{fl}(\\mathcal{M}_{fmA}^{2-buds}; \\omega\\otimes \\omega)$ are each equal to\n$2^{N_1}$, where $N_1$ is the leading coefficient in the $2$-local\nzeta-function of $Spec A$. We also find that the cohomology of\n$\\mathcal{M}_{fmA}^{2-buds}$ is closely connected to the delta-invariant and\nsyzygetic ideals studied in commutative algebra:\n$H^0_{fl}(\\mathcal{M}_{fmA}^{2-buds}; \\omega\\otimes \\omega)$ is the\ndelta-invariant of the largest ideal of $A$ which is in the kernel of every\nring homomorphism $A\\rightarrow \\mathbb{F}_2$, and consequently\n$H^0_{fl}(\\mathcal{M}_{fmA}^{2-buds}; \\omega\\otimes \\omega)$ vanishes if and\nonly if $A$ is a ring in which that ideal is syzygetic.\n",
    "  We discuss the development, verification, and performance of a GPU\naccelerated discontinuous Galerkin method for the solutions of two dimensional\nnonlinear shallow water equations. The shallow water equations are hyperbolic\npartial differential equations and are widely used in the simulation of tsunami\nwave propagations. Our algorithms are tailored to take advantage of the single\ninstruction multiple data (SIMD) architecture of graphic processing units. The\ntime integration is accelerated by local time stepping based on a multi-rate\nAdams-Bashforth scheme. A total variational bounded limiter is adopted for\nnonlinear stability of the numerical scheme. This limiter is coupled with a\nmass and momentum conserving positivity preserving limiter for the special\ntreatment of a dry or partially wet element in the triangulation. Accuracy,\nrobustness and performance are demonstrated with the aid of test cases. We\ncompare the performance of the kernels expressed in a portable threading\nlanguage OCCA, when cross compiled with OpenCL, CUDA, and OpenMP at runtime.\n",
    "Deep learning-based semi-supervised learning (SSL) algorithms have led to\npromising results in medical images segmentation and can alleviate doctors'\nexpensive annotations by leveraging unlabeled data. However, most of the\nexisting SSL algorithms in literature tend to regularize the model training by\nperturbing networks and/or data. Observing that multi/dual-task learning\nattends to various levels of information which have inherent prediction\nperturbation, we ask the question in this work: can we explicitly build\ntask-level regularization rather than implicitly constructing networks- and/or\ndata-level perturbation-and-transformation for SSL? To answer this question, we\npropose a novel dual-task-consistency semi-supervised framework for the first\ntime. Concretely, we use a dual-task deep network that jointly predicts a\npixel-wise segmentation map and a geometry-aware level set representation of\nthe target. The level set representation is converted to an approximated\nsegmentation map through a differentiable task transform layer. Simultaneously,\nwe introduce a dual-task consistency regularization between the level\nset-derived segmentation maps and directly predicted segmentation maps for both\nlabeled and unlabeled data. Extensive experiments on two public datasets show\nthat our method can largely improve the performance by incorporating the\nunlabeled data. Meanwhile, our framework outperforms the state-of-the-art\nsemi-supervised medical image segmentation methods. Code is available at:\nhttps://github.com/Luoxd1996/DTC",
    "Image segmentation is an important task in many medical applications. Methods\nbased on convolutional neural networks attain state-of-the-art accuracy;\nhowever, they typically rely on supervised training with large labeled\ndatasets. Labeling medical images requires significant expertise and time, and\ntypical hand-tuned approaches for data augmentation fail to capture the complex\nvariations in such images.\n  We present an automated data augmentation method for synthesizing labeled\nmedical images. We demonstrate our method on the task of segmenting magnetic\nresonance imaging (MRI) brain scans. Our method requires only a single\nsegmented scan, and leverages other unlabeled scans in a semi-supervised\napproach. We learn a model of transformations from the images, and use the\nmodel along with the labeled example to synthesize additional labeled examples.\nEach transformation is comprised of a spatial deformation field and an\nintensity change, enabling the synthesis of complex effects such as variations\nin anatomy and image acquisition procedures. We show that training a supervised\nsegmenter with these new examples provides significant improvements over\nstate-of-the-art methods for one-shot biomedical image segmentation. Our code\nis available at https://github.com/xamyzhao/brainstorm.",
    "Superpixel segmentation is becoming ubiquitous in computer vision. In\npractice, an object can either be represented by a number of segments in finer\nlevels of detail or included in a surrounding region at coarser levels of\ndetail, and thus a superpixel segmentation hierarchy is useful for applications\nthat require different levels of image segmentation detail depending on the\nparticular image objects segmented. Unfortunately, there is no method that can\ngenerate all scales of superpixels accurately in real-time. As a result, a\nsimple yet effective algorithm named Super Hierarchy (SH) is proposed in this\npaper. It is as accurate as the state-of-the-art but 1-2 orders of magnitude\nfaster. The proposed method can be directly integrated with recent efficient\nedge detectors like the structured forest edges to significantly outperforms\nthe state-of-the-art in terms of segmentation accuracy. Quantitative and\nqualitative evaluation on a number of computer vision applications was\nconducted, demonstrating that the proposed method is the top performer.",
    "  Neutron stars have long been regarded as extra-terrestrial laboratories from\nwhich we can learn about extreme energy density matter at low temperatures. In\nthis article, I highlight some of the recent advances made in astrophysical\nobservations and related theory. Although the focus is on the much needed\ninformation on masses and radii of several individual neutron stars, the need\nfor additional knowledge about the many facets of neutron stars is stressed.\nThe extent to which quark matter can be present in neutron stars is summarized\nwith emphasis on the requirement of non-perturbative treatments. Some\nlongstanding and new questions, answers to which will advance our current\nstatus of knowledge, are posed.\n",
    "  We make use of supersymmetric quantum mechanics (SUSY QM) to find three sets\nof conditions under which the problem of a planar quantum pendulum becomes\nanalytically solvable. The analytic forms of the pendulum's eigenfuntions make\nit possible to find analytic expressions for observables of interest, such as\nthe expectation values of the angular momentum squared and of the orientation\nand alignment cosines as well as of the eigenenergy. Furthermore, we find that\nthe topology of the intersections of the pendulum's eigenenergy surfaces can be\ncharacterized by a single integer index whose values correspond to the sets of\nconditions under which the analytic solutions to the quantum pendulum problem\nexist.\n",
    "Recently, neural architecture search (NAS) has been applied to automatically\nsearch high-performance networks for medical image segmentation. The NAS search\nspace usually contains a network topology level (controlling connections among\ncells with different spatial scales) and a cell level (operations within each\ncell). Existing methods either require long searching time for large-scale 3D\nimage datasets, or are limited to pre-defined topologies (such as U-shaped or\nsingle-path). In this work, we focus on three important aspects of NAS in 3D\nmedical image segmentation: flexible multi-path network topology, high search\nefficiency, and budgeted GPU memory usage. A novel differentiable search\nframework is proposed to support fast gradient-based search within a highly\nflexible network topology search space. The discretization of the searched\noptimal continuous model in differentiable scheme may produce a sub-optimal\nfinal discrete model (discretization gap). Therefore, we propose a topology\nloss to alleviate this problem. In addition, the GPU memory usage for the\nsearched 3D model is limited with budget constraints during search. Our\nDifferentiable Network Topology Search scheme (DiNTS) is evaluated on the\nMedical Segmentation Decathlon (MSD) challenge, which contains ten challenging\nsegmentation tasks. Our method achieves the state-of-the-art performance and\nthe top ranking on the MSD challenge leaderboard.",
    "Deep learning (DL) approaches are state-of-the-art for many medical image\nsegmentation tasks. They offer a number of advantages: they can be trained for\nspecific tasks, computations are fast at test time, and segmentation quality is\ntypically high. In contrast, previously popular multi-atlas segmentation (MAS)\nmethods are relatively slow (as they rely on costly registrations) and even\nthough sophisticated label fusion strategies have been proposed, DL approaches\ngenerally outperform MAS. In this work, we propose a DL-based label fusion\nstrategy (VoteNet) which locally selects a set of reliable atlases whose labels\nare then fused via plurality voting. Experiments on 3D brain MRI data show that\nby selecting a good initial atlas set MAS with VoteNet significantly\noutperforms a number of other label fusion strategies as well as a direct DL\nsegmentation approach. We also provide an experimental analysis of the upper\nperformance bound achievable by our method. While unlikely achievable in\npractice, this bound suggests room for further performance improvements.\nLastly, to address the runtime disadvantage of standard MAS, all our results\nmake use of a fast DL registration approach.",
    "Registration is a fundamental task in medical robotics and is often a crucial\nstep for many downstream tasks such as motion analysis, intra-operative\ntracking and image segmentation. Popular registration methods such as ANTs and\nNiftyReg optimize objective functions for each pair of images from scratch,\nwhich are time-consuming for 3D and sequential images with complex\ndeformations. Recently, deep learning-based registration approaches such as\nVoxelMorph have been emerging and achieve competitive performance. In this\nwork, we construct a test-time training for deep deformable image registration\nto improve the generalization ability of conventional learning-based\nregistration model. We design multi-scale deep networks to consecutively model\nthe residual deformations, which is effective for high variational\ndeformations. Extensive experiments validate the effectiveness of multi-scale\ndeep registration with test-time training based on Dice coefficient for image\nsegmentation and mean square error (MSE), normalized local cross-correlation\n(NLCC) for tissue dense tracking tasks. Two videos are in\nhttps://www.youtube.com/watch?v=NvLrCaqCiAE and\nhttps://www.youtube.com/watch?v=pEA6ZmtTNuQ",
    "Transmission electron microscopy (TEM) is one of the primary tools to show\nmicrostructural characterization of materials as well as film thickness.\nHowever, manual determination of film thickness from TEM images is\ntime-consuming as well as subjective, especially when the films in question are\nvery thin and the need for measurement precision is very high. Such is the case\nfor head overcoat (HOC) thickness measurements in the magnetic hard disk drive\nindustry. It is therefore necessary to develop software to automatically\nmeasure HOC thickness. In this paper, for the first time, we propose a HOC\nlayer segmentation method using NASNet-Large as an encoder and then followed by\na decoder architecture, which is one of the most commonly used architectures in\ndeep learning for image segmentation. To further improve segmentation results,\nwe are the first to propose a post-processing layer to remove irrelevant\nportions in the segmentation result. To measure the thickness of the segmented\nHOC layer, we propose a regressive convolutional neural network (RCNN) model as\nwell as orthogonal thickness calculation methods. Experimental results\ndemonstrate a higher dice score for our model which has lower mean squared\nerror and outperforms current state-of-the-art manual measurement.",
    "When confronted with objects of unknown types in an image, humans can\neffortlessly and precisely tell their visual boundaries. This recognition\nmechanism and underlying generalization capability seem to contrast to\nstate-of-the-art image segmentation networks that rely on large-scale\ncategory-aware annotated training samples. In this paper, we make an attempt\ntowards building models that explicitly account for visual boundary knowledge,\nin hope to reduce the training effort on segmenting unseen categories.\nSpecifically, we investigate a new task termed as Boundary Knowledge\nTranslation (BKT). Given a set of fully labeled categories, BKT aims to\ntranslate the visual boundary knowledge learned from the labeled categories, to\na set of novel categories, each of which is provided only a few labeled\nsamples. To this end, we propose a Translation Segmentation Network\n(Trans-Net), which comprises a segmentation network and two boundary\ndiscriminators. The segmentation network, combined with a boundary-aware\nself-supervised mechanism, is devised to conduct foreground segmentation, while\nthe two discriminators work together in an adversarial manner to ensure an\naccurate segmentation of the novel categories under light supervision.\nExhaustive experiments demonstrate that, with only tens of labeled samples as\nguidance, Trans-Net achieves close results on par with fully supervised\nmethods.",
    "Deep reinforcement learning augments the reinforcement learning framework and\nutilizes the powerful representation of deep neural networks. Recent works have\ndemonstrated the remarkable successes of deep reinforcement learning in various\ndomains including finance, medicine, healthcare, video games, robotics, and\ncomputer vision. In this work, we provide a detailed review of recent and\nstate-of-the-art research advances of deep reinforcement learning in computer\nvision. We start with comprehending the theories of deep learning,\nreinforcement learning, and deep reinforcement learning. We then propose a\ncategorization of deep reinforcement learning methodologies and discuss their\nadvantages and limitations. In particular, we divide deep reinforcement\nlearning into seven main categories according to their applications in computer\nvision, i.e. (i)landmark localization (ii) object detection; (iii) object\ntracking; (iv) registration on both 2D image and 3D image volumetric data (v)\nimage segmentation; (vi) videos analysis; and (vii) other applications. Each of\nthese categories is further analyzed with reinforcement learning techniques,\nnetwork design, and performance. Moreover, we provide a comprehensive analysis\nof the existing publicly available datasets and examine source code\navailability. Finally, we present some open issues and discuss future research\ndirections on deep reinforcement learning in computer vision",
    "Deep learning has become in recent years a cornerstone tool fueling key\ninnovations in the industry, such as autonomous driving. To attain good\nperformances, the neural network architecture used for a given application must\nbe chosen with care. These architectures are often handcrafted and therefore\nprone to human biases and sub-optimal selection. Neural Architecture Search\n(NAS) is a framework introduced to mitigate such risks by jointly optimizing\nthe network architectures and its weights. Albeit its novelty, it was applied\non complex tasks with significant results - e.g. semantic image segmentation.\nIn this technical paper, we aim to evaluate its ability to tackle a challenging\noperational task: semantic segmentation of objects of interest in satellite\nimagery. Designing a NAS framework is not trivial and has strong dependencies\nto hardware constraints. We therefore motivate our NAS approach selection and\nprovide corresponding implementation details. We also present novel ideas to\ncarry out other such use-case studies."
  ],
  "sampled": [
    "This paper presents a novel approach for synthesizing aperture sonar image segmentation using an iterative, deep, and unsupervised method. Traditional segmentation techniques for synthetic aperture sonar images rely on manual annotation or require a large amount of labeled data for training. These limitations restrict the applicability and flexibility of those methods. To overcome these challenges, we propose an iterative approach that uses a deep learning framework to learn and refine the segmentation process. Our proposed method does not require any labeled data for training, making it particularly useful in scenarios where labeled data is scarce or unavailable. Experimental results showed that the proposed method outperforms existing approaches in terms of accuracy and robustness. This work contributes to the field by providing a more efficient and practical solution for synthetic aperture sonar image segmentation.",
    "Image segmentation is a crucial task in computer vision and image processing. Cellular Automata (CA) have been widely used for various applications due to their simplicity and parallel processing capabilities. In this paper, we propose a novel approach for image segmentation using CA. Our method leverages the self-organization and emergent behavior of CA to segment images into regions with similar characteristics. We define a set of rules governing the behavior of individual cells in the CA, which are then applied iteratively to update the state of each cell based on its neighbors. We demonstrate the effectiveness of our method through experiments on a variety of datasets, comparing our results with state-of-the-art segmentation algorithms. Our approach achieves competitive performance in terms of accuracy and computational efficiency, highlighting the potential of CA in image segmentation tasks.",
    "In this paper, we present a novel approach for defining datatypes in rewrite systems for naturals and integers. We start by introducing the basic concepts of rewrite systems and their role in formalizing algorithms and computations. We then propose a datatype definition mechanism that allows for the formalization of natural numbers and integers within these systems. We demonstrate the usefulness of our approach through several examples and discuss the advantages and limitations of our method. Overall, our work provides a foundation for future research in datatype definitions for a wide range of mathematical objects within rewrite systems.",
    "This paper investigates the behavior of the leading coefficient of polynomials orthogonal over domains with corners. The authors derive a formula for the leading coefficient in terms of the corner angles and the weight function. They also provide numerical examples to illustrate the behavior of the leading coefficient for different corner angles. The results of this study contribute to a better understanding of the properties of orthogonal polynomials over domains with corners and can be applied in various fields such as approximation theory and numerical analysis.",
    "This paper presents an efficient decomposition framework for discriminative segmentation using supermodular losses. Discriminative segmentation is an important task in computer vision that involves assigning labels to each pixel in an image. Supermodular losses have been shown to be effective for this task, but their high computational complexity limits their applicability. To address this issue, the authors propose a decomposition framework that breaks the problem into two sub-problems: pixel classification and pairwise label consistency. They also propose an efficient algorithm for solving the sub-problems, which reduces the computational complexity of the overall segmentation task. Experimental results on benchmark datasets demonstrate the effectiveness and efficiency of the proposed framework compared to existing methods. Overall, this paper provides a valuable contribution to the field of discriminative segmentation and offers a practical solution for improving the efficiency of supermodular losses.",
    "This paper investigates the solvability of unit equations over finitely generated domains. Specifically, we consider the equation x^n = u, where x is an unknown element, n is a positive integer, and u is a unit in the domain. We provide necessary and sufficient conditions for the existence of solutions to this equation, and we also establish a method for finding all solutions when they do exist. Our results have applications in various areas of mathematics, including number theory and algebraic geometry.",
    "In this paper, we report on the direct observation of a gate tunable band-gap in electrical transport in ABC-trilayer graphene. We demonstrate that by applying a gate voltage, the band-gap in the trilayer graphene can be tuned, leading to significant changes in the electrical transport properties. We use a combination of scanning tunneling microscopy and spectroscopy to directly measure the band-gap and observe its tunability. Our results provide important insights into the electronic properties of trilayer graphene and open up new possibilities for its use in electronic devices.",
    "We investigate the dynamics of self-maintaining defect/droplets formed by two interacting Bose-Einstein condensates. By solving the Gross-Pitaevskii equation numerically, we show that the defect/droplets exhibit a robust behavior and can persist indefinitely without external perturbations. We analyze the stability properties of the defect/droplets and identify the key factors that contribute to their formation and maintenance. Our results provide insights into the fundamental properties of self-maintaining defect/droplets and offer potential applications in the field of nonlinear optics and quantum computing.",
    "In this paper, we study the height of piecewise-testable languages, which are a special class of regular languages. We provide a detailed analysis of the complexity of the logic of subwords for these languages. Specifically, we focus on determining the height of these languages and the relationship between their height and the complexity of their logic of subwords. We present several theorems and proofs to support our findings. Our results contribute to a better understanding of piecewise-testable languages and their associated logic of subwords.",
    "This paper presents a novel approach for decomposing 3D scenes into objects using unsupervised volume segmentation. The proposed method leverages the power of deep learning techniques to automatically segment volumetric data into individual objects without the need for manual annotation. The approach combines a 3D convolutional neural network with a clustering algorithm to identify and separate objects within a scene. Experimental results demonstrate the effectiveness of the proposed method in accurately decomposing complex 3D scenes into their constituent objects. The proposed approach has potential applications in various fields such as computer vision, robotics, and virtual reality.",
    "The paper \"Characteristics of Optimal Solutions to the Sensor Location Problem\" investigates the characteristics of optimal solutions to the sensor location problem. The sensor location problem is a well-known optimization problem in which the goal is to determine the optimal locations for a set of sensors in order to maximize the coverage of a given area. The paper presents a comprehensive analysis of the characteristics of optimal solutions, including their spatial distribution, density, and connectivity. The analysis is based on a mathematical model of the sensor location problem and is supported by extensive computational experiments. The results of the study provide valuable insights into the properties of optimal solutions and can be used to guide the design and implementation of sensor networks in various applications.",
    "DeepAtlas is an academic paper proposing a new framework called Joint Semi-Supervised Learning for Image Registration and Segmentation. The paper discusses the importance of accurate image registration and segmentation in various medical imaging applications and presents a novel technique that combines both tasks into a single learning framework. The proposed method utilizes deep learning techniques such as convolutional neural networks (CNNs) and graph cuts to simultaneously learn image registration and segmentation in a semi-supervised manner. Experimental results on medical image datasets demonstrate that the proposed method outperforms existing techniques in terms of both registration accuracy and segmentation quality. The paper concludes by suggesting potential future research directions and applications for the proposed framework.",
    "The paper proposes a new evaluation metric called Boundary IoU for object-centric image segmentation. The metric aims to address the limitations of existing metrics such as IoU and Dice coefficient, which do not consider the quality of object boundaries. Boundary IoU measures the overlap between the predicted object boundaries and the ground truth boundaries, taking into account both the spatial and boundary information. The authors demonstrate the effectiveness of Boundary IoU through experiments on various datasets and compare it with other metrics. The results show that Boundary IoU provides a more accurate and comprehensive evaluation of object-centric image segmentation algorithms. The paper concludes by discussing the potential applications and future directions of Boundary IoU in the field of computer vision.",
    "This paper investigates the homotopy invariants of combings of 3-manifolds. A combing is a way to assign a preferred direction to each point on a manifold. The authors define a new homotopy invariant called the combing group, which captures the essential information about the combing. They prove that the combing group is isomorphic to the fundamental group of the manifold, and show that it is a complete invariant for certain classes of 3-manifolds. The paper also explores the relationship between combings and other well-known invariants, such as the Thurston norm and the Heegaard genus. Overall, this work provides a deeper understanding of the structure and properties of combings of 3-manifolds.",
    "The paper discusses the concept of snow leopard permutations and their even and odd threads. Snow leopard permutations are a type of permutation where each of the elements is either positive or negative. The authors examine the properties and structure of snow leopard permutations and introduce the concept of even and odd threads within these permutations. Even threads are defined as substring sequences that contain an equal number of positive and negative elements, while odd threads contain an odd number of either positive or negative elements. The authors provide formal definitions and rules for even and odd threads within snow leopard permutations. Furthermore, they explore the algebraic properties of these permutations and discuss the implications and potential applications of their findings in various fields such as cryptography and combinatorics. Overall, the paper contributes to the understanding of snow leopard permutations and their underlying structure, highlighting the significance of even and odd threads in these permutations.",
    "YouTube-VOS is a large-scale video object segmentation benchmark that aims to advance the state-of-the-art in this field. The benchmark consists of a diverse set of 4,453 YouTube videos, each containing multiple annotated object masks. The dataset is carefully curated to cover a wide range of object categories, motion patterns, and video quality. The paper presents the details of the dataset, including the annotation process and evaluation metrics. Additionally, the authors provide an analysis of the current state-of-the-art methods on the benchmark and highlight the challenges and opportunities for future research in video object segmentation. The YouTube-VOS benchmark is expected to facilitate the development of more accurate and robust algorithms for video object segmentation.",
    "This paper explores the field of quantum cryptography beyond current implementations of quantum key distribution (QKD). It focuses on novel cryptographic protocols that utilize quantum mechanics to provide information security. The authors present an overview of QKD and its limitations, including issues with security assumptions and practical implementations. They then discuss different approaches to quantum cryptography, such as quantum money, quantum signatures, and quantum secure multi-party computation. The paper also examines experimental advancements in quantum cryptography and their potential applications in fields like secure cloud computing and blockchain technology. Overall, this research highlights the potential for quantum cryptography to revolutionize information security beyond traditional methods of key distribution and encryption.",
    "This paper presents a novel unsupervised video object segmentation method called Anchor Diffusion. The proposed method leverages the temporal coherence of video frames to improve the accuracy of object segmentation. It introduces the concept of anchor frames, which are selected based on their visual similarity to the target frame. These anchor frames are then used to propagate object masks across frames using a diffusion process. Experimental results on benchmark datasets demonstrate that the proposed method outperforms existing state-of-the-art methods in terms of segmentation accuracy and temporal consistency. The paper also provides an analysis of the computational efficiency of the proposed method, showing that it is computationally efficient and scalable to large-scale video datasets. Overall, Anchor Diffusion offers a promising approach for unsupervised video object segmentation.",
    "In magnetic resonance imaging (MRI), the degree of radiation damping (RD) can significantly affect the accuracy and precision of inversion recovery measurements. This paper investigates the characterization and suppression techniques for RD in inversion recovery measurements. A thorough analysis of the factors influencing RD is presented, and a new method for quantifying RD is proposed. Additionally, several suppression techniques, including gradient spoiling, RF pulse alterations, and sequence modifications, are evaluated and compared. Experimental results demonstrate the effectiveness of these techniques in mitigating the effects of RD and improving the accuracy of inversion recovery measurements in MRI. The findings of this study provide valuable insights into the understanding and control of RD in MRI, contributing to the advancement of quantitative imaging techniques.",
    "This paper investigates the properties of two-generator free Kleinian groups and their hyperbolic displacements. The authors provide a comprehensive analysis of the geometric and algebraic properties of these groups, including their limit sets and invariant measures. They also study the relationship between the hyperbolic displacements of the generators and the dynamics of the group. The results of this study contribute to our understanding of the structure and behavior of two-generator free Kleinian groups, and have potential applications in various areas of mathematics and physics.",
    "This paper proposes a novel method for segmenting two-dimensional structures using strided tensor networks. The method utilizes the concept of tensor networks to model the relationships between neighboring pixels in an image. By applying a strided decomposition to the tensor network, we can effectively capture long-range dependencies between pixels while reducing the computational complexity. We demonstrate the effectiveness of our method on various segmentation tasks, including object detection and semantic segmentation. The experimental results show that our method achieves state-of-the-art performance in terms of segmentation accuracy and computational efficiency. Overall, our work contributes to the field of image segmentation by providing a new approach that combines the strengths of tensor networks and strided decomposition.",
    "This paper presents a novel approach for texture fuzzy segmentation using skew divergence adaptive affinity functions. The proposed method aims to improve the accuracy and efficiency of texture segmentation by incorporating adaptive affinity functions based on skew divergence. The skew divergence is used to measure the dissimilarity between two texture regions, and the adaptive affinity functions are designed to capture the local texture characteristics. Experimental results on various texture datasets demonstrate that the proposed method outperforms existing segmentation techniques in terms of segmentation accuracy and computational efficiency. The findings of this study contribute to the field of texture segmentation and provide a valuable tool for image analysis and computer vision applications.",
    "This paper presents a novel approach for 3D semi-supervised learning using uncertainty-aware multi-view co-training. The proposed method leverages multiple views of 3D data to improve the performance of semi-supervised learning algorithms. The key idea is to use uncertainty estimates from each view to guide the co-training process, where the most uncertain samples are selected for labeling. The uncertainty estimates are obtained using a deep neural network that is trained to predict the confidence of the model's predictions. Experimental results on several benchmark datasets demonstrate the effectiveness of the proposed method, achieving state-of-the-art performance in 3D semi-supervised learning tasks. The proposed approach has the potential to be applied in various domains, such as computer vision and robotics, where 3D data is prevalent.",
    "This academic paper presents a method for interactive segmentation of medical images using fully convolutional neural networks (FCNs). It addresses the common challenge in medical image segmentation where a large amount of labeled training data is not always available. The proposed method utilizes FCNs to learn the segmentation task from a relatively small set of annotated images. In addition, it incorporates an interactive user interface to refine the segmentation results in real-time, providing immediate feedback to the user. Experimental results on a dataset of medical images demonstrate the effectiveness of the proposed method, achieving competitive segmentation accuracy compared to state-of-the-art techniques. The interactive nature of the system allows for quick adjustments and corrections, making it suitable for various medical imaging applications.",
    "Histopathology image segmentation is a critical task in medical image analysis, as it plays a crucial role in the diagnosis and treatment of various diseases. However, obtaining accurate and reliable segmentation results is challenging due to the limited availability of labeled data. In this paper, we propose a novel approach for histopathology image segmentation that leverages unlabeled data to improve the performance of semi-supervised learning. Our method combines a deep convolutional neural network with a self-training framework, where the network is trained on a small set of labeled data and then iteratively refined using a larger set of unlabeled data. We also introduce a novel loss function that encourages consistency between the predictions of the network on labeled and unlabeled data. Experimental results on a publicly available dataset demonstrate that our approach outperforms state-of-the-art methods in terms of segmentation accuracy and robustness. Our findings suggest that incorporating unlabeled data can significantly enhance the performance of histopathology image segmentation, and our proposed method provides a promising solution for this challenging task.",
    "Magnetic reconnection is a fundamental process in plasma physics that occurs in various astrophysical and laboratory settings. It is known to generate high-energy particles through the acceleration of ions. In this paper, we investigate the effect of large-scale effective potentials on ion heating during magnetic reconnection. We find that these potentials can significantly reduce ion heating by suppressing the acceleration of ions. Our results suggest that the presence of large-scale effective potentials can have important implications for understanding the dynamics of magnetic reconnection and the generation of high-energy particles in astrophysical and laboratory plasmas.",
    "The paper \"Upper bounds for sunflower-free sets\" presents new upper bounds for the size of sunflower-free sets. A sunflower is a collection of sets where each pair of sets has a non-empty intersection. Sunflower-free sets have applications in various areas of computer science, including combinatorics and complexity theory. The paper introduces a new technique called the \"compression method\" to derive upper bounds for sunflower-free sets. The authors prove that the size of a sunflower-free set is at most exponential in the logarithm of the number of sets in the sunflower. The paper also provides examples and applications of the compression method in different scenarios. Overall, the paper contributes to the understanding of sunflower-free sets and provides new insights into their size and properties.",
    "This paper presents an analysis of the HI (neutral hydrogen) content of extremely metal-deficient blue compact dwarf galaxies (BCDs). The HI observations were conducted using various radio telescopes, and the metallicity measurements were obtained from optical spectroscopic data. The study found that the HI content of these BCDs is significantly higher compared to normal BCDs, suggesting that the metallicity of the gas is a key factor in determining the HI content in these systems. The paper discusses the implications of these findings in the context of galaxy evolution and the role of metal enrichment in shaping the properties of BCDs.",
    "In this paper, we investigate the complementary relation between quantum coherence and quantum correlations in multiple measurements. We consider a system composed of multiple qubits and study the behavior of coherence and correlations under different measurement scenarios. We find that there exists a trade-off between coherence and correlations, such that an increase in coherence leads to a decrease in correlations and vice versa. We provide a quantitative measure for this trade-off and show that it holds for various types of measurements. Our results shed light on the fundamental connection between coherence and correlations in quantum systems and have implications for the design and optimization of quantum information processing tasks.",
    "This paper introduces a new analytic invariant for G_2 manifolds, which are seven-dimensional Riemannian manifolds with a special holonomy group. The invariant is defined using the Laplacian operator and the Hodge star operator, and it captures important geometric and topological information about the manifold. The paper presents several examples and applications of the invariant, including its use in distinguishing different G_2 manifolds and in studying their moduli spaces. The results of this paper contribute to the understanding of G_2 manifolds and provide new tools for their classification and analysis.",
    "This paper introduces a flexible regularization approach for mixture models and applies it to image segmentation. Mixture models are widely used in various fields, including image processing and computer vision. However, existing methods often assume fixed regularization parameters, which may not be optimal for different applications or data sets. To address this, we propose a regularization framework that allows the parameters to vary and adapt to the specific characteristics of the data. In particular, we use the Bayesian framework with a mixture of Gaussians model, and introduce flexible regularization terms to automatically determine the level of regularization for each component. We demonstrate the effectiveness of our approach on image segmentation tasks, where accurate delineation of objects and boundaries is crucial. Experimental results on various datasets show that our method outperforms existing techniques in terms of both quantitative evaluation metrics and visual quality. Overall, our flexible regularization framework provides a powerful tool for improving the performance of mixture models in image segmentation tasks.",
    "Few-shot medical image segmentation is a challenging task due to the limited availability of annotated data. In this paper, we propose a recurrent mask refinement approach for few-shot medical image segmentation. Our method leverages a pre-trained segmentation network and a few annotated images to generate initial segmentation masks. These masks are then refined iteratively using a recurrent neural network. The recurrent network takes the initial masks as input and produces refined masks as output. We evaluate our method on two publicly available medical image segmentation datasets and compare it with state-of-the-art few-shot segmentation methods. Our results demonstrate that our recurrent mask refinement approach achieves superior performance in terms of segmentation accuracy and generalization ability. Furthermore, we conduct ablation studies to analyze the effectiveness of different components in our method. Overall, our proposed approach shows promising potential for improving few-shot medical image segmentation.",
    "Image segmentation is a fundamental task in computer vision and has various applications in fields such as object recognition and medical imaging. Traditional image segmentation methods often require manual selection of threshold values, which can be time-consuming and subjective. In this paper, we propose a novel approach for image segmentation using Learning Automata (LA) to automatically determine multiple threshold values. The LA algorithm is trained using a fitness function that evaluates the quality of the segmentation. Experimental results on various images demonstrate the effectiveness of our approach in achieving accurate and efficient image segmentation.",
    "The paper introduces a new loss function called the Lovsz-Softmax loss, which serves as a tractable surrogate for optimizing the intersection-over-union (IoU) measure in neural networks. The IoU measure is commonly used in tasks such as image segmentation, but its non-differentiability poses challenges for optimization. The Lovsz-Softmax loss addresses this issue by providing a differentiable approximation of the IoU measure. The paper presents theoretical analysis and experimental results demonstrating the effectiveness of the proposed loss function in improving the performance of neural networks on various segmentation tasks. The Lovsz-Softmax loss offers a practical and efficient solution for optimizing the IoU measure in neural networks.",
    "Automatic liver lesion segmentation plays a crucial role in the diagnosis and treatment of liver diseases. In this paper, we propose a novel deep learning architecture called Feature Fusion Encoder Decoder Network (FFED-Net) for automatic liver lesion segmentation. The FFED-Net combines the strengths of both encoder-decoder networks and feature fusion techniques to improve the accuracy and robustness of liver lesion segmentation. We evaluate the performance of the FFED-Net on a publicly available liver lesion segmentation dataset and compare it with several state-of-the-art methods. The experimental results demonstrate that the FFED-Net achieves superior performance in terms of segmentation accuracy and computational efficiency. Our proposed FFED-Net has the potential to assist radiologists in accurately and efficiently segmenting liver lesions, thereby facilitating the diagnosis and treatment of liver diseases.",
    "Algebraic multigrid (AMG) methods have been widely used to solve linear systems arising in particle methods. However, most of the existing literature focuses on symmetric matrices. In this paper, we investigate the performance of AMG methods for non-symmetric matrices arising in particle methods. Specifically, we consider two types of non-symmetric matrices: those corresponding to the connections between particles in physical space and those corresponding to the connections between particles in parameter space. We compare the performance of two popular AMG methods, namely smoothed aggregation (SA) and algebraic multigrid (AMG), on a set of test problems. Our results show that SA outperforms AMG for both types of non-symmetric matrices, highlighting the importance of considering non-symmetric matrices in the design of AMG methods for particle methods. We also provide some insights into the reasons behind the observed performance differences. Overall, this paper contributes to a better understanding of the performance of AMG methods for non-symmetric matrices in particle methods and provides guidance for selecting appropriate AMG methods in practice.",
    "This paper proposes a novel approach called Concurrent Spatial and Channel Squeeze & Excitation (CSCSE) for improving the performance of fully convolutional networks (FCNs). The CSCSE method combines the spatial and channel squeeze & excitation operations, which are commonly used in convolutional neural networks (CNNs), to enhance the representation power of FCNs. The spatial squeeze & excitation operation captures the spatial dependencies within feature maps, while the channel squeeze & excitation operation captures the channel-wise dependencies. By concurrently applying both operations, the CSCSE method effectively captures both spatial and channel-wise dependencies, leading to improved feature representation and better performance in various computer vision tasks. Experimental results on benchmark datasets demonstrate the effectiveness of the proposed CSCSE method in improving the performance of FCNs compared to existing methods.",
    " We present a skin lesion segmentation model based on Encoder-Decoder with Attended Aggregated Multi-resolution Skip Connections (EA-MDSC). It leverages a multi-resolution encoding of the entire image through a composition of encoders and decoders. EA-MDSC employs attention mechanisms to focus on the regions of interest, while aggregating multi-resolution contextual information through skip connections. The model is trained end-to-end on a public dataset from mass-screening clinical images with segmentation maps as ground truth. We evaluate our model on the ISBI 2019 Skin Lesion Segmentation Challenge, achieving a performance that is on par with the winners, while being more than 14 times faster computationally. Furthermore, our model generalizes better on the MLH dataset, achieving a Dice Similarity Coefficient of 0.8838, against the winners' 0.8252. Code is available at https://github.com/Embedding/skin-lesion-segmentation-baseline.",
    " Abstract:\n    We perform an empirical investigation of the Zipf strategy for short-term investments in WIG20 futures contracts. The strategy is based on ranking the securities in the portfolio by their recent gains and replacing the security with the largest gain with the security with the smallest gain. We find that the Zipf strategy does not outperform a buy-and-hold strategy in terms of aggregate returns. When we take into account the volatility of returns and the portfolio's overall performance, the Zipf strategy performs worse than a buy-and-hold strategy. These results question the benefits of the Zipf strategy for short-term investments in WIG20 futures contracts.\n\nAuthors:\n    Piotr Jurczyk (piotr.jurczyk@pgs.edu.pl)\n    Witold Skrzypczak (witold.skrzypczak@pgs.edu.pl)",
    " Integrated Inference and Learning of Neural Factors in Structural Support Vector Machines\n\nWhile neural factorization models can express complex distributed computations,\nmost inference algorithms for structural SVM relax the modular structure\nimposed by these models, resulting in a factor graph that is not\nnecessarily sparse or tree-like. In this paper, we propose a new\nalgorithm for exact inference that respects the given factorization\nstructure, and show that the resulting graph has a tree-like structure;\ni.e., can be written as an oriented tree. We then use this inference\nalgorithm as the basis for a new algorithm for learning the weights of\nthe factors in a neural factorization machine. The experimental results\nshow that our method compares favorably with state-of-the-art\nalgorithms for learning neural factorization machines.\n\nKeywords: Neural Factorization Machines, Structural SVM, Graphical Models,\nTree-based Learning.",
    " Recent results in image editing with language have\neither required pixel-level annotations or produced results\nwith significant compositional artifacts through\nconvolutions. In this work, we bridge this gap with a\nlanguage-based image editing model that only requires\nobject-level annotations and synthesizes results with\nhigher-level semantics. Our model is based on a\nrecurrent attentive model (RAM) that processes image\nregions with attention weights to edit objects of\ninterest. We introduce a novel iterative editing\nframework that allows our model to refine its output\nwith successive iterations to generate high-quality\nresults. We demonstrate the effectiveness of our\napproach on image manipulation tasks, where our\nmodel outperforms existing state-of-the-art models in\nterms of quality with the advantages of requiring less\ntraining data and being more general and robust to\nvarious editing operations.",
    " Recent results on data-efficient machine learning have shone a spotlight on the data starvation problem facing many important machine learning applications such as biodiversity monitoring, medical imaging, and fraud detection  there are not enough labeled examples to train a meaningful model. In this paper, we explore the problem of creating labeled datasets using generative models. We propose DatasetGAN, a methodology that uses a generative model to create a dataset of synthetic data instances and uses a discriminative model to distinguish the synthetic data instances from real data instances. The generative model is trained based on feedback from a user regarding the realism of the synthetic data instances, whereas the discriminative model is trained to classify instances as either real or synthetic. We show that, used iteratively, this methodology can create high-quality labeled datasets with as little as 10% of the labeled data usually required. We demonstrate the efficacy of the approach on a variety of datasets including figure drawings, wildlife images, and satellite images of electrical power lines and show that our approach reduces the amount of labeled data needed to achieve state-of-the-art performance on the MNIST benchmark by a factor of 20, and state-of-the-art performance on the EMNIST benchmark by a factor of 10.",
    " Many state-of-the-art segmentation models exploit domain-specific information for better performance but rely on either 1) assuming the availability of domain-specific segmentation models or 2) using heuristic normalization schemes that do not perform well when the distribution of the data is complex. In this paper, we aim to address both of these issues. We propose a realistic image normalization (RIN) approach towards learning a single segmentation model that is able to adapt to multiple domains while maintaining performance. Our approach first estimates the domain-specificity in the image and then compensates for it by adjusting the image pixel-wise so that the distribution becomes more uniform. We demonstrate the effectiveness of our method on three publicly available datasets, and show the advantages against prior art on both segmented and unsegmented images.",
    " An image segmentation method is proposed in this paper, which is based on a combined approach of fuzzy classification and contextual region growing. First, to obtain the initial segments, the image is partitioned into several regions by using a fuzzy classification method. In order to obtain appropriate parameters for the fuzzy classification, we propose to select the appropriate fuzzy rules by using a genetic algorithm. Then, in order to obtain the final segments, the regions obtained by the fuzzy classification are merged into larger segments by using a contextual region growing method, where the merging is based on the similarity between the regions and the gradient of the image. In order to evaluate the performance of the proposed method, the database of UTK-IMDB is used, which is a standard database for benchmarking image segmentation methods. The experimental results show that the proposed method is effective in segmenting medical images.",
    " We present a cross-modal self-attention network (CMSAN) for referring image segmentation. Given a referring expression, our goal is to assign segment labels to each pixel in the corresponding image region. To this end, we propose to use a self-attention mechanism to capture the relationships between referring expressions and image regions, as well as the relationships between the image regions themselves. Specifically, we generate region queries and phrase queries to represent the image regions and referring expressions, respectively. Then, we apply self-attention to compute the weights of the region queries and phrase queries, which indicate the relevance between each region and each phrase. Finally, we use the weighted region queries and phrase queries to predict the segment labels for the image regions. To handle the long-tail problem in referring expressions, we propose to use a progressive attention mechanism, which gradually attends to the long-tail phrases. In addition, to overcome the data imbalance between referring expressions and image regions, we introduce a cross-modal sampling strategy to balance the training samples. Our experimental results on the ReferItSeg dataset show that our method outperforms the state-of-the-art approaches.",
    " Semantic image segmentation, as a fundamental task in computer vision, aims at assigning semantic labels to each pixel in an image. Recently, deep learning methods have shown promising results in this area. However, most existing methods rely on greedy inference, which can result in suboptimal performance. In this paper, we propose a novel approach for semantic image segmentation based on Deep Gaussian CRFs (DGCRFs), which are a class of probabilistic models that leverage deep features learned by convolutional neural networks. By formulating the segmentation problem as a probabilistic inference problem, our approach is able to produce more accurate and robust predictions. We introduce a fast and exact inference algorithm that scales to realistic images. Furthermore, we propose a multi-scale inference scheme that further improves the segmentation quality by exploiting the hierarchical structure of the DGCRFs. Our approach achieves state-of-the-art performance on the PASCAL VOC 2012 segmentation benchmark, significantly improving the popular Deep Convolutional Encoder-Decoder architecture.",
    " Semantic segmentation is a fundamental task in computer vision with a wide range of applications in various fields. However, training such models require large amounts of accurately annotated data, which are often expensive and time-consuming to acquire. In this paper, we tackle the problem of limited data and annotations in semantic segmentation. We propose a new approach that combines weakly-supervised and self-supervised learning techniques to train robust and accurate models with limited resources. Our method leverages the power of graph neural networks to effectively capture the relationships between pixels and enhance the segmentation performance. We demonstrate the effectiveness of our approach on a public semantic segmentation benchmark, showing that our model achieves competitive results compared to strongly-supervised models while using only a fraction of the data and annotations.",
    " We address the problem of domain adaptation for image segmentation, where we have a finite number of labeled source domains and unlabeled target domains, and the goal is to learn a segmentor that performs well on both the source and target domains. We propose a new constraint-based framework for domain adaptation, where we enforce label consistency as well as a similarity constraint between the feature representations of the source and target domains. We show that our approach is able to adapt to the target domain while maintaining performance on the source domains, and we evaluate our method on two public segmentation benchmarks, where we achieve state-of-the-art performance.",
    " Recent works in contrastive learning based on triplet networks achieve remarkable performance in image semantic segmentation. However, they rely on significant amounts of labeled data and fail to adapt to new classes not present in the training set. In this work, we propose a simple yet effective method to improve the performance of triplet networks. Our solution is to use attention maps to weigh the supervised signal. We show that our approach significantly improves performance on semantic segmentation, reducing the error by up to 7% over the state-of-the-art on the VOC2012 dataset, while using less labeled data. We present an easy-to-train end-to-end system that is able to learn a meaningful attention map in a self-supervised manner. When combined with triplet networks, our approach is able to preserve the known benefits of that architecture while using fewer labeled images.",
    " We introduce a new computational paradigm for belief propagation. This new paradigm, which we call Sigma Point Belief Propagation (SPBP), is based on the Monte Carlo approximation of the partition function, analogously to the way in which the quantum partition function is replaced by its classical Monte Carlo analog in Quantum Monte Carlo methods. In SPBP, particles propagate through the graph, summing the log-likelihoods of the variable nodes they visit. The particles also carry a weight which is proportional to the number of visits, and decay over time. These properties enable SPBP to compute the belief propagation iterates in a distributed manner, where particles are propagated through the graph by the variable nodes, and the factor nodes merely weigh and sum the particles. In experiments on synthetic datasets, we show that SPBP can yield an order of magnitude speedup over standard belief propagation, with a relatively small increase in the error.",
    " Recent progress in sketch colorization is primarily focused on accurate color prediction and lacks consideration of semantic segmentation. We propose a new loss function for sketch colorization that combines adversarial loss with segmentation loss, which can improve the colorization results and maintain the localization of the color. The segmentation loss is proposed to enforce the correspondence between the predicted color and the labeled segment map by introducing a threshold on the gradient of the segmentation metric. In addition, we introduce a new loss function for sketch colorization, termed as the adversarial segmentation loss, which combines adversarial loss with the proposed segmentation loss. The adversarial loss can enhance the colorization results by encouraging the predicted color to be more realistic, while the segmentation loss can improve the localization of the color. The proposed method has been evaluated on the public sketch-colorization dataset. The results demonstrate the effectiveness of the proposed method over the state-of-the-art approaches.",
    " We study the Cauchy problem for elliptic complexes in the space of distributions. We show that the existence and uniqueness of solutions to the Cauchy problem imply the completeness of the corresponding initial data. This result is applied to the Cauchy problem for elliptic complexes associated to a complex Monge-Ampere equation in the space of distributions.\n\n## Implicit function theorem and the Cauchy problem for elliptic complexes \n\nLet $\\mathcal{E}$ be a complex of elliptic operators on a smooth manifold $X$. The Cauchy problem for $\\mathcal{E}$ consists in finding a function $u\\in C^\\infty(X)$ such that $u\\restriction_{\\partial X} =f$ and $\\mathcal{E}(u) = 0$ on $X$, where $f$ is a given data on $\\partial X$. If $\\mathcal{E}$ is a complex of pseudodifferential operators, the Cauchy problem has been widely studied using various approaches (see [^1] for instance). In all these cases, the methods rely on the possibility of defining the involved operators as distributions, that is, as linear maps from the space of smooth functions to the space of smooth functions equipped with the $C^\\infty$-topology. However, it is well known that the definition of the involved operators in the distribution space does not always yield a meaningful definition for the elliptic complex $\\mathcal{E}$. Indeed, in general, there is no reason why the differential operator $\\mathcal{E}$ should be continuous as a map from the space of smooth functions to the space of distributions. Therefore, one cannot expect to apply classical methods to solve the Cauchy problem for $\\mathcal{E}$ in the space of distributions.\n\n## An explicit regularizing property and the completeness of initial data \n\nIn this paper, we consider the Cauchy problem for an elliptic complex $\\mathcal{E}$ in the distribution space. We show that the existence and uniqueness of solutions to the Cauchy problem imply the completeness of the corresponding initial data $f$, provided that $f$ is in the range of $\\mathcal{E}$. To prove this result, we use an explicit regularizing property of the elliptic complex $\\mathcal{E}$, which enables us to define a map from the space of smooth functions to itself, that is,",
    " Deep learning segmentation networks for rectal cancer microscopy images often show strong model variance, which hampers generalization performance. We attribute this to the limited amount of training data available, which leads to overfitting. To mitigate this problem, we propose a simple yet effective approach to reduce the model variance of a segmentation network. Our approach consists of training the network with data augmentation on a larger dataset, and then fine-tuning the network on the target dataset with a lower amount of labeled data. We compare our method to other approaches for model variance reduction, such as training on a larger dataset without data augmentation, and model selection using validation performance. Our results show that our method improves the mean Dice similarity coefficient by 5.2% compared to training on the full dataset without data augmentation, and by 3.2% compared to model selection using validation performance. Furthermore, it reduces the maximum Dice coefficient variation among five different runs by 40.7%.",
    " We present a new architecture for robust semantic segmentation based on superpixels derived from a clustering of pixels. Superpixels provide an initial grouping of pixels that captures local structure, such that each superpixel can be treated as a single object. We propose a novel approach to incorporate this prior knowledge of object locations by learning a superpixel convolutional network (SCN) that directly operates on superpixel inputs. Our approach leverages the recently introduced Inception architecture for efficient computation of multi-scale information. We show that Inception features extracted from superpixels provide good performance on semantic segmentation, and we analyze types of information that are missed when going from pixels to superpixels. We then propose a modification of the classical bilateral filter that is applied to the raw pixel data prior to running our SCN. This modification adaptively enhances the information content of each pixel, providing a form of pixel-level attention. We show that this attention mechanism improves performance in semantic segmentation, probably by making our SCN more robust to the loss of information during the superpixel clustering step. Our approach achieves 75.8% mean accuracy on the CamVid dataset, a new record on this dataset, and 79.4% mean accuracy on the Stanford Background dataset.",
    " We introduce a new large dataset of electron microscopy images of synapses, together with a completely automated pipeline for detecting synapses in these images. By avoiding manual labor and multiple choices during the pipeline, the presented dataset provides an objective ground truth, which we use to evaluate dozens of state-of-the-art deep learning models. We find that the best models still fail at detecting synapses in EM images, but with a significant improvement over previous works. Furthermore, we show the possibility of creating new effective models using only a small number of training examples. Finally, we use the winning models to provide a quantitative characterization, for the first time, of the full heterogeneity of synapses in a large brain region, thereby paving the way to a full understanding of the complexity of brain connectivity.",
    " Patterns are ubiquitous in natural language texts, formal languages, and biological sequences. Furthermore, patterns can often be embedded within one another forming hierarchical structures. For example, in a natural language sentence, individual words can form phrases, and phrases can form clauses, etc. Similarly, in genetic sequences, motifs (short patterns) can form larger structures such as genes, which in turn form chromosomes. These hierarchical structures can be represented as nodes in a tree, where each node has potentially multiple parent nodes and multiple child nodes. Such tree structures are referred to as tree patterns.\n\nThis paper addresses the problem of finding tree patterns with avoidance, where avoidance refers to the absence of a pattern from certain nodes in the tree. We formalize the problem as a pattern avoidance problem in a task-precedence poset, and present a general algorithm that takes advantage of the hierarchical structure of trees. The algorithm is based on dynamic programming, and employs a novel, general purpose, bottom-up, disaggregated recurrence, which we term fold-back. This fold-back operator allows us to decompose the avoidance problem into a set of simpler problems, and to solve these problems in a bottom-up manner.\n\nWe implement our algorithm, and run experiments on a standard benchmark. Our experiments show that our algorithm often outperforms the current state of the art in tree pattern avoidance, and is competitive with the best known algorithms for tree pattern matching, thus establishing pattern avoidance in trees as a new and challenging problem.",
    " Recent works have shown that the choice of evaluation metric can impact the performance of a model; however, in most cases, a single metric is used for model training. In many applications, such as natural language understanding, it is difficult to define a single metric that captures the quality of a model's output. Instead, multiple metrics may be used, each capturing different aspects of the model's behavior. Unfortunately, training a model to maximize all metrics simultaneously is an ill-defined problem, as any optimization algorithm needs an objective function for convergence, and having multiple metrics defined only as constraints can be challenging and may result in unsatisfactory solutions. In this work, we propose a framework where a single model is trained to optimize each metric separately, while still learning useful representations that help the model perform well on other metrics as well. We demonstrate the effectiveness of our approach on a variety of tasks, including natural language inference, sentiment analysis, and question answering, showing that our approach finds representations that are shared across different metrics, and outperforms models trained with a single metric.",
    " Semantic image segmentation of urban street scenes is a fundamental step towards intelligent transportation systems. In this paper, we present a real-time high-performance method for semantic image segmentation of urban street scenes. Our method is based on a deep learning architecture called Convolutional Neural Network (CNN). We use a pre-trained CNN model trained on the ImageNet dataset to extract features from the input images. We then fine-tune the CNN model on a new dataset specifically designed for semantic image segmentation of urban street scenes. Our method achieves accurate segmentation results and runs in real-time, making it suitable for applications such as autonomous driving and traffic monitoring.",
    " Recent progresses in MRI acquisition techniques have led to an explosion of big imaging data, posing a tremendous challenge for expert manual segmentation. Meanwhile, compared with the abundant labeled images from different domains, the few-shot segmentation setting, where only a few images of specific domains are available for training, is more practical in real-world applications. In this work, we exploit the intrinsic hierarchical structure of segmenting brain MR images from different domains with a deep heteroscedastic multi-task learning (HMT) framework. Specifically, we design a weighted cross-entropy loss to incorporate the heteroscedastic noise of unlabeled data from different domains in an automatic manner. Furthermore, to effectively utilize the limited labeled data, we propose a knowledge distillation strategy that explicitly trains a thinner student network with the learned knowledge from a thicker teacher network pre-trained on abundant data. When trained on a few-shot setting, our method outperforms the state-of-the-art methods for brain MRI segmentation on multiple public datasets, including ISLES, LLC and ADNI. The code is available at https://github.com/VITA-Group/Few-shot-brain-segmentation.",
    " Recent results on salient object detection take a top-down approach, in which the model first detects the foreground and then refines it to obtain the final salient regions. Most existing works focus on designing effective refinement modules to improve the quality of the predicted saliency maps. In this work, we argue that a key problem of current top-down methods is the quality of the initial foreground map, which is usually obtained by thresholding or clamping the output of an encoder. To address this problem, we propose a classifier-guided approach that refines the initial foreground map with a classifier. Specifically, we train a support vector machine (SVM) classifier with image-level labels to predict whether a pixel is in the foreground or not. Since the classifier is trained with image-level labels, it is able to exploit global information and capture the underlying object-like structures. Extensive experiments on the salient object detection benchmark datasets validate the effectiveness of our approach compared to the state-of-the-art methods.",
    " We characterize simple Leavitt path algebras of arbitrary graphs as the only *-ring factorizations of the Cuntz-Krieger norm into a *-homomorphism and a *-monomorphism. As an application we give a new characterization of the Leavitt path algebras of arbitrary graphs in terms of Baer *-rings. This simplifies and generalizes several recent characterizations.",
    " Current image segmentation techniques are usually designed to segment images of a specific modality, such as natural images or medical images. This restriction originates from the limitation of the training data as most of the deep learning segmentation models are trained on a specific dataset, which is usually limited to images of a single modality. In this paper, we present a new approach for image segmentation that overcomes this limitation. Our model, called HeMIS, is based on a modification of the U-Net architecture that allows it to handle images of different modalities without the need for retraining. We demonstrate the effectiveness of our approach on two different datasets, one for natural images and one for medical images. Our results show that HeMIS achieves state-of-the-art performance on both datasets without the need for any modification to the model.",
    " Abstract:\n    We perform an empirical investigation of the Zipf strategy for short-term investments in WIG20 futures. The strategy is based on the hypothesis that the ranks of the returns of the most valuable components of the WIG20 portfolio have some predictive power for the future returns. In the experimental part we evaluate the performance of the strategy by comparing it with the buy-and-hold strategy and with the strategy of investing in the most valuable component at each moment. We find that the Zipf strategy, despite its simplicity, may provide a significant advantage over the other strategies for short investment horizons, like one day.",
    " Recent works on perceptual parsing mainly focus on specific tasks or specific domains, such as scene parsing, object parsing, or person parsing. These methods often utilize separate deep models to handle different tasks, which may result in low efficiency and redundant computations. In this paper, we present a deep grouping model for unified perceptual parsing (DGMP). DGMP introduces a novel pyramid grouping module (PGM) to effectively group and convey multi-scale contextual information, and a joint parsing and refining network (JPRN) to jointly parse and refine the predicted results. Specifically, PGM can automatically group the interested regions and refine the grouped features within a single network architecture, which achieves multiple grouping behaviors with only one forward pass. Furthermore, our JPRN can not only parse the whole image but also refine the predicted results, which further improves the performance. Compared with state-of-the-art methods, DGMP can achieve better performance with a faster inference speed.",
    " In this paper, we define a monoid of invertibility preserving maps on a set and study its properties. We use this monoid to construct a group of invertibility preserving maps on a set. We apply these results to construct a group of isometries on a vector space and use this group to study the structure of Clifford algebras.",
    " We study the existence of an asymptotic upper bound on the clique-width of graphs in an arbitrary minimal class of graphs defined by a finite set of forbidden induced subgraphs. We show that if the minimal class is recursively enumerable, then it possesses an asymptotic upper bound on the clique-width, but that none of the currently known upper bounds on the clique-width of graphs is maximal for any minimal class. We also show that the family of graphs of bounded clique-width and the family of graphs of unbounded clique-width each have a maximal subclass of recursively enumerable graphs that possesses an asymptotic upper bound on the clique-width, which is not always the case for general classes of graphs.",
    " Recent works have shown that deep learning models can be robustly attacked via adversarial patches. Such patches are typically crafted manually by humans, which limits their scalability and applicability in real-world attack scenarios. In this work, we automate the patch generation process via a genetic algorithm, which searches for the best patch in an image collection. To avoid the need for an initial collection of patches, we propose a data generation process that uses a patched model to generate in-distribution patch candidates. We implement our approach in the iPatch tool, and show that it can successfully find patches achieving high attack success rates and transfer well to models from other architectures. We evaluate iPatch on ImageNet classifier models as well as popular NLP transformer models, and demonstrate the necessity of patch protection for NLP tasks.",
    " We present a simple, yet effective approach to learn a positional contrastive loss suitable for volumetric medical image segmentation. Our loss combines a standard contrastive loss with a positional loss, which models the spatial consistency of the predicted segmentation within a support volume. This allows us to use the popular dilated convolutional neural network architecture for segmentation, while retaining 3D spatial information in the output. We evaluate our method on the ISLES 2020 segmentation challenge and achieve the best performance among all submissions for the lung and kidney segmentation tasks. Code is available at https://github.com/AUTOMATIC1111/Positional-Contrastive-Learning.",
    " We present stellar population models for the disks of 26 nearby S0 galaxies, based on deep, spatially resolved spectroscopy from Hubble Space Telescope Advanced Camera for Surveys observations as part of the SAURON project. We derive the scale lengths of the stellar disks for the S0s, and find them to be uniformly thin, with a characteristic scale length of 4.2  1.4 kiloparsecs. This is similar to the scale length of the Milky Way's stellar disk, but much thinner than the scale lengths typically measured for late-type galaxies. The low dispersion of the scale lengths suggests that the thinning is an evolutionary effect, common to galaxies at the mature stage of their lives. The surface brightness profiles of the stellar disks are well fit by a single exponential profile, except for the central regions, which display a plateau, likely caused by stellar disks whose ages are decreasing inward. The mass density profile (r) of the stellar mass in the galaxies can be fit well by a double exponential profile with a transition radius of about 1.3 disk scale lengths, similar to the transition radius found in the Milky Way. This supports the hypothesis that the stellar mass profiles of S0 galaxies are built up in a similar manner to those of spirals. We determine the orbital velocities and dynamical masses for the S0s, and use these to calculate the projected phase space densities _3 for the galaxies. The majority of the S0s have _31, indicating that these galaxies are not dominated by random motion, as would be expected if most of their stellar mass was contained in a diffuse, dynamically hot halo. However, non-negligible contributions to _3 from the stars in the thin disks, which are dynamically cold, can produce this result. This suggests that the stellar halos of S0s may be much less massive than those of spirals.",
    " Description logic is a widely used formalism for the definition of ontologies. A description logic ontology consists of a set of logical axioms, which define concepts and the relationships between them. These axioms are usually defined in a hierarchical way, with more general concepts being defined first, and more specific concepts being defined in terms of more general ones. This hierarchical structure can be viewed as a tree-like structure, with the most general concepts being the root of the tree, and the more specific concepts being the leaves of the tree.\n\nThe complexity of a description logic ontology is determined by the number of concepts and relationships between them, and the way in which they are defined. A more complex ontology will have more concepts and relationships, and more complex definitions of these concepts and relationships. The complexity of an ontology can also be affected by the structure of the hierarchy of concepts and relationships, as a more complex hierarchy will result in a more complex ontology.\n\nIn this paper, we investigate the data complexity of description logic ontologies, that is, the amount of data that is required to represent an ontology, and the complexity of this data in terms of the number of concepts and relationships, and the way in which they are defined. We show that the data complexity of an ontology is related to the structure of the hierarchy of concepts and relationships, and that a more complex hierarchy will result in a more complex ontology in terms of data complexity. We also show that the data complexity of an ontology can be reduced by using a more efficient representation of the hierarchy of concepts and relationships, such as a nested set representation.",
    " Recent progress in deep learning has advanced referring expression comprehension, i.e., the understanding of sparse referring expressions that refer to objects or regions in images or videos, from image regions identification to pixel-wise segmentation. However, existing works mainly focus on 2D referring expression comprehension disregarding the inherent 3D structure of the real world. In this paper, we present a comprehensive multi-modal framework to tackle referring image segmentation, which takes advantages of both referring expressions and geometric constraints, to achieve referring expression comprehension with 3D awareness. Specifically, we first devise a new geometric constraint that leverages the 3D scene structure to obtain initial segmentations. Then, we formulate referring expression comprehension as a maximum a posteriori estimation problem that integrates the referring expression predictions and the geometric constraint. Furthermore, we explore a progressive refinement approach to iteratively refine the segmentation results. We validate the effectiveness of our method on the ReferItSeg dataset, which is a large-scale dataset for referring image segmentation, and achieve state-of-the-art performance.",
    " In this paper, we present CardiacNET, a deep learning framework for the segmentation of the left atrium and proximal pulmonary veins in MRI. Our approach employs a multi-view convolutional neural network (CNN) that utilizes the multiple contrasts and views available in MRI scans for the segmentation task. The multi-view CNN takes advantage of the rich information embedded in the different views and contrasts to improve the segmentation performance. We evaluated our approach on 100 MRI scans and compared it to manual segmentation performed by experts, as well as other state-of-the-art methods. Our results show that CardiacNET achieves an accuracy of 92.3% on the segmentation of the left atrium and 96.2% on the segmentation of the pulmonary veins. When compared to manual segmentation, our approach reduces the error rate by 57.7% for the left atrium and 50.6% for the pulmonary veins.\n\nOur code and dataset are available at: https://github.com/Cardiac-NET/Cardiac-NET.\n\nKeywords: cardiac MRI, deep learning, convolutional neural network, multi-view learning, segmentation.",
    " We introduce a new weakly-supervised segmentation framework that leverages geodesic inter-extreme points (GEIX) for object instance segmentation. Our approach extends the traditional geodesic ellipsoids to a new class of shapes that capture the relationships among multiple objects. This is achieved by optimizing over the manifold of the geometric shapes, referred to as geodesic inter-extreme variations, where the optimization objective is driven by the geometric properties and the label correlations among the objects. We show that the resulting optimization is efficiently solved as a linear programming (LP) problem on certain parametrization of the geodesic inter-extreme variations. In addition, to effectively solve the LP problem, we propose an algorithm that iteratively updates the shapes by performing a series of convex optimizations. We evaluate our approach on the cityscapes dataset, where our method outperforms the state-of-the-art approaches that rely on geodesics.",
    " We show upper bounds on the quantifier depth of graph differentiation, that is, of the problem of expressing in first-order logic the fact that the gradient of a real-valued function defined on a graph is zero at a given point, in terms of the classical quantifier depth of the involved relations. Our results confirm a conjecture ofSERENASIERRA.",
    "The paper discusses the feasibility of using thermal scanning probe lithography for sub-20 nm patterning on silicon and metal lift-off. The study found that thermal scanning probe lithography can be used to create sub-20 nm patterns on silicon and metal, with a resolution of up to 10 nm. The process is compatible with a variety of metals, including gold, silver, and aluminum, and can be used for both positive and negative tone resists. The paper also discusses the potential applications of this technology in the field of nanoscale electronics and sensors. It was found that the thermal scanning probe lithography process has several advantages over traditional photolithography, including the ability to create patterns with a high aspect ratio and the ability to pattern non-planar surfaces. Additionally, the process is compatible with a variety of materials, including silicon, silicon dioxide, and various metals. The paper concludes by discussing the potential of thermal scanning probe lithography as a viable alternative to traditional photolithography for sub-20 nm patterning and metal lift-off.",
    "The abstract for the academic paper titled \"Fast-SCNN: Fast Semantic Segmentation Network\" should include:\n\nFast-SCNN is a novel framework for semantic segmentation, which is a process of assigning a semantic label to each pixel in an input image. It is designed to be fast, accurate, and flexible, and it achieves this by combining a convolutional neural network (CNN) with a self-supervised learning (SSL) approach. The CNN is used to extract features from the input image, and the SSL approach is used to learn a mapping from the extracted features to the semantic labels.\n\nThe Fast-SCNN framework is based on the idea that the semantic segmentation task can be divided into two separate problems: (1) feature extraction, and (2) label mapping. The CNN is used to extract features from the input image, and the SSL approach is used to learn a mapping from the extracted features to the semantic labels. The CNN is designed to be fast, and it is based on a modified version of the VGG16 architecture. The SSL approach is based on a distance-weighted loss function, which is designed to be more robust to noise and outliers in the training data.\n\nThe Fast-SCNN framework was evaluated on the Pascal VOC 2012 semantic segmentation benchmark, and it achieved a mIoU (Intersection over Union) of 62.2% on the test set, which is a new state-of-the-art record. The framework was also evaluated on the Cityscapes dataset, and it achieved a mIoU of 80.3% on the test set.",
    "Abstract:\nTraditional image filtering methods operate directly on the pixel domain, making them sensitive to noise and details at multiple scales. Scale-space filtering is a framework that is less sensitive to scale-dependent features and noise. In this paper, we propose a flexible framework for scale-space filtering, called Hierarchical Image Peeling (HIP), which adapts to the image structure at multiple scales. HIP uses a top-down approach where it first identifies the regions of interest in an image (using a segmentation mask) and then recursively peels the image from these regions. We demonstrate the effectiveness of our method on smoothing and edge-preserving filters, showing improvements over state-of-the-art scale-space methods.\n\nWould you like to know more about this paper?",
    "Here is the abstract for the academic paper titled \"Fully Automatic Myocardial Segmentation of Contrast Echocardiography Sequence Using Random Forests Guided by Shape Model\":\n\nAbstract: We present a fully-automatic method for the segmentation of the left ventricular myocardium in contrast echocardiography sequences (ces). The method is based on random forests (rf) guided by a shape model. The shape model is built from manually segmented ces frames and describes the left ventricle geometry as a deformable model. The random forests classify the pixels of each frame into myocardial and background voxels. The segmentation of each frame is obtained by deforming the shape model to fit the rf classification. The method was evaluated on a database of 25 ces frames (125 slices). For comparison, we also evaluated a method based on a classic active contour without shape model. The results show that the proposed method gives more accurate and robust segmentation.",
    "Abstract\nWe propose a new enhancement technique for the segmentation of nuclei images obtained from 2D-cellular images. The main characteristic of our approach is the use of an enhancement neighborhood (EN) connected segmentation, based on the watershed transform, to obtain the final segmentation. Our proposed method is evaluated using five different datasets, and the results show that our method achieves a better performance compared to the watershed transform global segmentation and also compared to state-of-the-art methods. The evaluation is performed using five evaluation metrics, and the results show that our proposed method achieves better results in all cases.",
    "An abstract is a summary of a academic paper.\nAbstract:\nTo render realistic images, computer graphics algorithms must be able to distinguish and render a variety of materials. Although deep learning has achieved remarkable results in image-based material recognition, current datasets have limited size and diversity, containing only a small number of materials and lacking fine-grained annotations. We overcome these limitations by introducing a large-scale 4D light-field material recognition dataset with 1,826 fine-grained material labels and 25,326 images captured under diverse viewpoints, lighting conditions, and occlusions. We design a new deep neural network (DNN) architecture, FedNet, that directly utilizes the 4D light-field data for material recognition. Given a 4D light-field input, FedNet separately predicts material labels for each microlens image and merges the predictions to generate the final output. In addition, we propose a new 3D feature pooling strategy that effectively utilizes the spatial information in the 4D light-field input. Experiments show that FedNet achieves an accuracy of 89.4% on the fine-grained material recognition task, outperforming previous methods. Our dataset and code are publicly available at https://github.com/Material-Net/LightField-Material-Recognition.",
    "Abstract. \nThe field of semantic segmentation has progressed rapidly in recent years, with a focus on accurate pixel-level classification. However, the ability to diagnose and evaluate performance remains a challenging task. This paper discusses the current state of diagnostics in semantic segmentation and proposes several new metrics for evaluating performance. These metrics capture a more comprehensive understanding of model behavior and facilitate the development of more effective algorithms. Through careful analysis of model errors and extensive experiments on public datasets, we demonstrate the limitations of current evaluation practices and the potential of the proposed diagnostics. The proposed diagnostics promote a holistic understanding of model behavior, guide the design of more effective algorithms, and are easily adaptable to new datasets and models.",
    "Abstract:\nDomain adaptation has gained increasing attention in recent years, where the goal is to adapt a model trained on one domain to perform well on a target domain. However, most existing methods focus on the scenario where the target domain has only one data source, which may limit their applicability in real-world scenarios where multiple data sources are available for the target domain. In this paper, we address the multi-source domain adaptation under target shift, where the target domain consists of multiple data sources, and a distribution shift exists between the shared source domain and each target source. We propose a new framework for multi-source domain adaptation under target shift based on optimal transport, which enables the domain adaptation of each target source to learn from both the shared source domain and other target sources. Our framework can effectively capture the distribution discrepancies among all domains and mitigate the target shift problem. We conduct extensive experiments on three benchmark datasets for image classification, and the results demonstrate the effectiveness of the proposed method compared to the state-of-the-art approaches.",
    "Here is an abstract for the academic paper \"Anatomy of Domain Shift Impact on U-Net Layers in MRI Segmentation\":\n\nDomain shift, caused by variations in the statistical distribution of training and test datasets in medical imaging, is known to significantly degrade the performance of deep learning models. In this paper, we investigate the impact of domain shift on different layers of the U-Net architecture during MRI segmentation tasks. Our results show that the last few layers of the U-Net are more susceptible to domain shift, and we propose several strategies to mitigate this issue. We evaluate the proposed methods on a public MRI segmentation dataset and show that our approaches can significantly improve the performance of the U-Net in the presence of domain shift.",
    "The flux approximation is a classic and very effective computational method for studying shocks and contact surfaces in ideal, non-relativistic gas dynamics. In a previous investigation, we have developed a version of the flux approximation method, delta-shocks and vacuums, that can be applied in situations, such as zero pressure, where the classical formulation of the flux approximation fails. In this paper we derive the delta-shock and vacuum formulation in a manner that is suitable for general, non-equilibrium, solutions. We then demonstrate the accuracy and robustness of the method by applying it to a number of problems in zero pressure gas dynamics, both one and two dimensional.",
    "Semantic image segmentation, namely pixel-wise labeling, has many applications in our daily life, including object extraction, image understanding, and even medical imaging. In this paper, we investigate the use of deep convolutional neural network along with fully connected conditional random fields for accurate segmentation. We propose to aggregate class conditional scores from multi-scale segmentation models for final segmentation. Furthermore, a new objective function is proposed to optimize the segmentation performance. Finally, we show that our proposed method achieves state-of-the-art performance on the VOC2012 dataset with promising results.",
    "Deep learning methods have been increasingly employed for medical image processing tasks, such as image segmentation, classification, and registration. However, developing deep learning models for medical images poses several unique challenges, including the limited amount of training data, the need for robust models that can handle artifacts and noise, and the requirement for accurate and precise segmentation. In this paper, we provide an overview of the current state of deep learning for medical image processing, including a discussion of the most common applications and the challenges associated with them. We also discuss the potential future directions of this rapidly evolving field.",
    "An improved complexity result for the Scaled Gradient Method (SGM) is presented, applicable to nonconvex problems with simple saddle points. When a thresholding technique is applied to a recently proposed Schatten 1-norm, the resulting method, termed Schatten 1-norm Method (SNMP), achieves linear convergence. However, in certain situations, finding the Schatten 1-norm is computationally expensive, and this cost cannot be ignored, especially when the problem dimension is large. In this work, we propose an alternative to the Schatten 1-norm, based on Chebyshev polynomials, that is computationally efficient and attains linear convergence for a fairly broad class of nonconvex problems. The proposed method is numerically compared to other state-of-the-art first-order methods on both a convex and a concave quadratic model problem and a nonconvex stochastic approximation problem.",
    "This paper focuses on the generalized U(N) gauge transformations within the framework of the extended covariant Hamilton formalism of field theory. The generalized U(N) gauge transformations are shown to be inherently connected to the extended covariant Hamilton formalism, providing a deeper understanding of their role in the broader context of field theory. The paper presents a comprehensive analysis of the relationship between the generalized U(N) gauge transformations and the extended covariant Hamiltonian, highlighting the significance of the latter in shaping the former. By utilizing the extended covariant Hamilton formalism, the paper demonstrates the ability to generate generalized U(N) gauge transformations non-empirically, shedding light on the underlying principles and structure of field theory.",
    "The photoelectric effect is a phenomenon in which electrons are released from a material when it is exposed to light or other forms of electromagnetic radiation. In this paper, we present a theoretical analysis of the photoelectric effect induced by blackbody radiation, which is a type of thermal radiation emitted by objects at a temperature greater than absolute zero.\n\nWe begin by reviewing the basic principles of the photoelectric effect and blackbody radiation, including the concept of work function and the Planck distribution. We then discuss the potential for using blackbody radiation as a heat energy harvesting mechanism, considering factors such as the temperature and emissivity of the object, as well as the properties of the material from which the electrons are released.\n\nNext, we analyze the factors that affect the efficiency of this potential energy harvesting mechanism. We consider the optimal range of parameters, such as the temperature and emissivity of the object, as well as the properties of the material from which the electrons are released. We also discuss the limitations of this approach and explore alternative methods for harvesting heat energy, such as thermoelectric generation.\n\nFinally, we conclude by summarizing our findings and highlighting the potential for using the photoelectric effect induced by blackbody radiation as a heat energy harvesting mechanism. We also emphasize the need for further research and development in this area, particularly in terms of materials science and engineering, in order to fully realize this potential. Overall, this paper provides a comprehensive theoretical analysis of a novel approach to heat energy harvesting, with the potential to improve the efficiency and effectiveness of energy conversion processes.",
    "Few-shot segmentation is a challenging problem in which the goal is to segment new classes given only a few training examples. In this paper, we propose a self-guided learning approach that utilizes a reference image to adapt a pre-trained segmentation model to new classes. We further propose a cross-guided learning approach that utilizes a collection of reference images from multiple classes to adapt the model. Our approaches are based on a novel adaptation module that can be easily integrated into existing segmentation models. We demonstrate the effectiveness of our approaches on the VOC2012 and Cityscapes segmentation datasets, where we achieve state-of-the-art performance. Our code and models are available at this https URL.",
    "Abstract:\nPersonalized image semantic segmentation is a technique that combines the power of machine learning and computer vision to enable automated understanding of images. This paper discusses the challenges and opportunities that arise when applying this technique to large datasets, and presents a novel approach to address these issues. We propose a two-stage method that first identifies the most relevant features for a given image, and then uses these features to perform semantic segmentation. Our approach is designed to work with datasets that may contain millions of images, and can be used to segment images into multiple classes. We evaluate our method on the Cityscapes dataset, and show that it achieves state-of-the-art performance in terms of both accuracy and speed.",
    "The abstract for the academic paper titled \"High-Order Adaptive Gegenbauer Integral Spectral Element Method for Solving Nonlinear Optimal Control Problems\" would be:\n\nThis paper presents a high-order adaptive Gegenbauer integral spectral element method for solving nonlinear optimal control problems. The method is based on the Gegenbauer polynomial basis, which is a high-order approximation of the solution space. The spectral element method is an efficient and accurate discretization technique for solving optimal control problems. The method is adaptive, allowing for the efficient solution of problems with complex geometry and topography. The paper presents a comprehensive theoretical analysis of the method and demonstrates its accuracy and efficiency through a series of numerical examples. The examples include problems with complex geometry and topography, as well as problems with multiple objectives and constraints. The paper concludes by discussing the potential of the method for solving a wide range of optimal control problems.",
    "The work presented in this paper explores the phenomenon of alpha channeling with the high-field launch of lower hybrid waves. The objective of this work is to study the effects of alpha channeling on the properties and behavior of lower hybrid waves in plasma. This is important because understanding the effects of alpha channeling can help us develop more efficient and effective methods for the launch of lower hybrid waves, which have applications in fusion energy research and plasma processing.\n\nThe paper discusses the experimental and theoretical methods used to study the effects of alpha channeling on lower hybrid waves. The experimental results show that alpha channeling can have a significant impact on the properties and behavior of lower hybrid waves. The theoretical model was able to accurately predict the effects of alpha channeling on lower hybrid waves.\n\nThe work presented in this paper has important implications for fusion energy research and plasma processing. By understanding the effects of alpha channeling on lower hybrid waves, we can develop more efficient and effective methods for the launch of lower hybrid waves. This can help us to better control and manipulate plasma, which has applications in fusion energy research and plasma processing.",
    "An important practical limitation of quantum dot (QD) based single-photon sources (SPSs) is the low efficiency of photon collection from the nanocrystal (NC) hosting the QD. Here, we demonstrate that a high index tapered nanowire (TNW) can provide a high efficiency (up to 99%) passive mode-matching of the nanocrystal emission to the mode of the optical fiber, which is a promising approach for efficient photon collection in quantum optics and quantum information applications. We experimentally demonstrate a broadband quantum efficiency enhancement in high index TiO2 TNW resonators for efficient photon collection, which are promising for a variety of applications in quantum optics and quantum information, including linear and non-linear optics, quantum memories, and quantum repeaters.",
    "Computing first extensions of modules is an important problem in the theory of graded Hecke algebras. In this paper, we study this problem for a class of graded Hecke algebras that includes the algebras of type A, type B_r, and type C_r. We present a method for computing first extensions in these algebras, based on the notion of a graded division algebra with radical square zero. This method is then applied to compute first extensions between modules of the algebras of type A and type B_r.",
    "The segmentation of the left atrium (LA) in cardiac magnetic resonance images (CMRIs) is a fundamental step in the analysis of atrial fibrillation (AF). We propose a new method for LA segmentation in CMRI based on a mixture model (MM) global shape prior and an autoencoder (AE) local intensity prior. The MM is used to model the global shape of the LA, while the AE is used to learn a low-dimensional representation of the local intensity patterns within the LA. The MM and AE are trained on a large dataset of annotated CMRI scans and are used to segment new, unseen CMRI scans. We evaluate our method on a separate test dataset and compare it to state-of-the-art segmentation methods. Our results show that our method achieves competitive performance compared to other methods while requiring less training data. Furthermore, our method is able to generalize well to unseen data, demonstrating the effectiveness of the MM and AE in capturing global and local intensity patterns, respectively.",
    "Abstract:\nTraining conditional random fields (CRFs) on large datasets remains a challenging task due to the computational complexity of the dense chain CRF algorithm. We present a novel method for closed-form training of CRFs on large scale image segmentation datasets, based on low-rank factorization of the chain matrix. Our approach provides a significant speedup over the standard algorithm, while maintaining accurate segmentation results. We demonstrate the effectiveness of our method on the Cityscapes and Coco segments datasets, achieving state-of-the-art performance in terms of both speed and accuracy. Our code and models are publicly available at this https URL.",
    "Here is the 250-word abstract for \"Modern Convex Optimization to Medical Image Analysis\":\n\nThe field of medical image analysis has recently seen significant advancements due to the development of modern convex optimization techniques. These advancements have improved the accuracy and efficiency of various image analysis tasks, such as image segmentation, registration, and classification.\nThis paper provides a comprehensive review of modern convex optimization techniques in medical image analysis. It begins by introducing the basic concepts of convex optimization, including the formulation of convex optimization problems and the introduction of convex optimization algorithms. The paper then discusses the application of convex optimization to medical image analysis, including the use of convex optimization for image segmentation, registration, and classification tasks.\nThe paper concludes by discussing the future direction of convex optimization in medical image analysis. It highlights the potential of convex optimization to improve the accuracy and efficiency of various image analysis tasks, and suggests that further research in this area is necessary.\nOverall, this paper provides a comprehensive review of modern convex optimization techniques in medical image analysis and highlights the potential of convex optimization to improve the accuracy and efficiency of various image analysis tasks.",
    "Here is an abstract for the academic paper titled \"Review of multi-fidelity models\":\n\nThis paper provides a comprehensive review of the literature on multi-fidelity models, a powerful tool for decision-making under uncertainty. The paper begins by introducing the concept of multi-fidelity models and their advantages over traditional single-fidelity models. It then reviews the different types of multi-fidelity models and their applications in various fields. The paper also discusses the challenges and limitations of multi-fidelity models and provides recommendations for future research. The review concludes by highlighting the potential of multi-fidelity models to improve decision-making under uncertainty and their importance in various fields.",
    "Abstract:\nTraditional machine learning models are susceptible to model variance, especially when dealing with small datasets. We present a novel method to reduce the model variance of a rectal cancer segmentation network using an ensemble of models. Our approach combines multiple models, each trained on a different subset of the data, to create a more robust and accurate segmentation network. Compared to a single model, our ensemble approach reduces the model variance by up to 20% and improves the F1-score by up to 2%. Furthermore, we present a novel data augmentation technique that helps to reduce the model variance by creating additional training samples from existing data. Our approach has the potential to improve the performance of machine learning models in a variety of medical imaging tasks where data is limited.",
    "Abstract:\nThe Tversky loss function is a generalization of the popular cross-entropy loss function that is used for image segmentation using 3D fully convolutional deep networks. The Tversky loss function incorporates the uncertainty of the model in addition to the cross-entropy loss function, which improves the model's performance in segmenting images with noisy or ambiguous boundaries. We evaluate the Tversky loss function on the Cityscapes and KITTI datasets, and show that it improves the model's performance on both datasets compared to the cross-entropy loss function. We also show that the Tversky loss function is more effective at segmenting images with noisy or ambiguous boundaries than the cross-entropy loss function.\n\nMgcommons.com:\nA novel image segmentation approach using 3D fully convolutional deep networks and the Tversky loss function is proposed. In order to improve the performance of the model in segmenting images with noisy or ambiguous boundaries, the Tversky loss function is used to incorporate the uncertainty of the model. The proposed method showed improved performance over the cross-entropy loss function on the Cityscapes and KITTI datasets. The Tversky loss function proved to be more effective in segmenting images with noisy or ambiguous boundaries in comparison to the cross-entropy loss function. The experimental results show that the proposed method can effectively segment images and improve the model's performance in noisy or ambiguous boundary conditions.",
    "Here is the abstract for the academic paper titled \"Tractable Lineages on Treelike Instances: Limits and Extensions\":\n\nThis paper presents a comprehensive study of the tractability of lineages on treelike instances. We investigate the computational complexity of several fundamental operations on lineages, including lineage reconstruction, descendant-based search, and ancestor-based search. We show that these operations are tractable under certain conditions, such as when the lineage length is bounded or when the instance is sparse. We also present extensions of these operations to handle more complex scenarios, such as when the instance is dynamic or when the lineage is only partially known. Our results provide new insights into the tractability of lineages on treelike instances and lay the foundation for future research in this area.",
    "Here is an abstract for the academic paper titled \"Minimalist design of a robust real-time quantum random number generator\":\n\nAbstract:\nWe present a design for a real-time quantum random number generator (QRNG) with a minimalist design philosophy. The QRNG is designed to be robust, compact, and cost-effective, making it suitable for integration into a wide range of applications. The generator utilizes a quantum optical source, such as a laser, to generate random numbers by measuring the intensity of the light. The generated random numbers are then processed and output in real-time. The design is optimized for minimal size, weight, and power consumption, making it ideal for use in portable and embedded systems. The QRNG is also designed to be robust against environmental noise and interference, ensuring reliable and consistent performance.\n\nThe proposed QRNG has several potential applications, including cryptography, secure communication, and random number generation in scientific simulations. The QRNG is designed to be cost-effective, making it accessible to a wide range of users and applications.\n\nWe believe that the proposed QRNG design is a promising solution for real-time random number generation, offering a combination of minimal size, weight, power consumption, and cost, while maintaining robustness and reliability.",
    "Abstract:\nImage segmentation is a fundamental task in medical imaging and has been actively researched for decades. In recent years, deep learning models have shown promising results in image segmentation. However, a significant number of medical images available in the real world are labeled partially or not at all. These images are called semi-supervised or unsupervised images, respectively. Meanwhile, some images can be in multiple modalities, such as computed tomography (CT) and magnetic resonance imaging (MRI). Therefore, the image segmentation task should be performed under the semi-supervised and multimodal settings. In this paper, we propose a novel approach for image segmentation under the semi-supervised and multimodal settings. We disentangle the foreground and background of the image using a U-Net-based encoder-decoder architecture. Then, we align the features of different modalities using a shared encoder and fuse them into a single vector using a weights-learned fusion strategy. Finally, we segment the image by classifying the fused features using a conditional random field (CRF) classifier. We evaluate our approach on the BRATS dataset, which is a commonly used dataset for brain tumor segmentation. The experimental results show that our approach achieves competitive performance compared to the state-of-the-art approaches on the BRATS dataset.",
    "Abstract:\nLet $(X_i)_{i\\in {\\mathbb Z}}$ be independent and identically distributed random variables in $\\mathbb R$, with values in a probability group $(\\Omega,\\mathcal F,\\mathbb P)$. We consider their mixing properties and relation to the central limit theorem. In particular, we study the double recurrence of $X_0$ and show that it implies the convergence of the characteristic function of $X_0$ towards the characteristic function of a complex Gaussian distribution. Some applications of this result in the context of spatial statistics are given.",
    "An interactive object segmentation system aims to provide precise segmentation results for specific objects of interest in a natural image or video, regardless of whether the objects are known a priori or not. In this paper, we present an approach for interactive video object segmentation that operates on raw video data in the wild without requiring any a priori information. We exploit the temporal coherence in video to obtain robust and precise object segmentation results even in the presence of heavy occlusion, similar appearance, and complicated background. In our approach, the user interaction is limited to a minimal annotation of object regions at a few key frames, and the object regions are propagated through the video using a learned propagation model. The propagation model is trained to recognize the underlying structure of the video using a sparse set of object segmentations that are obtained by an initial run of our system. Our approach is capable of accurately segmenting objects of interest in an interactive manner, and is efficient in terms of computational performance and the required user effort. We demonstrate the effectiveness of our approach on a wide variety of videos including those with challenging scenes and complex objects.",
    "Abstract:\nSource-free domain adaptation is a challenging problem in image segmentation, as it involves training a model to segment images from a target domain without having access to any labeled source data. In this paper, we propose a novel approach to address this problem by using a cycle-consistent generative adversarial network (Cycle-GAN) to learn a mapping between the source and target domains. Our approach allows us to train a segmentation model on source data and then adapt it to the target domain without needing any labeled target data. We demonstrate the effectiveness of our approach on three different domain adaptation scenarios, and show that our method outperforms the state-of-the-art in terms of segmentation accuracy.",
    "Abstract:\nWith the widespread use of online social networking platforms, the study of the underlying social graphs has gained significant importance. This paper specifically focuses on Twitter, one of the most popular social media platforms today, and empirically analyzes the evolution of its social graph. By employing graph theory, we aim to explore the inherent properties and dynamics of the Twitter social graph, including its connectivity, centrality, and community structure. Our experimental study involves collecting a substantial dataset of Twitter user interactions and applying various graph algorithms and measures. We find that the Twitter social graph exhibits distinct characteristics, such as high clustering and power-law degree distribution, indicating the presence of communities and influencers. Moreover, our analysis reveals that the graph exhibits evolving properties over time, indicating the dynamic nature of user interactions and the platform's evolution. Overall, this study contributes to a better understanding of the Twitter social graph, which can aid in the development of more effective algorithms and applications for social network analysis and visualization.",
    "Medical image segmentation is prone to label corruption since the training and test domains differ. We propose a simple yet effective solution to address this domain shift issue via a cross-denoising network (CDN). Given a medical image, our proposed CDN estimates a clean label for each pixel and refines it through a denoising branch to reduce noise. To mitigate the domain shift issue, we propose a simple yet effective domain adaptation (DA) layer that aligns the distributions of source and target domains. Specifically, we estimate the source domain with only clean training labels and the target domain with only noisy labels. We then align the feature distributions of the source and target domains via maximum mean discrepancy (MMD) and minimize the distance between them via domain adaptation. Experiments on three public medical image segmentation datasets with noisy labels (e.g., due to annotation errors or low-quality images) demonstrate the effectiveness of the proposed approach against various types of noise. In particular, compared to the state-of-the-art methods, our approach achieves 9.92%, 6.73%, and 11.45% relative improvements in segmentation accuracy.",
    "Quantum causal models are models where the causal structure of the theory is described directly by the quantum state. This paper addresses two aspects of quantum causal models. The first is constructive: we give a general method of constructing causal models starting from a given prepolymer, extending previous work. The second aspect is concerned with the question of faithfulness. We prove a strong form of faithfulness, which to our knowledge has not been previously asserted nor even suggested in the literature: that any causal model which assigns probability 1 to a given outcome must be faithfully modelled by some quantum state. We also show that this implies, in a models-independent way, that non-faithful causal models can only assign probability 0 or 1 to an outcome, strengthening a previous result of Henson. We end with a discussion of the relationship between our work and the longstanding question of whether quantum mechanics allows for backward causation or retrocausality.",
    "Ballast degradation evaluation using image processing technique has gained attention in the recent past. This paper presents the Matlab implementation of a machine vision algorithm to conduct ballast degradation evaluation. The algorithm utilizes the Color Channel Combination (CCC) method to enhance the degradation level of ballast particles. The system was tested on a database of ballast images and the results were compared with the conventional manual method of degradation evaluation. The results showed that the machine vision algorithm can identify the degradation level of ballast particles with an accuracy of 92%. The algorithm can be used as a tool to assist railway engineers in conducting ballast degradation evaluation and optimizing ballast maintenance strategies.\n\nThe Matlab implementation of the machine vision algorithm for ballast degradation evaluation can be useful for railway engineers to assess the condition of ballast and optimize maintenance strategies. The algorithm can accurately identify the degree of degradation in ballast particles, providing valuable information for making informed decisions on ballast management. This technology can be applied in the field to analyze ballast images and assess the condition of the ballast in real-time, helping to maintain the integrity and performance of the railway system.",
    "Advocacy learning has demonstrated strong promise for many domains and we are rapidly becoming accustomed to applying this approach. However, few datasets have been studied experimentally with adversarial training such as the MNIST handwritten digit recognition task, which includes more than 500 million trials over almost two decades. Here, we propose an approach that allows generating ad-hoc networks through supervised, unconstrained sampling, enabling robust training even on data not suitable or appropriate for other methods. As in previous approaches (e.g., refs. 2527), our framework is based upon factorisation of the latent representations of discrete classes into more interpretable clusters by reducing their inter-class similarity; however, by adopting an extra layer between these hidden states, our generative model can represent high dimensional features efficiently without being trained in advance.\n\nThese ideas also appear in Nils Brauer's work, The Design (or Lack thereof) Of Learning From Imperfect Data; A Perspective On Support Vector Machines With Generalization Problems, but they're more developed here, with some really neat implementation examples at the end. You'll notice I omitted several things, like \"training a discriminator via convolutional nets with nonlinearities\" and various notions of \"learning\"; I decided to keep everything small and tidy enough to reproduce the code.\n\nHere's how you install dependencies\n\n$ pip download https://pypi.python.org/packages/source/SVN/convnet_tools.py $ pip install libavutil/pipfileinfo\n\nand start up the network:",
    "We present a new algorithm, MUSIC (MUSIC-based estimation), which can be used to estimate the probability that a given music file will be played by a human listener. The algorithm uses a novel approach to estimating the probability of a particular piece of music being played by a human listener. We show how this method can be applied to many different types of data and we demonstrate its performance on several real world datasets. Our results indicate that MUSIC outperforms other methods in terms of accuracy and speed.",
    "We present a new method of visualizing semantic relationships between visual features and language in scenes using semantic segmentation. Our system's high degree of generativity makes it a suitable candidate for visualizing complex relationships in a generative picture language.\n\nOur work is based primarily on the theory of visualizing the semantic relationships between features in scenes, inspired by the ideas in Bchner et al.'s Theories of Semantic Visualization thesis [1]. We consider the problem of visualizing semantic relationships between two visual features, such as an object and an object feature respectively. This approach is inspired by visualizing the semantic relationships between visual features in the natural world (see this paper for further details) when considering the relationships of two complex, spatially distributed sequences of features. In particular, we consider the problem of visualizing a semantic relationship between, for example, a location and a location feature (here, the features at two locations on the scene).\n\nFor example, consider two examples:\n\nA scene in which there are, in addition to the location feature, six features corresponding to motion direction.\n\nA non-artistic scene in which there are, in addition to the location feature, three features corresponding to time of day.\n\nWe are presented with a way to visualize relationships between these two situations with respect to the feature sequence of the non-artistic scene. For the purposes of illustration we are only interested in the question of whether there is a spatial relationship in the visual features of the two scenes.\n\nWe present general techniques we use to solve this problem, which in the future may be used effectively to perform similar tasks on scenes from diverse genres, different disciplines, and with different features, in different domains.\n\nOur results show that our method does produce a well-organized graph where the semantic relationships within a given image sequence is well preserved across different scenes. Moreover, our results show that the semantics of an image sequence can be visualized through a visual representation of its semantic relationships. This visualization technique provides a means for the visualization of semantic relationships between a visual feature in a scene. When visualized, the semantic relationships can be compared visually to visual features from different, different domains, such as music visualizations, or even a 3D scene rendered from various types of data.\n\nThe Semantic",
    "Abstract:\nThe holographic principle of QCD is a fundamental principle of quantum mechanics. It states that the wave function of a quantum system is a function of the state of the system, and that the wave function is a function of the state of the system. The holographic principle is also known as the \"quantum holographic principle\" or \"quantum holography\". The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is also known as the \"quantum holographic principle\" or \"quantum holography\". The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and it is the basis of the quantum holographic principle of QCD. The holographic principle is a fundamental principle of quantum mechanics, and",
    "Abstract\nThe brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional networks are the basic building blocks of cognition. The brain's functional",
    "We present an algorithm that can be used to derive the C-W equivalence between two sets of points, given their coordinates and distances. The algorithm is based on the fact that the distance between any pair of points in Euclidean space is equal to the sum of the squares of the distances between them. We show that this result holds even if we assume that the set of points has no boundary. This implies that the C-W equivalence is equivalent to the Euclidean equivalence. In particular, it follows that the C-W equivalence is equivalent to the Euclidean equivalence when the distance between two points is less than or equal to the square root of 2.",
    "Our paper deals with the problems that arise when you have to write the equation in algebraic notation. The obvious solution to the equation is to use an approximate interpolation, but those methods can be computationally expensive, if not prohibitively so for small data sets. There's also another problem, which is much more prevalent: You have to rewrite it every time. This is called 'chebyverification', and while it isn't as common as other problems of this nature (e.g., rewriting every time using brute force), it can still be disastrous. To see why it happens so frequently (and worse than before by over 5X), we will present some examples, show how they arise naturally with various analytic choices, and illustrate where optimization strategies might be developed to avoid them. Finally, we do briefly outline the current state-of-the-art on the subject.\n\n\nTo read the entire study, go here :",
    "Non-Measurable Unions in the Presence of Arbitrary Nonlinearity\n\nIn this work, we study the effect of arbitrary nonlinearity on the behavior of non-measurable unions. We show that if one has an arbitrary nonlinearity, then the union of two sets of elements can be described by a linear combination of these sets. This means that the union of two sets of elements can be described as a sum of linear combinations of their components. In other words, the union of two sets of elements can be described as a linear combination of their component sums. The existence of such a linear combination implies that there exists a set of all possible linear combinations of the union of two sets of elements. If one has an arbitrary nonlinearity, then it follows that the union of two sets of elements cannot be described by any linear combination of its components. Thus, the union of two sets of elements cannot be described as a linear combination of their component sums.\n\nWe prove that the above statement holds even when the union of two sets of elements is not commutative and that the above statement holds even when the union of two sets of elements is not associative.\n\nThis work was done with the help of the following resources:",
    "\"We present a novel approach to the detection of hidden structures in amorphous materials and complex physical systems. We propose a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in complex physical systems. We propose a novel method for the detection of hidden structures in complex physical systems by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in complex physical systems. We propose a novel method for the detection of hidden structures in complex physical systems by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in complex physical systems. We propose a novel method for the detection of hidden structures in complex physical systems by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in complex physical systems. We propose a novel method for the detection of hidden structures in complex physical systems by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in complex physical systems. We propose a novel method for the detection of hidden structures in complex physical systems by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in complex physical systems. We propose a novel method for the detection of hidden structures in complex physical systems by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in amorphous materials by using a novel method for the detection of hidden structures in complex physical systems. We propose a novel method for the detection of hidden structures in complex physical systems by using a novel method for",
    "The multi-fan algebras (MFA) are a family of algebraic structures that are based on the idea of a finite-dimensional vector space. The MFA is a special case of the general algebraic structure of a finite-dimensional vector space, which is a special case of the general algebraic structure of a finite-dimensional vector space. The MFA is a special case of the general algebraic structure of a finite-dimensional vector space because it is a special case of the general algebraic structure of a finite-dimensional vector space. The MFA is a special case of the general algebraic structure of a finite-dimensional vector space because it is a special case of the general algebraic structure of a finite-dimensional vector space. The MFA is a special case of the general algebraic structure of a finite-dimensional vector space because it is a special case of the general algebraic structure of a finite-dimensional vector space. The MFA is a special case of the general algebraic structure of a finite-dimensional vector space because it is a special case of the general algebraic structure of a finite-dimensional vector space. The MFA is a special case of the general algebraic structure of a finite-dimensional vector space because it is a special case of the general algebraic structure of a finite-dimensional vector space. The MFA is a special case of the general algebraic structure of a finite-dimensional vector space because it is a special case of the general algebraic structure of a finite-dimensional vector space. The MFA is a special case of the general algebraic structure of a finite-dimensional vector space because it is a special case of the general algebraic structure of a finite-dimensional vector space. The MFA is a special case of the general algebraic structure of a finite-dimensional vector space because it is a special case of the general algebraic structure of a finite-dimensional vector space. The MFA is a special case of the general algebraic structure of a finite-dimensional vector space because it is a special case of the general algebraic structure of a finite-dimensional vector space. The MFA is a special case of the general algebraic structure of a finite-dimensional vector space because it is a special case of the general algebraic structure of a finite-dimensional vector space. The MFA is",
    "Handling Inter-Annotator Agreement for Automated Skin Lesion Segmentation\n\nThe goal of this research is to develop a method for automatically segmenting skin lesions in a patient's skin using a combination of automated segmentation and manual segmentation. The method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface. The method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based on the assumption that the lesion is a discrete entity, and that the lesion is not a part of the skin surface.\n\nThe method is based",
    "Content-based Propagation of User Markings for Interactive Segmentation of Patterned Images\n\nAbstract\n\nWe present a method for content-based propagation of user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-defined user-",
    "In this work we investigate the use of high dimensional sparse filters for image filtering, focusing on the problem of image filtering with noisy data and limited capacity. We show how to apply this filtering method to a range of applications in image processing, particularly deep learning, by building a scalable BNF-like model that can adaptively learn to deal with the noisy data, and by employing the high-dimensional sparse linear algebra to efficiently scale up image filtering. Our model learns to handle arbitrary sparsely shaped data efficiently, using a high dimensional non-linearity in the input space and high dimensional non-linearity in the output space. The result is efficient implementation of simple filtering algorithms and a complete characterization of the framework's performance. In particular, we show for a range of image datasets, both for both real and n-dimensional sparse data, that training is achievable through a combination of parallel filtering and parallel sparse linear algebra. Our results also show that this system can be extended to handle large datasets, without requiring additional feature engineering.\n\nWe demonstrate two main results. First, we make use of the scaling technique proposed in this article, to achieve efficient scaling of high-dimensional sparse linear algebra representations on a GPU. Second, our framework can also provide an alternative form of feature engineering that allows the model to learn to do a variety of filtering tasks, such as bilinear filtering, soft and hard soft-edge detection, and fuzzy feature engineering.\n\nThe video gives a good description of the research, showing a few examples of both the parallel and the parallel sparse linear algebra pipelines.\n\nI want to thank Paul Chudnovsky and Ben DeZeeuw for helpful discussions, and I would like to extend a huge thank you to Alex Graves and his folks at Deep Learning Systems for making this work possible. I also would like to thank the many people who have submitted code or contributed ideas, especially Alex Graves and many others at Deep Learning Systems and The Open University. For a list of people who gave many kind words, see the paper.",
    "This paper presents the implementation of the adversarial constraint-based CNN with a large vocabulary. In contrast with previous efforts we employ fully connected components, which allows us to achieve better performance under unsupervised, multi-label classification tasks. All of our classes are implemented in the fully connected layer based on the adversarial constraint-based training framework proposed in [Sharma19][Keen21]. However, unlike traditional adversarial training, the CNN is trained directly and never participates in the learning process. We demonstrate significant improvement in classification accuracy in the unsupervised task in two different images of the same patient based only on the original CNN structure and using a large natural vocabulary. Using the adversarial structure, each CNN class is trained with different weights, and the resulting loss of each type of CNN is computed. Our approach achieves robustness and speed in comparison with the traditional approach.\n\nThis is definitely a big first step in the AI space here, and while they say this will be implemented in a medical imaging application, you could easily run the same approach on any subject, especially in the domain of medical imaging, which needs some type of classification to distinguish between healthy and sick people. From where we are standing, we can't tell you exactly how that will play out in the real world, but we're not exactly betting against it having some serious, positive effects.\n\n[image credit: iStock]",
    "\"We present a method for replicating lidar point clouds with deep sensor cloning. We use a deep learning approach to learn the shape of the point cloud and then use a deep neural network to reconstruct the point cloud from the raw sensor data. We demonstrate that our method can be used to reconstruct point clouds from a variety of sensors, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets, including lidar, GPS, and laser ranging. We also demonstrate that our method can be used to reconstruct point clouds from a variety of datasets",
    "We present fast graph-cut based optimization (GCBO) for dense deformable registration of volume images, which can be used to reduce the number of image transformations and improve the quality of the resulting registration. GCBO uses a simple algorithm that combines several different techniques to minimize the number of image transformations needed to reconstruct an object's shape. We show that GCBO improves both the accuracy and speed of the reconstruction process compared with other methods. Our results demonstrate that GCBO can significantly improve the quality of the final registration by reducing the number of image transformations required to reconstruct the object's shape.",
    "First introduced in [1], the Hermite function is a unique polynomial whose polynomial coefficients are constant and whose coefficients are non-repeating. In this paper, we study its behavior under nonlinear equations in the form of a special case of the well-studied function of the first degree. We prove a non-linearity for an analogous Hermite polynomial \\(L\\) with the same polynomial coefficients, but with different polynomial coefficients: the non-repeating ones of \\(L\\) vanish.\n\nSee the paper for an introduction to the special case and the derivation of the theorem.\n\n[1] A.C. Hermite: Mathematically a Biologist. Mathematische Rundschau, vol. 27, no. 1, 1957, p. 2023.\n\nRelated:\n\nComments",
    "High-dimensional estimating equations (HEDE) have broad applications, in the domains of biomedical drug discovery, biophysical dynamics, and environmental economics. The generalization techniques that have allowed us to create high-dimensional HEDE models are not very useful, at least in practice. To gain a practical insight on the difficulties we have encountered in doing so, we present a numerical example of the process we have been describing, along with two variants (with different numbers of dimension) where it is not possible to solve the equations. We also present a proof of the completeness of the technique. Our analysis focuses on the case where an arbitrary data set can be represented as a sum of \"subspaces\" containing \"values,\" and are not constrained to have certain properties. We propose a more general strategy to estimate models, to be used with higher-dimensional data sets that have at least the dimension that is needed. We show that with such data, we can model many important phenomena in physics and biology, notably biological macromolecular interactions, electrochemical and molecular dissociation, and non-equilibrium electron transfer processes. While a certain amount of computational effort is necessary in the case of simple models without constraints on the size of the spatial dimensions of the model, our approach is well suited for models with arbitrary spatial dimensions.\n\nThe full paper has been published in Nature Communications: \"Hierarchical and Multidimensional Estimating Equations for Physical Models with High Dimensionality.\"\n\nI've always been a huge fan of the idea of \"higher order approximations\"  in particular, the idea that we can use higher level approximations and use them to do things we could not do before. There are many tools that allow us to do this in various settings, but I believe that we are about to build an algorithm called DFT with the potential (based on my own experiences with DFT and its cousins) to help give us the ability (justifiably or not) to \"take a picture\" of a problem and be able to estimate a single \"picture\" of that problem. I have been watching this potential (and I have to say I am not disappointed) with a mixture of glee and trepidation, and I'm excited to be part of the DFT effort (and excited to see what comes of it)",
    "Face recognition is a challenging problem in computer vision. The problem is to find a face in a large image, given a set of features. The problem is particularly difficult for images with a large number of faces, such as those in the Internet. In this paper, we propose a novel approach to face recognition that uses a second-order pooling approach to find a face in a large image. We show that our approach is able to solve the problem of face recognition with a large number of faces in a reasonable amount of time. We also show that our approach is able to solve the problem of face recognition with a large number of faces in a reasonable amount of time.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.\n\nThe paper is available here.",
    "Abstract The distorted mirror of Wikipedia (DM) has been widely discussed in academic circles, and its impact on scholarly communication has been studied by several researchers. This study examines the extent to which Wikipedia articles about academics are biased against them. We find that DM articles tend to be more negative than those about other fields, but this effect is not significant when we control for the number of citations to these articles. In addition, we show that the bias is driven by the fact that Wikipedia articles about academics have fewer references to their work than do articles about other disciplines. These results suggest that Wikipedia's focus on the humanities may lead it to produce an overly positive view of academia.\nThis is a very interesting study. I think it does a good job of showing how Wikipedia can skew the way people perceive certain topics. It also shows that there is a lot of room for improvement in terms of how Wikipedia presents information about academics. For example, if you look at the article on the University of California system, it says that UC Berkeley is one of the top ten universities in the world, yet it doesn't mention that they're ranked #1 in the US. That would be a much better representation of what the university actually is.\nI'm sure there will be some who say that this isn't really relevant because Wikipedia is just a collection of random links to other websites. But I don't see how that could possibly be true. If Wikipedia was just a bunch of random links to other websites, then why did it take so long for someone to notice that it had a problem? And if Wikipedia were just a bunch of random links to other websites, then why didn't anyone notice that it was being edited by a group of editors with a clear agenda?\nIf Wikipedia is just a bunch of random links to other websites, then why did it take so long for someone to notice that it had a problem?\nAnd if Wikipedia is just a bunch of random links to other websites, then why did it take so long for someone to notice that it was being edited by a group of editors with a clear agenda?\nIt seems like a pretty big deal that Wikipedia is being used as a source of information about academics. I wonder if there are any plans to address this issue?",
    "http://ioptab.iop.org/1612.04402",
    "Abstract While much has been written about prompt generation for DEL, it remains highly problematic to reliably produce the output given many different environment parameters - some difficult and others obvious like an ENV variable's value and configuration of.NET's eventing infrastructure. The primary problem can be summarized as follows: To obtain reliable and predictable outputs from simple, dynamic input, a generator should be composed to use standard environment variables where possible and otherwise invoke built in function such as shell commands or batch file parsing that does not rely on the current environment. In addition to being less error prone because one does not need to make hard assumptions on the input, this design methodology reduces reliance on libraries (such as CSPRNGs ) which are susceptible to changes during runtime in order to exploit specific inputs within the program. However this approach still requires careful manual effort to ensure no data gets accidentally overwritten because any number of errors can result when entering unknown variables while running DEVELOPER'S CHILD with some kind of custom logic involving INPUT's,.NET's Eventing Frameworks, etc.\nWhile there are multiple approaches to dynamically create these environments (often named \"Del\", \"DELIMEPLATIONER \", \"dynamic prompt generation \" or even just DEL_SEARCH_DEPL) they invariably fall short due to the necessity (at least in my experience) of ensuring most of the initial input contains a string like /bin/bash in its name. This makes them extremely resource intensive, expensive in terms of CPU usage, require having an entire interpreter to run on your computer and, as a side effect, limits their flexibility due to the fact that most people have limited familiarity with how languages work internally until they actually need to interact with those languages to generate an environment out of input. Since I'm looking at the topic as a programmer who is very concerned with maintaining his programming language knowledge through active practice so while these features may get new features added quickly into existing programming environments they won't necessarily change something that is fundamental to what I take pride in when using an existing programming language. While most of us will probably never see that feature enabled by default within our editors, IDEs or other programs we often do need to enter inputs that start with bash ; or command line arguments that start with \\; etc. But how often do we encounter prompts from",
    "\"The study of regional wealth inequalities is a relatively new field of research. The main goal of this paper is to provide a comprehensive overview of the literature on regional wealth inequalities in Italy. The main findings are that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the regional wealth inequality is higher in Italy than in other European countries, and that the",
    "Dental biofilms are an important component in dental plaque and gingival inflammation, but their role in disease progression has not been fully elucidated. We present a statistical model that quantifies the contribution of dental biofilms to oral health by using a novel approach based on the analysis of data from a large cohort of patients with periodontal diseases. Our results show that dental biofilms contribute significantly to the development of periodontitis, whereas they do not affect the severity or persistence of gum disease. The model also shows that the presence of dental biofilms does not predict the risk of developing periodontitis. These findings suggest that dental biofilms may be useful as biomarkers for the assessment of periodontal disease, but further studies are needed to confirm this hypothesis.",
    "\"We present a new knowledge-based fully convolutional network (KFCN) that is able to classify lung CT images with high accuracy. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network is trained on a large dataset of CT images and is able to classify lung CT images with a mean error of 0.5 mm. The network",
    "\"In this paper, we present a new approach for facial landmark detection, based on deep learning, that combines multiple deep neural networks into a single super-trained system for facial landmark recognition. Our system can learn to extract landmarks from any object feature image, including ones that are not directly visible, or for example when a human's face is obscured by an object. We present extensive analyses showing that our algorithm can accurately predict facial landmark attributes in the absence of extensive landmark knowledge, and also demonstrate its ability to converge on a human-recognized human face. Our data set is enriched with a relatively large number of human faces that are well known to both computer vision researchers and general users, which makes our task interesting for both researchers and users.\n\nThe current state of facial recognition technologies is centered around automated analysis of images, mainly from online sources. While human recognition, also known as face detection, is an important research topic for the future, the current state of automated computer vision has focused on simple face detection, such as recognizing face, or face contours; detecting the distance between two objects; or recognizing a single shape features. The aim of this work is to find a more comprehensive approach or paradigm for facial detection, which will enable computer vision research to be carried out in a more advanced manner in the near future. Our proposed approach uses several deep learning models to represent the features of the human face, and combines these with the knowledge of each feature in order to model the user's facial expressions, thereby creating a novel facial detection framework. The proposed approach enables machine learning to deal with complex and diverse problems, ranging from tracking the facial movements of faces, to detecting facial distortions. Our results support the idea that deep learning has the potential to increase computational efficiency and make computer vision accessible to a large community of researchers.\n\nThe goal of this work is to demonstrate that deep learning achieves super-realtime facial landmark detection. With this approach, the neural networks can learn to discover landmarks on the basis of unsupervised feature learning, to achieve a state-of-the-art performance of 6.4% in a task where only 20% of the images were annotated with landmark boundaries. To demonstrate the validity of our work, we analyzed the accuracy and accuracy of our proposed approach against the state-of-the-art of existing",
    "Observations of an EXO-200 background in radioactive rock obtained from the Mt. BakerSnoqualmie National Monument in Washington State indicate that the emission of radioactivity from the radioactive geochemistry of the rock is significantly higher than that of natural geological sources, probably due to a very high rate of radioactive decay in the rock. This background has been detected at a number of distances from the source, implying that the background must arise from a physical process, possibly due to the interaction between the geochemistry of the rock and an external field. A comparison between the background-induced emissions and background values of ambient background radiation suggests that the background was generated by radioiodine decay.\n\nThe article also includes the following short, but very useful, video clip from a presentation called \"How a Geologist Obtains a Radioactive Background for Exo-200\" by David M. Lauer, PhD, on our YouTube channel:\n\n(Note for Science and Health Lovers: This video provides links to many other scientific papers that cover this same topic, such as this one: \"Analysis of the radioiodine background at Mt. BakerSnoqualmie National Park\" by David M. Lauer, PhD, published in the Journal of Geophysical Research, Vol 105, No. F5, June 4, 2006.)",
    "\"Our main idea in this paper is about the efficient evaluation of a compact version of product or product space. According to this strategy, a compact space consists of a set of linear products, and a set of linear filters over this set. Here, linear maps are used to specify the compactness property of the (filtered) compact set of products, which are known as product space. In our case, we evaluate the composition of a linear map with the product space itself by selecting at random a linear map of all fixed dimensions. In contrast to other work, we do not specify, at first sight, a specific choice of \"product\", but rather take the property of nonlinearity of the filters. Such a property, which is not known to the author of such analysis, is not easily definable by using finite series or other traditional nonlinearity tests. In addition to the usual nonlinearity tests, we also take advantage of the property of compactness to the filter, which gives a good approximation to the nonlinearity. As a consequence, using a product space as an efficient (or inefficient) measure for the nonlinearity of a filter is both correct and a generalization of the usual nonlinearity tests from regularity to compactness. Concretely, we first introduce an optimization scheme that we call \"narrower product space,\" which we prove that a compact compact collection of products (or products of filters) will be compact if and only if both this compact collection and the selected filter have a finite complement. In other words, the selection of a filter in the product space must be as specific as that of a linear map in the collection space. A generalization of our method is that any fixed pair of linear maps can be selected without restriction by simply selecting random elements from the selection between them. Moreover, given a \"filter\" and some product space, we show that this product space is always compact, and thus compact in any sense in which product space is defined in an efficient and general way. \"\n\n\nHere is an animation of our proof in practice:",
    "We present an algorithm that can be used to analyze sparse dictionaries, such as those generated by the popular word2vec library. The algorithm uses a kernel-based approach to efficiently extract features from sparse dictionaries and then applies them to train new models on large datasets. We demonstrate our method's performance in several real world applications including image classification, speech recognition, and natural language processing. Our results show that our technique outperforms other approaches based on feature engineering or neural networks, and we also provide some insights into how this approach works.",
    "We demonstrate remote quantum transmission at room temperature and high precision through polarization polarization switching, providing unprecedented capability to transfer large quantities of information in the near future by using a single photon as channel. At room temperature the photon carries out four polarization state transitions. By integrating our results into an accurate classical encoding scheme we have managed to achieve nonlinear optical communication with up to 1 Gbit/s speed on standard silicon substrates with a bandwidth-limited number of channels (i10 = 10^2). In this way, data can be transmitted without loss or errors over distances exceeding several kcm. We address other challenges such as high quality interconnects, energy management and efficient use of laser power. The proposed algorithms are designed together with the requirements of commercial applications where real-time quantum communications is paramount. Finally, thanks to robust integration of experimental measurements with theoretical calculations we were able to develop new constraints which further improve our theoretical predictions.",
    "\"We present a method for segmenting semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from remote sensing imagery. We use a novel approach to segment semantic space from",
    "Abstract:\nThe most likely separation of intensity and warping effects in image registration is a linear combination of the two. The linear combination is the most likely separation of intensity and warping effects because it is the most likely separation of intensity and warping effects in the image registration process. The linear combination is also the most likely separation of intensity and warping effects in the image registration process because it is the most likely separation of intensity and warping effects in the image registration process. The linear combination is also the most likely separation of intensity and warping effects in the image registration process because it is the most likely separation of intensity and warping effects in the image registration process. The linear combination is also the most likely separation of intensity and warping effects in the image registration process because it is the most likely separation of intensity and warping effects in the image registration process. The linear combination is also the most likely separation of intensity and warping effects in the image registration process because it is the most likely separation of intensity and warping effects in the image registration process. The linear combination is also the most likely separation of intensity and warping effects in the image registration process because it is the most likely separation of intensity and warping effects in the image registration process. The linear combination is also the most likely separation of intensity and warping effects in the image registration process because it is the most likely separation of intensity and warping effects in the image registration process. The linear combination is also the most likely separation of intensity and warping effects in the image registration process because it is the most likely separation of intensity and warping effects in the image registration process. The linear combination is also the most likely separation of intensity and warping effects in the image registration process because it is the most likely separation of intensity and warping effects in the image registration process. The linear combination is also the most likely separation of intensity and warping effects in the image registration process because it is the most likely separation of intensity and warping effects in the image registration process. The linear combination is also the most likely separation of intensity and warping effects in the image registration process because it is the most likely separation of intensity and warping effects in the image registration process. The linear combination is also the most likely separation of intensity and warping effects in the image registration process because it is the most",
    "Abstract\n\nWe present a novel method to segment volumetric medical images into anatomical landmarks and then apply it to image-based localization tasks. We show that our approach can be used to improve performance on both classification and localization tasks, which are typically performed by hand. Our results demonstrate that our method can be applied in real time to image-based localization tasks such as the one presented here.",
    "In this work we address a novel form of sputter on polar surfaces, where multiple particles are produced by light trapped within a rotating beam cavity. The result can be defined as an interference pattern, which may show up either symmetrically with respect to the orientation of particle origin/destination or asymmetric. Similar results were obtained previously using light trapping on metallic surfaces using a highly modified type of rotary tunneling microscope (MTM) [4], which permitted a large number of particle pairs in exchange (see Methods). In particular, we exploit this method on thin film graphene prepared in a three-dimensional channel. When one single pair of electrons is transferred across each graphene molecule at a single energy level, an electric potential difference and electromagnetic force arise between two adjacent pairs, that induces their formation in the same direction. As in the case of optical trapping on the metal substrate, we observe a rotation and sputtering effect at much lower frequencies when several such pairs occur in simultaneous locations along a given longitudinal axis [5]. At low atomic voltage (~8 eV), the resulting forces lead to emission waves emanating from nearby electrode locations (E i and E j ) that propagate along the surface, generating a complex system of correlated electronic charge density fluctuations that propagate outwardly throughout the entire sample length. These electric fields are more prevalent near edge regions due to the polarization angle between charged electron centers and oxygen atoms that is slightly different from the normal polarity of oxygen molecules. Since both center charges have approximately 180 symmetry, they create opposite electrical currents and magnetic moments, similar to those found for circular polarized beams (e.g., CVDs; Fig. 3a) whose induced electromagnetic field tends to push electrons toward one another. Thus for our experimental probe setup, only the most intense energy levels are capable of driving these effects on solid films on both sides of a vertical plane perpendicular to the original direction of motion. We also find that while all electron emissions generated upon interaction are directed away from the electrodes owing to the current dependence, the emitted trajectories remain distinct in various orientations depending on the applied directional magnetic field. Because spatial separation and polarization are extremely important parameters in the underlying mechanism (i.e., interparticle electric dipoles during particle generation and then recombination and spin dynamics), they determine how spatially separated excitations generate a complex wavefield with distinctive",
    "Fractals are ubiquitous in nature, and their mathematical properties have been studied extensively by mathematicians since antiquity. However, it has long been unclear how to represent these fractal structures mathematically. In this work we present an algorithm that can be used to generate fractal images using only standard algebraic operations. We show that our method produces images with high quality and accuracy, which are indistinguishable from real-world images. Our approach also allows us to produce images with arbitrary shapes, such as circles or squares. The resulting images are useful for many applications, including image processing, computer vision, and 3D visualization.",
    "The goal of this paper is to develop a method for real-time image normalization that is robust to the presence of noise in the image. We propose a novel approach to image normalization that is based on a novel image reconstruction algorithm that is based on a novel image reconstruction algorithm. We show that our method is able to recover the original image from the reconstructed image. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image with a high degree of confidence. We also show that our method is able to recover the original image from the reconstructed image",
    "We present a novel method for learning subspace representations of sparse structured outliers and noise. We use a novel subspace representation of the noisy data, which is a sparse matrix of the form (1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,",
    "\n\nWe study the Gaussian core model in high dimensions, also known as the Dyson model. We prove that in the thermodynamic limit, the model undergoes a phase transition at a critical temperature $T_c$. Below $T_c$, the model has a unique ground state, while above $T_c$, the model has multiple ground states. We also study the model's critical properties and show that they are in agreement with the predictions of mean field theory.",
    "\n\nIn this paper, we study the coupling of vector fields to the Gauss-Bonnet invariant. We show that the coupling is possible if and only if the vector fields are divergence-free. We also show that the coupling is unique up to a divergence-free vector field.",
    "\n\nIn this paper, we propose an adaptive strategy for superpixel-based region-growing image segmentation. The proposed strategy consists of two steps: (1) superpixel generation and (2) region-growing. In the first step, we use a superpixel generation algorithm to generate a set of superpixels. In the second step, we use a region-growing algorithm to grow regions from the superpixels. The proposed strategy is adaptive in that it can automatically adjust the parameters of the superpixel generation and region-growing algorithms to the characteristics of the input image. We have evaluated the proposed strategy on a set of images and compared the results with those of the state-of-the-art methods. The results show that the proposed strategy outperforms the state-of-the-art methods in terms of accuracy and efficiency.",
    "\n\nRecently, neural architecture search (NAS) has become a popular technique for automatically designing neural networks. Typically, a search algorithm is used to iteratively explore the space of possible architectures and identify the best one for a given task.\n\nHowever, this process can be inefficient if the search space is large or the evaluation function is expensive to compute. In this paper, we propose a new technique for NAS that poisoning the search space. That is, we selectively remove architectures from the search space that are unlikely to be the best.\n\nWe show that this technique can significantly speed up the search process while still finding high-quality architectures. Finally, we evaluate our technique on a standard NAS benchmark and find that it outperforms the state-of-the-art NAS method.",
    "\n\nWe propose a semiparametric extension of the stochastic block model for longitudinal networks. In our model, the number of blocks and the within- and between-block edge probabilities are allowed to vary over time, and we estimate them using a Bayesian approach. We apply our model to a network of scientific collaborations, and find that it provides a better fit to the data than the standard stochastic block model.",
    "\n\nIn this paper, we propose a new deep learning architecture for semantic image segmentation. Our architecture is based on the encoder-decoder framework, but with a deep decoder network. The deep decoder network is composed of multiple convolutional and deconvolutional layers, and is capable of learning a rich, high-level representation of the input image. This representation is then used by the final segmentation layer to produce a dense prediction. We evaluate our architecture on the PASCAL VOC 2012 semantic segmentation benchmark, and show that it outperforms the state-of-the-art methods.",
    "\n\nIn this paper, we study the sensor location problem, which is a classic problem in the area of networked sensing. The problem is to select a set of sensor locations such that the sensing quality is maximized while the cost of deploying and operating the sensors is minimized. We first formulate the problem as an optimization problem, and then we present a general method for solving the optimization problem. We also provide a detailed analysis of the characteristics of the optimal solutions.",
    "\n\nIn this paper, we propose a novel semi-supervised learning method for medical image segmentation. The proposed method is based on a multi-task attention mechanism that can automatically focus on the most relevant features for each task. The attention mechanism is trained using a combination of supervised and unsupervised loss functions. The supervised loss function is used to train the attention mechanism to focus on the most relevant features for the segmentation task, while the unsupervised loss function is used to encourage the attention mechanism to focus on features that are shared between the segmentation and the other tasks. The proposed method is evaluated on two publicly available medical image segmentation datasets, and the results show that the proposed method outperforms the state-of-the-art semi-supervised learning methods.",
    "\n\nThe Many Worlds Interpretation (MWI) of quantum mechanics is a simple and elegant way of understanding the much-mysterious quantum realm. The key idea is that there is a multiplicity of universes, or \"worlds\", each of which evolves independently of the others. According to the MWI, every quantum event splits the universe into multiple universes, each universe containing a different outcome of the event. Therefore, every quantum event leads to a branching of the multiverse.\n\nThe MWI has been found to be a very successful interpretation of quantum mechanics, able to explain many of the strange and seemingly bizarre properties of the quantum realm. In particular, it provides a natural way of understanding the phenomenon of quantum interference, one of the most striking and counter-intuitive aspects of quantum mechanics.\n\nThe MWI also has some intriguing implications for the nature of reality. In particular, it suggests that the universe we experience is just one of an infinite number of universes, each with its own version of us. This has led some to speculate that the MWI could provide a way of understanding the many-worlds of quantum computation, in which a quantum computer explores all of the different universes that are consistent with its quantum state.\n\nIn this paper, we will provide an introduction to the Many Worlds Interpretation of quantum mechanics, and explore its implications for quantum computation. We will also discuss some of the open questions about the MWI, and ways in which it could be experimentally tested.",
    "\n\nIn this paper, we propose an attention-guidedactive learning strategy for 3D medical image segmentation. Our method is motivated by the fact that, in many medical image segmentation tasks, only a few annotations are needed for the model to achieve high performance. To this end, we first train a segmentation model with only a few annotated samples. Then, we use the model to predict the labels for a large number of unannotated samples. Finally, we select a small number of samples with high entropy as the query set for the next round of annotation. We compare our method with several state-of-the-art methods on two 3D medical image segmentation tasks, and the results demonstrate that our method can achieve significant performance improvement with only a small number of annotations.",
    "\n\nWe study the rate of convergence of some asymptotically chi-square distributed statistics by Stein's method. We obtain the rate of convergence of the sum of two independent random variables whose distributions are asymptotically chi-square distributed with different degrees of freedom. We also obtain the rate of convergence of the maximum of two independent random variables whose distributions are asymptotically chi-square distributed with different degrees of freedom.",
    "\n\nImage segmentation is a fundamental problem in computer vision with many applications. In this paper, we propose a new image segmentation method using weak shape priors. Our method is based on a simple observation: an object in an image can be segmented by finding a set of connected pixels that have similar intensity values and are close to each other in the image. This observation leads to a natural image segmentation algorithm, which we call the connected component algorithm. Our algorithm is very efficient and can be used for real-time applications. We demonstrate the effectiveness of our algorithm on a variety of images, including natural images, medical images, and synthetic images.",
    "\n\nDeep learning methods based on convolutional neural networks (CNNs) and Transformers have shown great success in many computer vision tasks. However, these models are usually designed and trained separately for 2D and 3D data, respectively. In this paper, we propose a novel 3D medical image segmentation framework, CoTr, that efficiently combines the strengths of CNNs and Transformers. CoTr consists of a CNN encoder and a Transformer decoder. The CNN encoder extracts rich spatial features from 3D medical images, while the Transformer decoder predicts pixel-level labels by leveraging the global context information. Our framework is very flexible and can be used with any CNN or Transformer-based models. We have extensively evaluated our framework on two challenging 3D medical image segmentation tasks: (1) liver and tumor segmentation on the LiTS dataset, and (2) white matter hyperintensities (WMH) segmentation on the MRBrainS dataset. CoTr achieves state-of-the-art performance on both tasks, outperforming the previous best methods by a large margin.",
    "\n\n\n\nIn this paper, we present a method for 3D biomedical image segmentation that combines a fully convolutional neural network (FCN) with a recurrent neural network (RNN). The FCN is used to extract features from the input images, and the RNN is used to learn the relationships between the features. The two networks are trained jointly, and the output of the RNN is used to guide the FCN. Our method is tested on two datasets, and we show that it outperforms the state-of-the-art methods.",
    "\n\nIn this paper, we propose a new time series graph cut image segmentation scheme for liver tumors. The proposed scheme firstly extracts the tumor region from the liver image by local thresholding and region growing methods. Secondly, it segments the tumor region into different sub-regions by using a time series graph cut segmentation method. Finally, the scheme classifies the tumor sub-regions into different tumor types according to their intensity and texture features. Experiments on liver image datasets validate that the proposed scheme can effectively segment liver tumors and classify them into different tumor types.",
    "\n\nWe present a new method for coherent averaging of data from multiple sensors. The method is based on the observation that the noise in the data from each sensor is uncorrelated with the noise in the data from the other sensors. This allows us to construct an estimate of the signal that is more accurate than the estimate that would be obtained by simply averaging the data from the sensors. We demonstrate the effectiveness of the method with simulations and real data from a network of seismic sensors.",
    "\n\nIn this paper, we consider the optimal boundary control problem for a simplified Ericksen--Leslie system describing the flow of a nematic liquid crystal in two spatial dimensions. We prove the existence of an optimal control and derive a necessary condition in the form of a variational inequality. We also numerically solve the variational inequality to obtain the shape of the optimal control.",
    "\n\nIn this paper, we study the Baum-Connes property for a quantum (semi-)direct product of two C*-algebras. We prove that if the Baum-Connes property holds for both factors, then it also holds for the quantum (semi-)direct product. This generalizes a result of Higson and Kasprzak for the classical (semi-)direct product.",
    "\n\nIn recent years, there has been an increasing interest in the development of decision support systems (DSSs) for patient referrals in healthcare contexts. However, the existing DSSs often lack the ability to deal with uncertainty, which is a critical issue in healthcare decision making. In this paper, we propose a new framework, called MCU-Net, for uncertainty representations in DSSs for patient referrals. MCU-Net is based on a multi-channel deep neural network architecture, which can learn the underlying distributions of referral data and generate multiple predictions with different levels of confidence. We evaluate the proposed framework on a real-world dataset of patient referrals from a large healthcare system. The results show that MCU-Net outperforms the state-of-the-art DSSs in terms of both accuracy and uncertainty representations.",
    "\n\nFully convolutional neural networks (FCNNs) are powerful models for semantic segmentation that have been shown to outperform traditional methods such as support vector machines (SVMs). In this paper, we apply FCNNs to the problem of crowd segmentation in images. We first train an FCNN on a large dataset of crowd images and then use it to segment crowds in new images. We compare our FCNN-based method to state-of-the-art methods for crowd segmentation, including SVMs and deep learning-based methods. Our results show that our FCNN-based method outperforms all other methods on a challenging dataset of images with dense crowds.",
    "\n\nIn this paper, we present a recurrent residual convolutional neural network based on U-Net (R2U-Net) for medical image segmentation. Unlike existing methods that rely on multiple U-Nets for recurrent processing, our R2U-Net employs a single U-Net with two independent streams: a recurrent stream and a residual stream. The recurrent stream contains a stack of LSTM cells that propagate the features extracted from the input image across the stack. The residual stream uses the features extracted from the input image to learn the residual mapping between the output of the last LSTM cells and the ground truth segmentation. The two streams are then combined to produce the final segmentation. We have evaluated our R2U-Net on the ISIC 2017 Skin Lesion Segmentation Challenge and the BraTS 2018 brain tumor segmentation challenge. Our R2U-Net achieves state-of-the-art performance on both datasets, outperforming the previous best methods by a significant margin.",
    "\n\nDeep convolutional neural networks (DCNNs) have shown great success in many computer vision tasks. In this paper, we explore the use of DCNNs for object saliency detection and image segmentation. We propose a simple but effective DCNN-based model for object saliency detection. The model consists of two convolutional layers followed by two fully-connected layers. We train the model on a large-scale saliency detection dataset, and show that it outperforms the state-of-the-art saliency detection methods on a number of benchmarks. We further show that the trained model can be used for weakly-supervised image segmentation, and achieves competitive results compared to the state-of-the-art methods.",
    "\n\nThis paper presents an uncertainty-based human-in-the-loop system for industrial tool wear analysis. The system is designed for use in an industrial setting, where the goal is to provide timely and accurate information about tool wear to a human operator. The system consists of three main components: a data acquisition system, a tool wear estimation system, and a human-in-the-loop interface. The data acquisition system is used to collect data about the tool wear process, while the tool wear estimation system uses this data to estimate the amount of wear on the tool. The human-in-the-loop interface is used to provide the operator with information about the estimated tool wear, as well as to allow the operator to provide feedback about the estimation. This feedback is then used to improve the estimation for future iterations. The system is designed to be used in a closed-loop fashion, where the operator and the system are constantly working together to improve the estimation of tool wear.",
    "\n\nIn this paper, we present VICE, a tool for the visual identification and correction of neural circuit errors. VICE is based on a novel approach to error correction that uses a combination of static and dynamic analysis to identify and correct errors in neural circuits. We have used VICE to successfully correct errors in a variety of neural circuits, including circuits for object recognition, navigation, and motor control. VICE is freely available for use by the scientific community.",
    "\n\nIn this work, we propose a self-paced contrastive learning method for semi-supervised medical image segmentation. First, we use a contrastive learning objective to train a deep network on a large unlabeled medical image dataset. Then, we use the learned network to generate pseudo-labels for a small labeled medical image dataset. Finally, we use the pseudo-labels to fine-tune the network on the small labeled dataset. We compare our method to state-of-the-art semi-supervised learning methods on two public medical image segmentation datasets: the Brain Tumor Segmentation Challenge (BRATS) and the Meniscus Segmentation Challenge (MSKCC). Our method achieves comparable or better results to the state-of-the-art methods on both datasets.",
    "\n\nIn this paper, we propose a cost-effective region-based active learning (CEREALS) approach for semantic segmentation. CEREALS is a two-stage approach that first generates a small number of high-quality training samples using a region-based active learning method, and then trains a deep neural network using the generated samples. To generate high-quality training samples, CEREALS uses a region-based active learning method that selects regions that are informative and diverse. To select informative regions, CEREALS uses a saliency map that highlights the regions that are most important for classification. To select diverse regions, CEREALS uses a clustering method that groups similar regions together. CEREALS then trains a deep neural network using the generated samples. The deep neural network is trained using a standard backpropagation algorithm. CEREALS is evaluated on the Pascal VOC 2012 and Cityscapes datasets. The results show that CEREALS outperforms the state-of-the-art methods on both datasets.",
    "\n\nIn recent years, convolutional neural networks (CNNs) have been successfully applied to medical image segmentation. However, most of the existing methods require a large number of annotated images for training, which are often unavailable in medical applications. In this paper, we propose a sample selection method for training CNNs for multi-organ segmentation with limited annotations. Our method is based on the idea of active learning, which iteratively selects the most informative samples for annotation. In each iteration, our method first trains a CNN with the available annotations, and then uses the trained network to predict the labels for a large number of unannotated images. The predicted labels are used to compute the relaxed upper confidence bound (RUCB) for each image, which measures the informativeness of the image with respect to the current CNN. The images with the highest RUCB values are then selected for annotation. Experiments on the ISBI challenge dataset and the MRI dataset show that our method can achieve comparable performance to the state-of-the-art methods with a significantly smaller number of annotations.",
    "\n\nSteckmap is a publicly available software package written in IDL which fits the spectra of galaxies with a single template constructed from a linear combination of stellar population synthesis models. The package has been designed to be used with data from the Sloan Digital Sky Survey (SDSS), but can be used with any spectroscopic data. The stellar population synthesis models used to construct the template are from the publicly available ELODIE library. The template can be either publicly available or can be constructed by the user. The software package also includes a library of templates constructed from the ELODIE library for a range of galaxy types. The software can be used to determine the best-fitting template for a given galaxy, and to estimate the parameters of the stellar population synthesis models used to construct the template. The library of templates can be used to study the properties of galaxies in a homogeneous way.",
    "\n\nIn this work, we propose a simple and novel semi-supervised learning technique called ROAM (Random Layer Mixup). ROAM can be seen as a generalization of the Mixup augmentation technique, where now instead of mixing two input images, we mix two sets of feature maps obtained from different layers of a deep neural network. We apply ROAM to two different tasks in medical imaging: (i) chest X-ray classification, and (ii) breast cancer histopathology image classification. For both tasks, we achieve state-of-the-art results using only a small amount of labeled data.",
    "\n\nImage-level data augmentation (D. A.) is a standard way to improve the robustness of deep neural networks for semantic image segmentation. However, recent studies have shown that D. A. at the object-level can further improve the performance of semantic segmentation models. In this paper, we propose ObjectAug, a simple yet effective object-level D. A. method that can be applied to any semantic segmentation model. ObjectAug first extracts object proposals from the input image using an off-the-shelf object proposal method. It then randomly selects a subset of the proposals and applies a set of user-specified augmentation operations to them. The augmentations are applied only to the object proposals and not to the whole image. The augmented proposals are then used to generate the final segmentation map by \"filling in\" the pixels inside the proposals with the corresponding object labels. ObjectAug can be applied to any semantic segmentation model and does not require any modifications to the model or its training procedure. We evaluated ObjectAug on the PASCAL VOC 2012 andCityscapes semantic segmentation datasets. Our experiments show that ObjectAug can significantly improve the performance of a variety of semantic segmentation models, with an absolute gain of up to 3.4% in mean IoU over the baseline model.",
    "\n\nWe report here the first observation of total electronic Raman scattering in the charge-density-wave (CDW) phase of the spinless Falicov-Kimball model. We find that the CDW order parameter couples linearly to the phonons, leading to a renormalization of the phonon frequency. The total intensity of the Raman scattering is found to be proportional to the CDW order parameter squared. Our results are in good agreement with recent experimental observations in the cuprate superconductors.",
    "\n\nIn this paper, we investigate how people learn to pay attention to mistakes. We find that people are more likely to pay attention to a mistake when it is made by someone else, when it is made in a domain in which they have little expertise, and when it is made in a domain in which they have high stakes. We also find that people are more likely to pay attention to a mistake when it is made in a domain in which they have high standards, when it is made in a domain in which they have high standards for themselves, and when it is made in a domain in which they have high standards for others.",
    "\n\nDeep reinforcement learning (RL) has emerged as a powerful tool for learning complex tasks from high-dimensional data. In recent years, deep RL has been successfully applied to a range of problems in computer vision, including object detection, image segmentation, and image generation. In this paper, we survey the recent advances in deep RL for computer vision. We first review the RL algorithms that have been most successful in computer vision, including value-based methods such as Deep Q-Networks (DQN) and policy gradient methods such as Trust Region Policy Optimization (TRPO). We then discuss the challenges involved in applying RL to computer vision tasks, such as the curse of dimensionality and the need for large amounts of training data. Finally, we review the recent successes of deep RL in computer vision, including the use of RL for object detection, image segmentation, and image generation.",
    "\n\nKernel spectral clustering is a powerful tool for data clustering which can be used to find hidden patterns in data. In this paper, we review the basics of kernel spectral clustering and discuss its applications in various fields. We also provide a detailed analysis of the algorithm and its performance.",
    "\n\nIn this paper, we propose a new method for 3D medical image segmentation based on elastic boundary projection. Our method is motivated by the observation that many 3D medical images can be approximately represented as a collection of 2D slices. This observation motivates us to develop a method that can segment 3D medical images by projecting them onto a 2D plane and then performing 2D image segmentation. Our method is based on the idea of using an elastic membrane to approximate the 3D surface of the object to be segmented. We then use a gradient-based optimization algorithm to find the optimal 2D projection of the 3D surface onto the plane. We apply our method to the problem of segmenting the left ventricle of the heart from 3D MRI images. Our method is able to accurately segment the left ventricle from 3D MRI images with a high degree of accuracy.",
    "\n\nMeanShift++ is an extremely fast mode-seeking algorithm with many applications. We propose and develop two new applications of MeanShift++: image segmentation and object tracking. Our algorithm is based on a simple and efficient mean-shift algorithm that can be easily implemented on a variety of platforms. We provide quantitative results on a standard image segmentation benchmark and demonstrate the efficacy of our algorithm on a wide range of natural images. Our algorithm is significantly faster than the state-of-the-art mean-shift algorithm and achieves comparable results. We also demonstrate the efficacy of our algorithm for object tracking in video. Our algorithm is able to track objects in complex videos with remarkable accuracy and is significantly faster than the state-of-the-art mean-shift algorithm.",
    "This academic paper presents a comprehensive analysis of the LPM (Landau-Pomeranchuk-Migdal) effect in sequential bremsstrahlung, focusing majorly on the factorization aspect. A precise calculation is conducted using Quantum Chromodynamics (QCD) and Quantum Electrodynamics (QED), pertaining to both soft and collinear radiation. Correlations between successive emissions are also considered, with a further extension made to multiple sequences. Results show the significant influence of the LPM effect on factorization breaking, especially at very high energies, thus shedding light on its implications for particle physics. It is our anticipation that the findings and theoretical groundwork presented in this paper will stimulate better understanding and further research on the topic.",
    "This paper presents a novel Spatio-angular Minimum-variance Tomographic Controller (SMTC) for Multi-Object Adaptive Optics (MOAO) systems. The proposed controller aims to improve the performance of MOAO systems by reducing the impact of wavefront distortions. The SMTC is designed based on the minimum-variance principle and incorporates both spatial and angular information in the tomographic reconstruction process. Theoretical analysis and simulation results demonstrate that the proposed controller can significantly enhance the imaging quality of MOAO systems, outperforming traditional controllers in terms of correction accuracy and robustness. This research provides a promising solution for the optimization of MOAO systems, with potential applications in astronomical telescopes and other optical imaging systems.",
    "This paper provides a comprehensive study of log-symplectic manifolds, a class of manifolds that are of significant interest in symplectic geometry. We present a series of examples and counter-examples to illustrate the defining properties and characteristics of these manifolds. The examples are drawn from a variety of contexts, including complex geometry, algebraic geometry, and dynamical systems. The counter-examples are designed to highlight the boundaries of the definition and to clarify common misconceptions. Our analysis contributes to a deeper understanding of the structure and properties of log-symplectic manifolds, and provides a foundation for further research in this area.",
    "In this paper, we propose Pyramid Medical Transformer (PMT), a new, highly efficient and versatile model for medical image segmentation. We exploit the Transformer architecture's robust nature for feature extraction, localization, and segmentation in the context of complex medical images. PMT deploys a pyramid attention mechanism that captures rich contextual information at different scales, effectively improving its segmentation performance on a variety of medical imaging modalities. The model is tested on several benchmark medical imaging datasets where it outperforms existing state-of-the-art models, proving not only its efficacy but also its potential for broad applicability in medical image analysis. The paper contributes to the intersection of deep learning and medical image analysis, providing new technological capabilities for healthcare providers.\n",
    "This paper explores the nature of indiscriminate covers of infinite translation surfaces, challenging existing notions that portray them as 'devious' or complex. By deriving concrete examples and mathematical proofs, the study demonstrates how these covers behave neutrally or 'innocently', instead of complicating or manipulating the properties of translated surfaces. The paper introduces novel techniques and theoretical perspectives to highlight the simplicity and mannerism of these covers. It aspires to contribute to deeper understandings of how indiscriminate coverings function and interact, encouraging further research on the topic.",
    "This paper explores the dichotomy for first-order reducts of unary structures. It delves into the complexity of the constraint satisfaction problem (CSP) for these structures, providing a comprehensive analysis of the dichotomy conjecture. The study employs a novel approach to the algebraic theory of CSPs, focusing on the primitive positive definable reducts of unary structures. The results reveal a dichotomy for these reducts, which either fall into the class of tractable problems or are NP-complete. This research contributes to the understanding of the complexity of CSPs and provides a foundation for further studies in this field.",
    "This paper presents a novel approach to predict urban expansion using a combination of Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) models. The proposed model leverages the strengths of CNN in extracting spatial features from satellite images and LSTM's ability to capture temporal dependencies in sequential data. The model was trained and tested on a dataset comprising multi-temporal satellite images of several urban areas. The results demonstrate that the proposed CNN-LSTM model outperforms traditional models in predicting urban expansion, with higher accuracy and precision. This research contributes to the field of urban planning and sustainable development by providing a robust tool for forecasting urban growth patterns and aiding in strategic planning.",
    "This paper explores the concept of time directionality in both classical and quantum physics. It delves into the fundamental principles of time asymmetry, entropy, and the arrow of time, providing a comprehensive analysis of how these concepts are interpreted and applied in both classical and quantum realms. The paper also investigates the paradoxes and challenges associated with time directionality, such as the problem of irreversibility and the quantum measurement problem. Furthermore, it discusses the implications of time directionality for the understanding of the universe's evolution and the fundamental laws of physics. The paper concludes with a discussion on potential areas for future research in this intriguing intersection of physics and philosophy.",
    "This academic paper presents a novel methodology for segmenting overlapping wear particles in conditions where labelled data is limited and sample imbalance exists. The study utilizes advanced machine learning algorithms to effectively identify wear particles, crucial for the diagnosis and prognosis of machine health. A unique dataset of particle images was compiled, distinguishing this work from previous studies that rely heavily on fully labelled datasets. The proposed approach demonstrates a high accuracy rate, effectively addressing the problem of segmentation of overlapping wear particles. Our approach significantly enhances particle analysis efficiency, proving its potential in real-time, automated, and intelligent machine health monitoring systems.",
    "This academic paper revisits two intriguing mathematical series, namely the Kempner and Irwin series. Using advanced mathematical analysis and number theory, we derive formulas capturing the behavior and sum of these series. The Kempner series, also known as the Kempner function, manifests in the analysis of algorithms and in studying prime numbers, while the Irwin series is a lesser-known but similarly intriguing construct closely related to Kempner's series. Our findings solidify understanding of these functions, providing insight into their theoretical underpinnings and potential practical applications. We hope our comprehensive treatment of the series contributes to ongoing studies in mathematical series and primes.",
    "This paper presents a novel approach for brain image segmentation by combining Hidden Markov Random Field (HMRF) and Conjugate Gradient (CG) methods. The proposed method aims to improve the accuracy and efficiency of brain image segmentation, a critical task in medical imaging for disease diagnosis and treatment planning. The HMRF model is used to capture spatial dependencies in the image, while the CG method is employed to optimize the energy function of the HMRF model. Experimental results on various brain images demonstrate that the proposed method outperforms traditional segmentation methods in terms of both segmentation accuracy and computational efficiency. The paper also discusses potential applications of this approach in other medical imaging tasks.",
    "This academic paper presents an extensive study on the electrical properties of bismuth-implanted amorphous chalcogenide films. The paper details the methods employed for the production and testing of these films, primarily concentrating on ion implantation as a technique for modifying their resistive and capacitive attributes. The paper employs a comprehensive analysis of the obtained data, including I-V (current-voltage) and C-V (capacitance-voltage) characteristics. Further, it discusses the connection between said electrical attributes and the device's prospective applicability in non-volatile memory devices, optical discs and switching technologies. It provides substantial evidence to support the idea that bismuth-implantation significantly affects the electrical properties of amorphous chalcogenide films. The investigation's findings propose theories for the changes observed, resulting in an enhanced comprehension of the subject matter and potential applications for these technologies.\n",
    "This academic paper presents a comprehensive study on the application of asymmetric loss functions (ALFs) and deep densely connected networks (DDCNs) in the detection of multiple sclerosis (MS) lesions using highly imbalanced medical image segmentation. Previous research studies have suggested that symmetric loss functions do not sufficiently capture the complexity of medical imaging data, which often contains an imbalanced distribution between the classes. To overcome this limitation, we propose a novel technique that combines ALFs and DDCNs to enhance the performance of medical image segmentation. Experiment results demonstrate significant improvement in the detection of MS lesions, both qualitatively and quantitatively, in comparison with conventional deep learning algorithms. Our research has significant potential for aiding clinical decision-making and advancing personalized medical treatment.",
    "This paper presents a novel hybrid approach to the segmentation of brain tumors in Magnetic Resonance Imaging (MRI) images. The study develops and applies a combination of image processing and machine learning techniques to improve the accuracy and efficiency of brain tumor detection. The proposed method integrates both supervised and unsupervised techniques, presenting an innovative fusion of region-based techniques and edge detection methods to optimize tumor demarcation. The performance of the proposed algorithm is evaluated through quantitative measurements based on precision, recall, and overall accuracy. Results demonstrate enhanced accuracy in the detection and segmentation of brain tumors, surpassing existing methods. This research contributes to the advancement of computer-aided diagnosis and assists in improving patient treatment planning and prognosis evaluation.",
    "This paper introduces spatially adaptive Multigrid Methods to efficiently solve fluid-structure interaction problems with temperature-induced fluctuations. A deep exploration is conducted on the fundamental challenge posed by these systems - the spatial scales that result from thermal fluctuations. The systems response is found to be sensitive to fluctuations at all scales, which go down to the mesh size in numerical simulations, thus making the conventional homogenization methods ineffective. This research deploys a hitherto unparalleled technique - spatially adaptive Stochastic Multigrid Method, to resolve the smallest scales only where crucial. The effectiveness of this method is compared with traditional techniques through computational simulations. Results show a significantly lower computational cost relative to the standard methods, solidifying the value of the proposed technique in accelerating the numerical solution of fluid-structure systems with thermal fluctuations.",
    "This paper explores the utilization of contrastive learning for medical image segmentation, particularly in cases where only limited annotations are available. The focus is on the simultaneous extraction of both global and local features from the images. The corresponding method employed, referred to as 'dual-branch network', is designed to recognize and learn the inherent variation between anatomical structures present in the images, whilst overcoming the challenges of limited data with high quality labels. Intrinsic to this method is a contrastive loss function that enhances the distinction of inter-class variations and intraclass similarities. Our results demonstrate that the proposed method significantly outperforms existing state-of-the-art segmentation methods. The findings of this study could have significant implications for the future of medical imaging, by improving segmentation accuracy and functionality in clinical settings.",
    "This paper provides a comprehensive review of flux braiding experiments, a critical area in the field of plasma physics and astrophysics. The study delves into the theoretical background, experimental setups, methodologies, and results of various flux braiding experiments conducted over the years. It also discusses the implications of these experiments in understanding magnetic reconnection, solar flares, and other space plasma phenomena. The paper further identifies gaps in current knowledge and suggests potential avenues for future research. This review serves as a valuable resource for researchers and students interested in the intricate dynamics of magnetic fields.",
    "This paper introduces a computer vision pipeline designed for automated determination of cardiac structure and function, as well as disease detection, through two-dimensional echocardiography. The goal of the system is to enhance the efficiency, accuracy and objectivity of echocardiogram interpretation, via automating assessment protocol. The pipeline was established by developing a machine learning algorithm that facilitates the extraction and analysis of key cardiac features. The study involves testing and validating the algorithm using a diverse set of echocardiograms, while comparing results with manual measurements taken by professionals. Experimental results demonstrate impressive robustness and accuracy in identifying various cardiac structures, evaluating their functions, and detecting cardiac diseases. This suggests an encouraging potential for the application of this pipeline in clinical settings, contributing to swift and objective cardiac analysis.",
    "This paper presents a novel approach to improve the generalization of deep learning models for overhead image segmentation tasks. The proposed method incorporates Getis-Ord Gi* statistics into the pooling layers of convolutional neural networks (CNNs), which is a significant departure from traditional max or average pooling methods. The Getis-Ord Gi* statistic is a local indicator of spatial association, and its integration into CNNs allows the model to capture and leverage spatial dependencies in overhead images. Experimental results on several benchmark datasets demonstrate that the proposed method outperforms state-of-the-art models in terms of segmentation accuracy and model generalization. This research opens up new avenues for incorporating spatial statistics into deep learning models for image segmentation tasks.",
    "This paper presents an innovative approach to automatic color image segmentation using a square elemental region-based seeded region growing and merging method. The proposed method aims to overcome the limitations of traditional image segmentation techniques by incorporating a square elemental region-based approach, which enhances the accuracy and efficiency of the segmentation process. The method begins with an initial segmentation into square elemental regions, followed by a seeded region growing process, and finally a merging process to combine similar regions. The performance of the proposed method is evaluated using various color images, demonstrating its effectiveness in achieving high-quality segmentation results. The method is robust, computationally efficient, and capable of handling images with complex structures and varying textures. This research contributes to the field of image processing by providing a novel method for automatic color image segmentation.",
    "This paper presents a comprehensive study on the Microscopic Response Method (MRM), a theoretical approach to understanding transport in systems with both topological and thermal disorder. The MRM is a powerful tool that allows for the calculation of transport coefficients in a wide range of systems, including those with complex disorder. The paper provides a detailed explanation of the method, its applications, and its limitations. It also presents a series of numerical simulations to validate the theory and demonstrate its effectiveness. The results show that the MRM can accurately predict transport behavior in systems with both topological and thermal disorder, making it a valuable tool for researchers in the field of condensed matter physics.",
    "This study presents a novel approach to semantic segmentation using hierarchical psychometric learning, a technique that integrates insights from psychology with machine learning methodologies. We propose a hierarchical model that employs psychometric properties to gain a deeper understanding of data structures and improve semantic segmentation results. In contrast to existing approaches, this method efficiently manages diverse features and high-dimensional data, thereby enhancing the accuracy of object recognition. Our approach is extensively evaluated and benchmarked against existing semantic segmentation techniques, and the results illustrate notable improvements in both accuracy and efficiency. The findings offer significant potential for a myriad of applications, including image understanding, localization, and scene understanding in computer vision.",
    "This paper presents a novel approach to video segmentation using Convolutional Gated Recurrent Networks (CGRNs). The proposed method leverages the strengths of convolutional neural networks (CNNs) and gated recurrent units (GRUs) to effectively segment videos into meaningful sections. The CGRNs are designed to capture both spatial and temporal dependencies in video data, which are crucial for accurate segmentation. Experimental results on several benchmark datasets demonstrate that our method outperforms existing state-of-the-art techniques in terms of segmentation accuracy and computational efficiency. The paper also provides insights into the inner workings of CGRNs, shedding light on their potential applications in other video analysis tasks.",
    "This research paper aims to examine the effectiveness of a random-detector-efficiency (RDE) countermeasure in a commercial system. The study has identified a significant flaw that reveals an unrealistic assumption of its functionality. By conducting a series of comprehensive tests, the researchers determined the limitations and vulnerabilities of the current RDE countermeasures. The study highlights the need to reassess the current assumption and to enhance the countermeasures in commercial systems for better security and efficiency. The findings provide valuable insights for relevant stakeholders and scientists in the specific field, adding substantially to the current knowledge base and future research prospectus.",
    "This paper provides a comprehensive numerical investigation on the interaction between magnetic dipole radiation and various substrates. By scrutinizing the influential role of substrates, the study offers novel insights into manipulating magnetic dipole radiation effectively. The approach, comprising of rigorous theoretical analysis and computational simulations, broadens our understanding of dipole-substrate interactions, particularly for high-frequency radiation. Additionally, the article discusses possible applications in areas such as metamaterials, nanoantennas, and optoelectronic devices. This extensive study significantly underlines the potential of substrates to shape and control magnetic dipole radiation, opening up new possibilities for the design and development of advanced photonic devices.",
    "This paper presents a novel approach to identifying key courses in an academic curriculum by utilizing data mining techniques on students' grades. The study aims to uncover the hidden patterns and relationships between different courses and their impact on students' academic performance. The data set comprises grades of thousands of students across various disciplines and semesters. The results reveal significant courses that contribute to the academic success of students. These findings can assist educational institutions in curriculum planning and development, and help students in making informed decisions about course selection. The paper also discusses the potential of data mining in the field of education and suggests directions for future research.",
    "This paper presents a detailed study on the generation of polarization entangled photon pairs in the telecom band via a Sagnac interferometer, under continuous wave (CW) pumping. By considering the impact of CW-pumping, a comprehensive understanding of the complex interplay between different photon pairs can be achieved. This study explores telecom bands as a possible platform for quantum communication systems, endowing them with increased flexibility and higher data transmission rates. The experimental results validate the theoretical model, showcasing substantial enhancement in the entanglement quality. This technology holds a vital place in furthering research in both applied areas like quantum cryptography and fundamental science like quantum physics.",
    "This paper presents a novel approach for Synthetic Aperture Sonar (SAS) image segmentation, utilizing an iterative, deep, and unsupervised learning method. The aim is to improve the automatic recognition and classification of objects in underwater scenarios, a task that poses significant challenges due to the complex nature of the undersea environment. Our method employs a deep convolutional autoencoder model to rigorously learn a set of high-level feature representations and an iterative, unsupervised clustering technique to effectively segment the SAS images. Experimental results, conducted on real-world data, demonstrate the superiority of our proposed method over conventional techniques in terms of segmentation accuracy and processing efficiency. The applicability of this approach is significant, with potential uses in a wide range of marine research and industrial applications including seafloor mapping, underwater archaeology, and mine detection.",
    "This paper introduces Convolutional Oriented Boundaries (COB), a novel method for image segmentation that leverages the power of convolutional neural networks (CNNs). COB combines the strengths of both region-based and boundary-based methods, providing a unified approach to image segmentation. The paper demonstrates how COB can be applied to a variety of high-level tasks, including object detection, semantic segmentation, and instance segmentation. Experimental results show that COB outperforms existing methods on several benchmark datasets, highlighting its effectiveness and versatility. The paper also discusses potential applications of COB in other areas of computer vision, suggesting that it could serve as a powerful tool for a wide range of image analysis tasks.",
    "This academic paper focuses on the development and evaluation of Fully Transformer Networks (FTN) for semantic image segmentation. Our approach effectively utilizes transformer models, traditionally employed in natural language processing, for pixel-level image recognition tasks. Unlike the standard Convolutional Neural Networks (CNNs), the FTN leverages the global self-attention mechanisms of the transformer model to capture more complex dependencies between pixels. The research presents significant empirical evidence demonstrating the effectiveness of the FTN, especially in architectural and scene parsing benchmarks. The performance was evidenced to surpass existing CNN-based semantic segmentation approaches. This paper elucidates on the design, implementation, and optimization processes of the FTN, potentially heralding a new era in semantic image segmentation studies.",
    "This paper presents a comprehensive study on the electrical transport in ABC-trilayer graphene, a material with unique electronic properties. The research focuses on the direct observation of a gate tunable band-gap, a feature that could revolutionize the field of nanoelectronics. Using advanced experimental techniques, we demonstrate that the band-gap in ABC-trilayer graphene can be effectively controlled by an external electric field. This discovery opens up new possibilities for the development of graphene-based electronic devices with tunable properties. The results of this study provide valuable insights into the electronic structure of ABC-trilayer graphene and contribute to the broader understanding of the physics of low-dimensional materials.",
    "This paper presents a novel approach to enhance the safety and reliability of deep learning applications in healthcare, specifically focusing on the quantification of biomarker uncertainty in neural network predictions. The study introduces a new methodology that accurately measures the uncertainty associated with the prediction of biomarkers, thereby improving the reliability of diagnostic and prognostic tools. The proposed method is validated using various datasets and compared with existing techniques, demonstrating superior performance in terms of accuracy and precision. The results suggest that the integration of this method can significantly improve the safety and efficacy of deep learning applications in healthcare, paving the way for more reliable and trustworthy AI-based medical systems.",
    "This paper presents a comprehensive study on D-branes and defects in Liouville and Toda field theories. It delves into the intricate relationship between these two entities, providing a detailed analysis of their properties and interactions. The paper also explores the role of D-branes in the context of string theory, and how they contribute to our understanding of the universe's fundamental structure. Additionally, it discusses the implications of defects in these field theories, and how they can potentially influence the behavior of D-branes. The findings of this study contribute to the ongoing discourse in theoretical physics, offering new insights and perspectives on these complex phenomena.",
    "This paper introduces Sem-GAN, a novel Generative Adversarial Network (GAN) approach to the task of image-to-image translation that ensures semantic consistency between the input and the output. This innovative neural network model addresses inherent challenges in maintaining consistency in attributes and structures of images during the translation process. Our results demonstrate that Sem-GAN outperforms state-of-the-art models in quantitative evaluations, offering higher translation accuracy while maintaining semantic consistency. Furthermore, the proposed method produces visually impressive results on various translation tasks, including object transfiguration, season transfer, and photo-to-cartoon translation. The paper provides insights into the model's design, training, and evaluation criteria, contributing to further advancements in image-to-image translation research.",
    "This paper investigates the low-frequency 1/f noise in MoS2 thin-film transistors, comparing single and multilayer structures. The study reveals that the noise power spectral density in these devices is inversely proportional to frequency, consistent with the 1/f noise behavior. The noise magnitude was found to be significantly higher in single-layer devices compared to multilayer structures, attributed to the higher trap density in single-layer MoS2. The results also indicate that the noise in these devices is predominantly due to carrier number fluctuations. This research provides valuable insights into the noise characteristics of MoS2 thin-film transistors, which is crucial for their potential applications in electronic devices.",
    "This paper presents a novel proposal for a real-time predictive maintenance platform that utilizes 3D printing technology for business vehicles. The proposed platform aims to enhance the efficiency and reliability of maintenance processes, reduce downtime, and extend the lifespan of business vehicles. The platform integrates advanced technologies such as Internet of Things (IoT), Machine Learning (ML), and 3D printing to predict potential failures and perform necessary repairs in real-time. The paper discusses the design and implementation of the platform, its potential benefits, and the challenges encountered during its development. The results from preliminary tests demonstrate the platform's effectiveness in improving maintenance procedures and reducing operational costs. This research contributes to the growing body of knowledge on the application of 3D printing and predictive analytics in vehicle maintenance.",
    "This paper examines the relationship between financial market structure and the real economy by comparing the performance of different clustering methods in identifying sectors that are financially and economically similar. The study uses a dataset of stock prices and economic indicators for a set of firms across various industries and applies three clustering algorithms - K-means, hierarchical clustering, and density-based spatial clustering of applications with noise (DBSCAN) - to group the firms into sectors. The results show that the clustering methods identify similar sectors across different algorithms, but with some variations in the composition of firms within each sector. The study also finds that the clustering methods are able to identify sectors that are financially and economically similar, as measured by the correlation of stock prices and economic indicators within each sector. The results have implications for the analysis of financial market structure and the real economy, as they suggest that clustering methods can be used to identify sectors that are likely to be affected by similar economic shocks or policy interventions. The study contributes to the literature on financial market structure and the real economy by providing a novel approach to sector identification and highlighting the importance of considering the relationship between financial and economic variables in analyzing the impacts of economic shocks and policy interventions.",
    "In this paper, we propose a novel approach to semantic segmentation known as attention-guided supervised contrastive learning (AGSCL). This method combines the strengths of both supervised contrastive learning and attention mechanisms to improve visual feature representation and enhance segmentation accuracy.\n\nSupervised contrastive learning has emerged as a powerful tool for self-supervised learning in computer vision tasks, but it relies heavily on large amounts of labeled data, which may be difficult or expensive to obtain. Attention mechanisms, on the other hand, have proven effective in selectively focusing on relevant regions in images, but they require careful design and tuning. AGSCL addresses these limitations by integrating an attention module into the contrastive loss function, allowing the model to learn richer representations that capture semantically meaningful features while reducing the need for annotated data.\n\nThe proposed framework consists of two main components: an encoder network followed by a projection head, and a contrastive loss function modified with the attention mechanism. The encoder network is trained to encode input images into latent vectors that preserve spatial hierarchies, while the projection head generates pseudo labels based on the predicted class probabilities. The attention module computes a weighted sum of the latent vectors using attention weights learned from the same dataset, enhancing the importance of instances within each mini-batch that are similar in appearance and context. These attended latent vectors then serve as inputs to the contrastive loss function, which encourages positive pairs (i.e., different views of the same instance) to stay close together while pushing negative ones apart.\n\nWe evaluate our method extensively on several benchmark datasets, including Cityscapes, PASCAL VOC, and COCO. Our experiments demonstrate that AGSCL outperforms traditional supervised contrastive learning and achieves competitive performance against state-of-the-art semi-supervised segmentation methods, despite requiring significantly fewer annotations. Furthermore, the incorporation of attention allows the model to better handle occlusions, clutter, and intra-class variations. Visualizations of attention maps reveal insightful patterns that highlight the effectiveness of localizing salient regions.\n\nOur work not only advances the state-of-the",
    "In this paper, we propose a novel approach for 3D biomedical image segmentation that combines fully convolutional neural networks (FCNs) and recurrent neural networks (RNNs). Our proposed method leverages the strengths of both FCNs and RNNs to improve the accuracy and efficiency of 3D image segmentation.\n\nFCNs have shown great success in image segmentation tasks due to their ability to learn rich feature representations from raw pixel data. However, they are limited by their inability to model complex spatial relationships between pixels. On the other hand, RNNs are well-suited for modeling sequential data and can capture long-range dependencies, but they struggle with processing large datasets and require significant computational resources.\n\nOur proposed approach addresses these limitations by combining FCNs and RNNs into a single network architecture. The FCN component is used to extract high-level features from the input data, while the RNN component refines the segmentation results by modeling the spatial relationships between neighboring voxels. We implement our approach using a popular deep learning framework and evaluate it on several publicly available 3D biomedical image datasets.\n\nThe experimental results demonstrate that our combined FCN-RNN approach outperforms state-of-the-art methods in terms of segmentation accuracy and computational efficiency. Specifically, we achieve an average dice similarity coefficient of 0.85 on the BraTS dataset, which represents a 12% improvement over the next best performing method. Additionally, our approach reduces the computational cost by a factor of 4 compared to traditional FCN-based methods.\n\nWe also perform a series of ablation studies to analyze the contributions of each network component and provide insights into the working mechanism of our approach. The results suggest that the combination of FCNs and RNNs is essential for achieving optimal performance, as neither component alone can match the performance of the full network.\n\nIn conclusion, our work demonstrates the potential of combining FCNs and RNNs for 3D biomedical image segmentation. The proposed approach has important implications for various medical applications, such as tumor detection, lesion characterization, and",
    "In this paper, we propose a novel approach for semantic segmentation of very fine resolution urban scene images, titled Bilateral Awareness Network (BAN). BAN combines the strengths of transformer and convolutional neural networks (CNNs) to improve the accuracy and efficiency of semantic segmentation.\n\nThe transformer architecture has shown great success in various natural language processing tasks, but its application in computer vision tasks is limited due to its inability to process spatial information. On the other hand, CNNs are well-suited for image processing tasks, but their receptive field is limited, which hinders their ability to capture long-range dependencies.\n\nTo address this issue, we propose a bilateral attention mechanism that integrates the strengths of both transformer and CNNs. The bilateral attention mechanism allows the network to attend to both local and global features, enabling it to capture both fine-grained details and long-range dependencies.\n\nThe BAN architecture consists of a CNN backbone, a transformer encoder, and a bilateral attention module. The CNN backbone extracts local features, which are then fed into the transformer encoder to capture long-range dependencies. The bilateral attention module is used to combine the local and global features, allowing the network to focus on the most relevant information.\n\nWe evaluate the BAN on several benchmark datasets, including Cityscapes, PASCAL VOC, and CamVid. The results show that BAN outperforms state-of-the-art methods in terms of accuracy and efficiency. Specifically, BAN achieves an mIoU of 81.8% on Cityscapes, which is 3.5% higher than the previous state-of-the-art method.\n\nWe also conduct several ablation studies to demonstrate the effectiveness of the bilateral attention mechanism. The results show that the bilateral attention mechanism improves the performance of the network by 10.3% compared to using only local or global features.\n\nIn conclusion, this paper proposes a novel approach for semantic segmentation of very fine resolution urban scene images using",
    "This paper addresses the problem of designing robust controllers for regular linear systems with infinite-dimensional exosystems. The exosystems are modeled as infinite-dimensional systems with known inputs and outputs, and the goal is to design a controller that stabilizes the system and achieves a desired performance in the presence of perturbations and uncertainties.\n\nThe paper presents a new approach to address this problem, which is based on the use of techniques from robust control theory and calculus of variations. The approach involves solving an optimization problem that minimizes a cost function that measures the performance of the system, subject to constraints on the stability and robustness of the system.\n\nThe paper shows that the optimization problem can be solved using a combination of convex optimization and feedback control techniques, and presents a numerical algorithm to implement the approach. The algorithm is illustrated through simulations and experimental results on several examples of regular linear systems with infinite-dimensional exosystems.\n\nThe main contribution of the paper is the development of a systematic method for designing robust controllers for regular linear systems with infinite-dimensional exosystems. The method is based on the use of optimization techniques and provides a way to trade off performance and robustness in the presence of perturbations and uncertainties. The paper demonstrates the effectiveness of the method through simulations and experimental results, and highlights its potential for applications in a variety of fields, including chemical processes, power systems, and automotive control.",
    "This paper proposes a novel variational image segmentation model that incorporates normalized cuts, adaptive similarity, and spatial regularization. The proposed model aims to improve the accuracy and efficiency of image segmentation by addressing several limitations in traditional methods, including the sensitivity to parameter settings and the lack of consideration for spatial information.\n\nThe proposed model is based on a variational framework, which formulates image segmentation as an optimization problem that minimizes an energy functional. The energy functional combines a data fidelity term with a regularization term that enforces the smoothness of the segmentation boundary. To address the limitation of traditional methods, we introduce an adaptive similarity measure that takes into account both pixel-level and region-level features. We also propose a spatial regularization term that captures the spatial information of the image and encourages consistent segmentation results.\n\nThe normalized cut algorithm is used to optimize the energy functional, which leads to a more robust and efficient segmentation process. Experimental results on several benchmark datasets demonstrate the superior performance of our proposed method compared to state-of-the-art segmentation techniques. Specifically, our method shows improved accuracy and robustness across different datasets, and it outperforms traditional methods in terms of computational efficiency.\n\nOverall, this paper makes significant contributions to the field of image segmentation by introducing a novel variational model that integrates normalized cuts, adaptive similarity, and spatial regularization. Our proposed method has important implications for various applications, such as object recognition, tracking, and scene understanding, where accurate image segmentation is a critical step.",
    "In this paper, we introduce a new statistical measure, the three-point phase correlation, to quantify the non-linear large-scale structure of a system. The three-point phase correlation is a measure of the correlation between the phases of three waves at different scales, and is designed to capture the non-linear interactions between waves that are not captured by traditional two-point correlation measures.\n\nWe apply the three-point phase correlation to a variety of systems, including turbulent flows, magnetic fields, and gravitational waves. In each case, we find that the three-point phase correlation reveals important features of the non-linear large-scale structure that are not captured by traditional two-point correlation measures.\n\nIn turbulent flows, we find that the three-point phase correlation is able to capture the non-linear interactions between turbulent eddies, which are not captured by traditional two-point correlation measures. In magnetic fields, we find that the three-point phase correlation is able to capture the non-linear interactions between magnetic field lines, which are not captured by traditional two-point correlation measures. In gravitational waves, we find that the three-point phase correlation is able to capture the non-linear interactions between gravitational waves, which are not captured by traditional two-point correlation measures.\n\nWe also explore the relationship between the three-point phase correlation and other statistical measures, such as the power spectrum and the bispectrum. We find that the three-point phase correlation is related to, but distinct from, these other measures, and provides a unique perspective on the non-linear large-scale structure of a system.\n\nOverall, the three-point phase correlation is a powerful tool for analyzing the non-linear large-scale structure of a system, and has important implications for our understanding of a wide range of physical phenomena.",
    "Root segmentation in soil is a crucial step in plant phenotyping, as it allows for accurate measurement of root traits and enables studies on root system architecture and function. However, manual segmentation of roots in soil is a time-consuming and labor-intensive process, limiting the throughput and accuracy of root phenotyping studies. In this paper, we propose a novel approach for automated segmentation of roots in soil using a deep learning technique called U-Net.\n\nOur approach involves imaging the soil-root system using X-ray computed tomography (CT) and processing the images through a U-Net architecture to identify and separate the roots from the surrounding soil. We evaluated the performance of our method on a dataset of 30 CT scans of soil-root systems and compared the results to manual segmentation by an expert.\n\nOur results show that the U-Net-based approach accurately segmented the roots in soil with a high degree of accuracy (mean intersection over union = 0.87). The approach was also able to identify and separate individual roots, allowing for detailed analysis of root system architecture. We found that the U-Net-based approach was more efficient and accurate than manual segmentation, with a processing time per image of approximately 10 minutes compared to several hours for manual segmentation.\n\nOur study demonstrates the potential of using deep learning techniques for automated segmentation of roots in soil, which can greatly improve the efficiency and accuracy of root phenotyping studies. The approach can be further refined and adapted for use in various soil types and root systems, enabling researchers to study root-soil interactions and plant-microbe interactions in a more efficient and accurate manner.",
    "This paper presents a novel approach to image segmentation, Learning to Segment from Scribbles using Multi-scale Adversarial Attention Gates (MSAAG). The proposed method leverages the power of adversarial attention mechanisms to learn a robust and accurate segmentation model from sparse annotated data.\n\nExisting methods rely heavily on fully supervised learning, requiring large amounts of manually labeled data. In contrast, MSAAG uses scribble annotations, which are significantly easier and faster to obtain, yet still provide valuable information about the location of objects in an image. By incorporating multi-scale features and adaptive attention gates, our model is able to effectively focus on the most relevant regions of an image and learn rich semantic representations.\n\nThe key innovation of MSAAG lies in its ability to integrate spatial and channel-wise attention into a single module. This enables the model to learn both local and global context, leading to improved performance compared to traditional attention-based approaches. Additionally, we introduce a new loss function that encourages the model to produce smooth and consistent segmentation masks, further enhancing overall accuracy.\n\nExtensive experiments demonstrate that MSAAG outperforms state-of-the-art weakly supervised segmentation models on several benchmark datasets. Our approach achieves superior performance with fewer annotated examples, exhibiting its capability to efficiently leverage limited annotation resources. Moreover, we perform ablation studies to analyze the effectiveness of different components within the MSAAG framework, providing insights into the contributions of each component to the overall performance gain.\n\nIn summary, this work introduces a novel image segmentation approach that leverages scribble annotations and advances in adversarial attention mechanisms to achieve high accuracy with minimal manual effort. The proposed MSAAG model has important implications for applications where labeling data is costly or challenging, such as medical imaging, autonomous driving, and robotics.",
    "This paper provides a comprehensive set of lecture notes on Ridge Regression, a widely used linear regression technique in statistical modeling. The notes cover the key concepts and techniques of Ridge Regression, including the mathematical formulation, the optimization algorithm, and the interpretation of results.\n\nThe paper starts with an introduction to linear regression and the problem of multicollinearity, which motivates the need for regularization techniques like Ridge Regression. The definition and explanation of Ridge Regression are then presented, along with the mathematical formulation of the method. The paper also discusses the difference between Ridge Regression and other regularization methods, such as Lasso Regression.\n\nThe optimization algorithm for Ridge Regression is described in detail, including the use of gradient descent and the Armijo-Goldstein rule. The paper also discusses the selection of the regularization parameter and its impact on the model's performance.\n\nThe paper then presents various applications of Ridge Regression, including linear regression with multiple covariates, generalized linear models, and robust standard errors. The paper also compares the performance of Ridge Regression with other regression methods through simulations and real-data examples.\n\nFinally, the paper concludes by summarizing the main points covered in the lecture notes and highlighting the advantages and limitations of Ridge Regression. The paper also suggests directions for future research and provides additional resources for readers interested in learning more about Ridge Regression.\n\nOverall, these lecture notes provide a thorough introduction to Ridge Regression, making them suitable for students, researchers, and practitioners interested in using this powerful technique for linear regression analysis.",
    "This paper presents a novel approach to unsupervised image segmentation based on differentiable feature clustering. The proposed method leverages the flexibility of differentiable clustering algorithms to learn a rich representation of the input data, which is then used to segment the images. The key insight is to treat the clustering process as a continuous optimization problem, rather than a discrete optimization problem, allowing the algorithm to explore the space of possible clusters smoothly and efficiently.\n\nThe proposed method is evaluated on several benchmark datasets, including CIFAR-10 and SVHN, and shows superior performance compared to traditional unsupervised segmentation methods, such as k-means and hierarchical clustering. In addition, the method is able to learn a hierarchical representation of the data, allowing for both coarse-grained and fine-grained segmentations to be computed from the same model.\n\nThe main contribution of this paper is the introduction of a new unsupervised learning algorithm for image segmentation, which combines the strengths of differentiable clustering and feature learning. The proposed method has important implications for a wide range of computer vision tasks, including object recognition, tracking, and scene understanding.\n\nThe paper is organized as follows: In section 2, we review related work in unsupervised image segmentation and differentiable clustering. In section 3, we present the proposed method in detail, including the algorithm's architecture and optimization process. In section 4, we provide experimental results demonstrating the effectiveness of the proposed method. Finally, in section 5, we conclude the paper with a discussion of the implications and future directions of the proposed approach.",
    "In this paper, we explore thin-disk laser pump schemes for achieving high power output with a large number of passes and moderate pump source quality. We present a comprehensive analysis of various pump schemes, including conventional single-pass and recirculating configurations, as well as novel multi-pass designs that utilize disk amplifiers. Our results show that optimized multi-pass schemes can achieve significantly higher powers than traditional single-pass configurations, while also providing improved beam quality and reduced thermal loading. Moreover, we demonstrate that modest improvements in pump source quality can lead to substantial gains in overall performance, highlighting the potential benefits of advanced pump technology developments. Our findings have important implications for the design and development of high-power laser systems, particularly those employed in fields such as material processing, spectroscopy, and nonlinear optics.",
    "In this paper, we present a novel approach to train deep neural networks for segmentation of neuronal structures in microscopy images. Our approach, called Icon, combines the strengths of interactive segmentation and deep learning to achieve accurate and efficient segmentation of neuronal structures.\n\nIcon is designed to address the challenges of segmenting neuronal structures in large-scale microscopy datasets, where manual annotation is time-consuming and expensive. Our approach leverages user interaction to iteratively refine the segmentation output of a deep neural network, allowing for accurate segmentation of complex neuronal structures.\n\nWe evaluate Icon on several benchmark datasets and compare its performance to state-of-the-art segmentation methods. Our results show that Icon achieves high accuracy and outperforms other methods in terms of efficiency and scalability. We also demonstrate the versatility of Icon by applying it to various types of neuronal structures and imaging modalities.\n\nIcon has the potential to significantly improve the throughput and accuracy of neuronal structure segmentation in various fields, including neuroscience, drug discovery, and regenerative medicine. Its interactive nature also makes it an ideal tool for experts to validate and correct segmentation results, ensuring the highest accuracy in downstream analyses.\n\nOur work presents a significant step forward in the development of deep learning methods for segmentation of neuronal structures, and we believe that Icon will be a valuable tool for researchers and scientists working in this field.",
    "In this paper, we propose a novel approach to medical image segmentation using a spatial guided self-supervised clustering network (SGSCN). Our method leverages the inherent spatial structure in medical images to learn a robust and accurate representation of the underlying anatomy without requiring manual annotation.\n\nThe SGSCN is designed as a deep neural network that jointly learns a spatial embedding and a clustering algorithm. The network takes unlabelled medical images as input and outputs a set of clusters, each representing a distinct anatomical structure. The spatial embedding is learned by minimizing a loss function that encourages the network to group pixels that are close in space and belong to the same anatomical structure.\n\nWe evaluate our method on several publicly available datasets of magnetic resonance imaging (MRI) scans and compare it to state-of-the-art methods. Our results show that the SGSCN outperforms traditional supervised learning approaches, which require manually annotated data, and achieves high accuracy on various tasks such as brain structure segmentation and tumor detection.\n\nOur main contribution is the introduction of a spatial guidance mechanism into the self-supervised clustering process, which enables the network to learn a meaningful representation of the anatomy from unlabelled data. This makes our method particularly useful for applications where annotated data is scarce or difficult to obtain.\n\nOverall, our work demonstrates the potential of self-supervised learning for medical image segmentation and highlights the importance of incorporating domain knowledge into the design of deep learning models for medical image analysis.",
    "In this paper, we explore the challenges and opportunities of multi-modal learning, where students learn through multiple modalities, such as visual, auditory, and kinesthetic. While research has shown that multi-modal learning can lead to better learning outcomes, the reality is that many teachers are trained to teach in a single modality, leading to a mismatch between the teacher's teaching style and the students' learning styles.\n\nTo address this challenge, we propose a novel approach called Uni-Modal Teachers (UMT), which leverages the strengths of both human teachers and AI-powered adaptive learning systems. UMT enables human teachers to effectively teach students with diverse learning styles by providing personalized, adaptive, and synchronized learning materials, activities, and assessments that cater to each student's unique needs.\n\nWe evaluate the effectiveness of UMT through a comprehensive experiment involving 500 students and 20 teachers across different subjects and grade levels. Our results show that UMT significantly improves learning outcomes, with students demonstrating higher levels of engagement, motivation, and understanding. We also find that teachers experience reduced workload and stress, as they are able to focus on teaching and mentoring, rather than on creating and adapting learning materials.\n\nOur findings have important implications for education, as they demonstrate that it is possible to improve multi-modal learning by leveraging the strengths of both human teachers and AI-powered adaptive learning systems. The UMT approach has the potential to revolutionize the way we teach and learn, and could help to address the growing demand for personalized education.",
    "In this paper, we present a novel pseudospectral method for solving partial differential equations (PDEs) that is high-order, stable, and efficient. The method is based on barycentric Gegenbauer quadratures, which are used to approximate the solution of the PDEs in a collocation format. The use of barycentric weights allows for a more accurate representation of the solution at the collocation points, leading to improved accuracy and stability of the method.\n\nThe proposed method is tested on a variety of benchmark problems, including the one-dimensional advection equation and the two-dimensional incompressible Navier-Stokes equations. The results show that the method is able to accurately capture the dynamics of the problems and is more efficient than traditional pseudospectral methods. The method is also shown to be robust and well-conditioned, with a convergence rate that is independent of the number of collocation points.\n\nThe key advantage of the proposed method is its ability to achieve high-order accuracy while still using a relatively small number of collocation points. This makes it particularly useful for problems where the solution is smooth, but the computational cost of high-order methods is prohibitive. Additionally, the use of barycentric weights allows for a more flexible choice of collocation points, which can be important in problems with complex geometries or boundary conditions.\n\nOverall, the proposed pseudospectral method using barycentric Gegenbauer quadratures represents a significant advancement in the field of numerical partial differential equations, providing a high-order, stable, and efficient solution technique that can be used to solve a wide range of problems in science and engineering.",
    "In this paper, we propose a novel approach to image segmentation in optical environments using quantum edge detection. Traditional edge detection methods are limited by their inability to effectively handle images with low contrast or noisy edges, which can lead to inaccurate segmentation results. By leveraging the principles of quantum computing, we demonstrate a quantum edge detection algorithm that can accurately detect edges in images with low contrast or noisy edges, resulting in improved image segmentation accuracy.\n\nOur approach utilizes the concept of quantum entanglement to enhance the sensitivity of edge detection, allowing for the detection of edges that are not visible using traditional methods. We demonstrate the effectiveness of our approach through simulations and experiments using a quantum computer, and show that our method outperforms traditional edge detection methods in terms of accuracy and robustness.\n\nThe main contribution of this paper is the development of a quantum edge detection algorithm that can accurately detect edges in images with low contrast or noisy edges. Our algorithm is based on a novel quantum entanglement-based approach that enhances the sensitivity of edge detection, allowing for the detection of edges that are not visible using traditional methods.\n\nThe paper is organized as follows: In section 1, we provide an introduction to the problem of image segmentation and edge detection, and discuss the limitations of traditional methods. In section 2, we provide a brief overview of quantum computing and the concept of quantum entanglement. In section 3, we describe our quantum edge detection algorithm and its implementation on a quantum computer. In section 4, we present the results of our simulations and experiments, and compare the performance of our method with traditional edge detection methods. Finally, in section 5, we conclude with a discussion of the implications of our results and future directions for research.\n\nOur work has important implications for a wide range of applications, including medical imaging, object recognition, and autonomous vehicles. By providing a more accurate and robust method for image segmentation, we can improve the performance of these applications and enable new capabilities that were previously not possible.",
    "In this paper, we explore the relationship between Floer theory and reduced cohomology on open manifolds. We begin by introducing the basic definitions and concepts of Floer theory, including the notion of a Floer chain complex and its relation to the symplectic geometry of the manifold. We then turn our attention to the study of reduced cohomology, discussing the main results and techniques used in its definition and computation.\n\nOur main result is the construction of a direct sum decomposition of the singular cohomology groups of an open manifold into a Floer-theoretic piece and a reduced cohomology piece. This decomposition provides a new perspective on the structure of the cohomology ring of an open manifold, shedding light on the interactions between the topological, geometrical, and symplectical properties of the space.\n\nWe demonstrate the power of this decomposition by applying it to several classes of open manifolds, including cotangent bundles, symplectic balls, and certain non-compact semifree orbifolds. Our analysis reveals interesting patterns and structures that were previously overlooked or unclear, leading to a deeper understanding of these spaces from both a geometric and dynamical viewpoint.\n\nAs an additional consequence of our work, we establish novel connections between Floer theory and other areas of mathematics, such as topology, algebraic geometry, and representation theory. These connections not only place our findings within the broader context of contemporary mathematical research but also suggest new directions for further investigation and potential applications.\n\nIn summary, this paper contributes significantly to our understanding of the interplay between symplectic dynamics, algebraic topology, and geometric analysis on open manifolds. By combining the tools of Floer theory with the study of reduced cohomology, we unveil previously hidden details about the structure and behavior of various important examples of open manifolds, opening up exciting possibilities for future investigations and advancing our grasp of the rich universe of symplectic and algebraic phenomena.",
    "The paper \"Multi-environment model estimation for motility analysis of Caenorhabditis Elegans\" presents a novel approach to analyzing the motility behavior of the nematode worm Caenorhabditis Elegans in multiple environments. The worm's motility behavior is essential for its survival and is influenced by various environmental factors, such as temperature, humidity, and presence of chemicals.\n\nTraditional methods for analyzing the motility behavior of C. Elegans are limited to a single environment, which does not accurately reflect the worm's behavior in different environments. In this study, we propose a multi-environment model estimation approach that enables the analysis of the worm's motility behavior across multiple environments.\n\nOur approach uses a neural network-based model to estimate the relationship between the worm's motility behavior and various environmental factors. We train the model using a large dataset of C. Elegans' motility behavior in different environments and validate its performance using experimental data.\n\nThe results show that our approach accurately estimates the worm's motility behavior in multiple environments and outperforms traditional methods. We also demonstrate the applicability of our approach in identifying optimal environments for C. Elegans' motility and in predicting the effects of environmental changes on the worm's behavior.\n\nOur findings have important implications for the study of C. Elegans' behavior and its application in various fields, such as drug discovery, toxicology, and environmental monitoring. The proposed approach can be extended to other organisms, enabling the analysis of their behavior in multiple environments and improving our understanding of the interactions between organisms and their environments.",
    "In this paper, we present a novel approach for computing the ground and first excited states of the fractional Schrdinger equation in an infinite potential well. The fractional Schrdinger equation, which is a generalization of the classical Schrdinger equation, has gained increasing attention in recent years due to its ability to describe the behavior of non-local systems. However, solving the fractional Schrdinger equation in the presence of an infinite potential well has proven to be a challenging task, particularly for the ground and first excited states.\n\nOur approach uses a combination of numerical and analytical techniques to compute the ground and first excited states of the fractional Schrdinger equation in an infinite potential well. We first reformulate the problem in terms of a fractional differential equation, which we then solve using a numerical method. We also derive an analytical expression for the ground state energy and wave function, which we compare to our numerical results.\n\nOur results show that the ground state energy and wave function of the fractional Schrdinger equation in an infinite potential well are significantly different from those of the classical Schrdinger equation. In particular, we find that the ground state energy of the fractional Schrdinger equation is lower than that of the classical Schrdinger equation, and that the wave function of the fractional Schrdinger equation has a more spread-out structure.\n\nWe also compute the first excited state of the fractional Schrdinger equation, which is found to be much more sensitive to the parameter of the potential well than the ground state. Our results provide new insights into the behavior of non-local systems in the presence of an infinite potential well, and demonstrate the power of the fractional Schrdinger equation for modeling such systems.\n\nOverall, our work represents a significant step forward in the study of the fractional Schrdinger equation in the presence of an infinite potential well, and demonstrates the potential of this equation for describing the behavior of non-local systems in a wide range of physical and mathematical contexts.",
    "This paper proposes a novel approach to estimating the receiver operating characteristic (ROC) curve, a widely used metric for evaluating the performance of binary classification models. Existing methods for estimating the ROC curve often suffer from non-smoothness, which can lead to inaccurate inference and visualization. In this paper, we propose a new method that leverages log-concave density estimates to construct a smooth ROC curve estimator.\n\nOur approach is based on the observation that the ROC curve can be represented as the boundary of a set of log-concave densities. Using this representation, we develop a method to estimate the ROC curve by fitting a log-concave density to the data and then computing the boundary of the resulting probability simplex. We show that our estimator has several desirable properties, including smoothness, consistency, and asymptotic normality.\n\nWe demonstrate the effectiveness of our method through simulations and real-data examples, comparing our estimator to existing methods in terms of smoothness, accuracy, and computational efficiency. Our results show that our estimator exhibits superior performance in terms of smoothness and accuracy, while also being computationally efficient.\n\nOur paper makes an important contribution to the field of statistics and machine learning by providing a novel approach to estimating the ROC curve that is smooth, consistent, and asymptotically normal. The proposed method has important implications for a wide range of applications, including medical diagnosis, image classification, and decision-making under uncertainty.",
    "In this paper, we present a theoretical framework for understanding the phenomenon of weakly nonlinear self-sustained detonations. Detonations are powerful explosive events that occur when a combustible medium undergoes a rapid chemical reaction, leading to a rapid release of energy and a shock wave that can propagate over long distances.\n\nSelf-sustained detonations are a specific type of detonation that maintain their strength over time, without any external energy input. They are characterized by a feedback loop where the energy released by the chemical reaction heats the medium, which in turn accelerates the reaction rate, sustaining the detonation.\n\nWeakly nonlinear self-sustained detonations are a regime of self-sustained detonations where the reaction rate is slightly affected by the temperature of the medium. This regime is characterized by a small perturbation in the reaction rate that grows over time, leading to a periodic or quasi-periodic behavior.\n\nIn this paper, we develop a theory that describes the dynamics of weakly nonlinear self-sustained detonations. We use a combination of analytical and numerical methods to study the behavior of the system and demonstrate the existence of periodic and quasi-periodic solutions. We show that these solutions are stable and can be sustained over long times, providing a theoretical explanation for the observed behavior of weakly nonlinear self-sustained detonations.\n\nOur results have important implications for the understanding of nonlinear phenomena in combustion and chemical reactions. In particular, they provide a new perspective on the mechanisms that control the behavior of self-sustained detonations, and highlight the importance of weak nonlinearities in determining the long-term behavior of these systems.\n\nThe paper is organized as follows: In section 2, we introduce the mathematical model for self-sustained detonations and discuss the weakly nonlinear regime. In section 3, we present the analytical and numerical methods used to study the dynamics of the system. In section 4, we present the results of our analysis, including the existence and stability of periodic and quasi-periodic solutions. Finally, in section 5, we conclude with a discussion of the",
    "In this paper, we present a novel approach for efficiently computing piecewise flat embeddings (PFEs) for data clustering and image segmentation. PFEs are a type of nonlinear dimensionality reduction technique that can be used to identify clusters and separate objects in high-dimensional data. However, computing PFEs can be computationally expensive, especially for large datasets.\n\nOur proposed approach leverages a combination of optimization techniques and data structures to efficiently compute PFEs. We introduce a new algorithm that iteratively updates the embedding space using a block-based approach, which significantly reduces the computational complexity of the algorithm. We also propose a novel data structure, called the Piecewise Flat Embedding Tree (PFET), which enables efficient querying and updating of the embedding space.\n\nWe evaluate our approach on several benchmark datasets and compare it to state-of-the-art methods. Our results show that our approach achieves competitive performance in terms of clustering accuracy and segmentation quality, while providing a significant speedup in computation time. We also demonstrate the scalability of our approach by applying it to large-scale datasets.\n\nOur main contributions can be summarized as follows:\n\n* We propose a novel approach for efficiently computing piecewise flat embeddings (PFEs) for data clustering and image segmentation.\n* We introduce a new algorithm that iteratively updates the embedding space using a block-based approach, which significantly reduces the computational complexity of the algorithm.\n* We propose a novel data structure, called the Piecewise Flat Embedding Tree (PFET), which enables efficient querying and updating of the embedding space.\n* We evaluate our approach on several benchmark datasets and compare it to state-of-the-art methods, demonstrating competitive performance and significant computational savings.\n\nOverall, our work provides a new and efficient way to compute PFEs, which can be useful in a wide range of applications, including data mining, image processing, and machine learning.",
    "In this paper, we present a novel approach for efficient transmission and accurate segmentation of 3D medical images in the clouds using machine vision guided 3D medical image compression. With the increasing use of 3D medical imaging technologies, such as magnetic resonance imaging (MRI), computed tomography (CT), and ultrasound, the need for efficient and accurate transmission and segmentation of large volumes of 3D medical data has become more important than ever.\n\nCurrent compression methods for 3D medical images often suffer from high computational complexity, poor image quality, and limited accuracy in segmentation. To address these challenges, we propose a machine vision guided 3D medical image compression approach that leverages the power of deep learning algorithms to learn the underlying patterns in 3D medical images and compress them efficiently while preserving image quality and segmentation accuracy.\n\nOur proposed approach consists of three stages: (1) pre-processing, (2) compression, and (3) segmentation. In the pre-processing stage, we use a convolutional neural network (CNN) to learn the features of the 3D medical images and reduce the dimensionality of the data. In the compression stage, we employ a novel hybrid compression method that combines convolutional neural networks (CNNs) and discrete cosine transform (DCT) to compress the pre-processed data. Finally, in the segmentation stage, we use a Fully Convolutional Network (FCN) to accurately segment the compressed image.\n\nWe evaluate our proposed approach on several publicly available 3D medical image datasets, including MRI, CT, and ultrasound images. The results show that our approach significantly outperforms several state-of-the-art compression and segmentation methods in terms of both compression ratio and segmentation accuracy. Specifically, we achieve an average compression ratio of 4.5:1 with a negligible loss in image quality and segmentation accuracy.\n\nThe main contributions of this paper can be summarized as follows:\n\n* We propose a machine vision guided 3D medical image compression approach that leverages the power of deep learning algorithms to learn the underlying patterns in",
    "Iris recognition is a widely used biometric modality that has gained significant attention in recent years due to its high accuracy and resistance to fraud. However, the presence of eye pathologies can significantly affect the performance of iris recognition systems, leading to incorrect identifications or false negatives. This paper investigates the impact of various eye pathologies on iris recognition and proposes novel approaches to improve the accuracy of iris recognition in such cases.\n\nA comprehensive review of existing literature on iris recognition and eye pathologies was conducted, followed by a thorough analysis of the effects of different types of eye pathologies on iris recognition. The study also involved the collection of a dataset of images of eyes with various pathologies and the development of a new algorithm designed specifically to handle these conditions.\n\nThe results showed that certain eye pathologies, such as cataracts, glaucoma, and uveitis, have a significant negative impact on the accuracy of iris recognition. In particular, cataracts were found to cause the most significant degradation in iris quality, resulting in a decrease in recognition accuracy of up to 30%. The proposed algorithm, which incorporates advanced image processing techniques and machine learning algorithms, was able to mitigate this effect and achieve an accuracy rate of over 95% even in the presence of severe eye pathologies.\n\nThis research demonstrates the importance of considering eye pathologies when designing and implementing iris recognition systems, particularly in applications where security and accuracy are paramount, such as border control or law enforcement. The findings suggest that the use of specialized algorithms and image processing techniques can significantly improve the robustness of iris recognition systems and enable their reliable operation even in challenging scenarios.",
    "In this paper, we aim to bridge the gap between category-level and instance-level semantic image segmentation. Category-level segmentation focuses on grouping images into semantic categories, while instance-level segmentation aims to segment individual objects within an image. We propose a novel approach that combines the strengths of both paradigms, enabling the segmentation of images into semantic instances that are grouped into categories.\n\nOur approach leverages a large-scale dataset of annotated images to learn a hierarchical representation of semantic concepts. We demonstrate the effectiveness of our method on several benchmark datasets, achieving state-of-the-art performance in both category-level and instance-level segmentation tasks. Our experimental results show that our approach outperforms traditional category-level and instance-level segmentation methods, and provides improved accuracy and efficiency in various applications such as object detection, instance-level image retrieval, and visual question answering.\n\nThe main contribution of this paper is the introduction of a novel architecture that seamlessly integrates category-level and instance-level segmentation. Our approach combines a category-level segmentation network with an instance-level segmentation network, enabling the sharing of knowledge and features between the two networks. This hierarchical representation of semantic concepts allows for more accurate and efficient image segmentation, and provides a robust foundation for various computer vision tasks.\n\nThe paper is organized as follows: In section 2, we review related work in category-level and instance-level segmentation. In section 3, we describe our proposed method in detail. In section 4, we present our experimental results and analysis. Finally, in section 5, we conclude the paper and discuss future directions for this research.\n\nOur work has significant implications for various applications in computer vision, including object detection, instance-level image retrieval, and visual question answering. By bridging the gap between category-level and instance-level segmentation, our approach provides a more comprehensive understanding of images and their semantic content.",
    "In this paper, we demonstrate a novel method for optically addressing an individual erbium ion in silicon using a focused laser beam. Erbium ions are commonly used in quantum computing and photonic devices due to their unique optical properties. However, addressing individual ions in a dense ensemble can be challenging, especially when they are embedded in a solid-state matrix like silicon.\n\nOur approach leverages the fact that the absorption cross-section of erbium ions is strongly dependent on the polarization state of the incident light. By carefully controlling the polarization of a focused laser beam, we were able to selectively excite a single erbium ion within a densely doped silicon sample. The ion's fluorescence emission was then collected through a high numerical aperture objective and analyzed using a spectrometer.\n\nWe observed a clear anti-correlation between the ion's fluorescence intensity and the laser power, indicating that the ion's excited state population was being depleted by the laser-induced spin-flip process. Furthermore, we demonstrated that the ion's fluorescence could be switched on and off by modulating the laser's polarization, allowing us to precisely control the ion's quantum state.\n\nThis work represents a significant advancement in the field of quantum optics and has important implications for the development of scalable quantum information processing architectures based on rare earth ions in silicon. Our technique paves the way for efficient readout and manipulation of individual ion qubits in such systems, which will be essential for large-scale quantum computing applications.",
    "In this paper, we present a novel 4D light-field dataset and propose two convolutional neural network (CNN) architectures for material recognition tasks. The proposed dataset, called Material-LF, is the first of its kind to capture high-quality 4D light-field images of various materials under different lighting conditions. The dataset contains 16,384 images of 21 different materials, each captured under 24 different lighting conditions.\n\nThe two proposed CNN architectures, called LF-Net and LF-Net++, are designed to exploit the spatial and temporal information in 4D light-field images for material recognition. LF-Net is a light-field image convolutional neural network that uses a novel spatial-temporal separation module to extract both spatial and temporal features from 4D light-field images. LF-Net++ is an extension of LF-Net that incorporates a multi-scale feature fusion module to improve the performance of the network.\n\nWe evaluate the performance of LF-Net and LF-Net++ on the Material-LF dataset and achieve state-of-the-art results. Our experiments show that LF-Net outperforms several state-of-the-art 2D CNNs and 3D CNNs on material recognition tasks. Additionally, LF-Net++ achieves even better performance by incorporating multi-scale features.\n\nOur main contributions are: (1) the creation of a large-scale 4D light-field dataset for material recognition, (2) the proposal of two CNN architectures specifically designed for 4D light-field image processing, and (3) the demonstration of the effectiveness of 4D light-field images for material recognition tasks.\n\nOur work has significant implications for various applications, such as robotics, computer vision, and virtual reality. The 4D light-field dataset and CNN architectures proposed in this paper can be used to improve the performance of material recognition systems in various scenarios, such as object recognition, scene understanding, and 6D object pose estimation.",
    "In this paper, we explore the characteristics of the Eliashberg formalism using the example of the high-pressure superconducting state in phosphorus. The Eliashberg formalism is a mathematical framework used to describe the electron-phonon interaction and its impact on superconductivity. By applying this formalism to phosphorus, we aim to gain insights into the underlying mechanisms that govern its superconducting properties under high pressure. Specifically, we focus on the analysis of the electronic structure, phonon spectrum, and electron-phonon coupling in this material. Our results show that the Eliashberg formalism can accurately capture the essential features of the high-pressure superconducting state in phosphorus, including the strong electron-phonon coupling and the presence of multiple phonon modes contributing to the pairing mechanism. We also find that the superconducting critical temperature increases with increasing pressure, which is consistent with experimental observations. Our work highlights the potential of the Eliashberg formalism as a valuable tool for studying superconductivity in materials with complex electron-phonon interactions, and provides new insights into the physics governing high-pressure superconductors.",
    "In this paper, we propose a novel approach to volumetric medical image segmentation using positional contrastive learning. Traditional methods for medical image segmentation rely on supervised learning techniques, which require annotated data to train the model. However, annotating medical images is a time-consuming and expensive process, and the lack of annotated data can limit the performance of these models.\n\nIn contrast, our proposed method leverages the vast amount of unannotated data available in medical imaging archives to train a segmentation model. By using positional contrastive learning, we can learn a representation of the image that captures the spatial relationships between different structures within the image. This representation can then be used to segment the image without the need for annotated data.\n\nWe evaluate our method on several publicly available datasets, including brain MRI and CT scans, and show that it outperforms traditional supervised learning methods. We also demonstrate the generalizability of our approach by applying it to a variety of different segmentation tasks, including tumor segmentation, organ segmentation, and vessel segmentation.\n\nOur results demonstrate the potential of positional contrastive learning for medical image segmentation, and highlight the opportunity to leverage large-scale unannotated data to improve the accuracy and efficiency of medical image analysis.",
    "In this paper, we present a novel approach for generating images from eye movements using a wearable eye tracker. Our proposed method, called WAYLA (Wearable Artificial Intelligence for Eye-tracking based Image Generation), leverages the latest advancements in deep learning and computer vision to create realistic images from the patterns of eye movements.\n\nWe evaluate the effectiveness of WAYLA through a series of experiments, using both qualitative and quantitative measures. Our results show that WAYLA is able to generate high-quality images that accurately reflect the user's intended design, as revealed by the eye movements. Furthermore, we demonstrate the versatility of WAYLA by generating a wide range of images, including objects, scenes, and abstract patterns.\n\nThe contribution of this paper lies in the development of a wearable device that can generate images from eye movements, providing a new means of artistic expression for individuals with disabilities, as well as a tool for researchers to study the relationship between eye movements and creativity.\n\nOur study has the potential to have a significant impact on various fields, including art, design, psychology, and human-computer interaction. The ability to generate images from eye movements has the potential to enable individuals with disabilities to express themselves in new and creative ways, while also providing insights into the cognitive processes underlying image generation.\n\nIn conclusion, WAYLA offers a powerful tool for image generation, with potential applications in fields such as art, design, and research. Our approach has the potential to revolutionize the way we interact with technology, and we envision a future where wearable devices like WAYLA become ubiquitous, enabling individuals to create and communicate in entirely new ways.",
    "This paper proposes a novel approach for boundary detection using image segmentation, which adapts to the local properties of the image. The proposed technique leverages the strengths of both top-down and bottom-up segmentation methods to accurately detect boundaries in images with varying levels of noise and complexity.\n\nThe proposed technique first applies a bottom-up approach to generate a set of superpixels, which are then used to construct a hierarchy of regions. The hierarchy is then used to identify the most likely boundary locations using a top-down approach. The technique adapts to the local properties of the image by adjusting the scale and threshold parameters based on the local gradient information.\n\nExperiments conducted on several benchmark images demonstrate the effectiveness of the proposed technique in accurately detecting boundaries in images with different levels of noise and complexity. The proposed technique outperforms traditional boundary detection methods, such as the Canny edge detector, in terms of both accuracy and computational efficiency.\n\nThe main contribution of this paper is the introduction of a locally adapting technique for boundary detection using image segmentation, which combines the strengths of both top-down and bottom-up approaches. The proposed technique has important applications in various fields, such as object recognition, image restoration, and medical imaging.",
    "In this paper, we propose a novel method for constructing a non-negative low rank and sparse graph with data-adaptive features. Our approach leverages the strengths of non-negative matrix factorization and sparse graph representation to create a robust and efficient graph model that can accurately capture the complex relationships between data points.\n\nThe proposed method consists of two main stages. First, we use a non-negative matrix factorization technique to decompose the data matrix into two low-rank matrices, which capture the underlying structure of the data. We then use these matrices to construct a sparse graph, where each node represents a data point and the edges represent the similarity between the data points.\n\nThe key innovation of our method is the use of data-adaptive features, which are learned from the data itself. These features are used to weight the edges in the graph, allowing the model to selectively focus on the most important relationships between data points. This results in a graph that is both sparse and informative, making it well-suited for tasks such as clustering, classification, and dimensionality reduction.\n\nWe evaluate our method on several real-world datasets and compare it to state-of-the-art graph construction methods. The results show that our method outperforms the competition in terms of both computational efficiency and accuracy. We also demonstrate the versatility of our method by applying it to a variety of applications, including image segmentation, text classification, and recommender systems.\n\nOverall, our paper makes an important contribution to the field of graph construction and demonstrates the power of non-negative low rank and sparse graph representation with data-adaptive features. The proposed method has broad applications in data analysis, machine learning, and related fields, and we expect it to be of interest to researchers and practitioners working in these areas.",
    "In this paper, we investigate the crossover of three-dimensional (3D) topological insulator Bi2Se3 to the two-dimensional (2D) limit. By employing a combination of theoretical and experimental approaches, we explore the topological phase transition that occurs as the thickness of the material is reduced from 3D to 2D.\n\nUsing first-principles calculations, we demonstrate that the 3D Dirac cone of Bi2Se3 flattens and forms a 2D Dirac cone as the thickness decreases, resulting in a topological insulator-to-metal transition. We also observe the occurrence of quantum spin Hall effect in the 2D limit, which is characterized by the presence of topologically protected edge states.\n\nFurthermore, we experimentally study the crossover using angle-resolved photoemission spectroscopy (ARPES) and observe a strong dependence of the Fermi velocity on the thickness of the material. We find that the Fermi velocity decreases as the thickness decreases, indicating a transition from a 3D to a 2D Fermi surface.\n\nOur results provide a comprehensive understanding of the crossover of Bi2Se3 from a 3D topological insulator to a 2D metal, and shed light on the topological phase transition that occurs in this process. The observation of the quantum spin Hall effect in the 2D limit further highlights the potential of this material for use in spintronics and other emerging technologies.",
    "In this paper, we propose a novel approach to unsupervised medical image segmentation using contrastive registration. Unlike traditional segmentation methods that rely on fully-supervised learning or manual annotation, our approach leverages the power of contrastive learning to learn a representation of the image that can be used for segmentation. We introduce a new framework that combines contrastive registration with a spatial pyramid pooling module to learn a hierarchical representation of the image, which can be used to segment medical images in an unsupervised manner.\n\nWe evaluate our approach on several publicly available medical imaging datasets, including brain MRI, lung CT, and liver CT. Our results show that our method outperforms state-of-the-art unsupervised segmentation methods, including those that use deeper networks or more complex architectures. We also perform an ablation study to analyze the effectiveness of the various components of our approach, demonstrating the importance of the contrastive registration module and the pyramid pooling module.\n\nOur approach has several advantages over traditional segmentation methods. First, it does not require any manual annotation or supervision, which can be time-consuming and costly to obtain. Second, it can handle complex medical images with varying levels of noise and resolution. Finally, our approach is robust to variations in the input data, allowing it to generalize well to new images.\n\nOverall, our proposed method has the potential to significantly improve the efficiency and accuracy of medical image segmentation, and could have a positive impact on a wide range of medical applications, including disease diagnosis, treatment planning, and monitoring.",
    "This paper presents a novel approach to stereo-based terrain traversability analysis, which is essential for autonomous vehicles and robots to navigate safely and efficiently in complex environments. The proposed method combines normal-based segmentation and superpixel surface analysis to estimate the traversability of uneven terrains.\n\nFirstly, the stereo images are processed using a normal-based segmentation algorithm to extract planar and non-planar surfaces. Then, superpixels are generated from the segmented images to enhance the spatial coherence of the surface features. Subsequently, the superpixels are analyzed using a set of traversability metrics that consider factors such as slope, orientation, and roughness.\n\nThe proposed method was evaluated on various challenging outdoor scenarios, including hills, rocks, and ditches. Experimental results demonstrate that our approach outperforms traditional methods based on single-image analysis, particularly in areas with steep slopes and irregular surfaces. Moreover, the combination of normal-based segmentation and superpixel surface analysis enables the method to effectively handle shadows, occlusions, and other difficult conditions.\n\nThe main contribution of this work lies in its ability to provide accurate and robust terrain traversability estimation by leveraging the complementary information present in stereo imagery. The proposed method has significant implications for real-world applications, such as autonomous driving, robotic exploration, and search and rescue operations. Future work includes further optimization and integration of the method into complete navigation systems.",
    "The flood filling game, also known as the connected dominos game, two colors and one match or the kite dominoes game was introduced by Tardos et Al in 2015 [TKSS], a year after Ailon et al had already shown that the problem was not polynomially solvable on planar maps [ASTW]. In this game a player starts with either black or white tiles and places them adjacent to at least one tile which is initially placed. These tiles are then covered (flooded) if they form a rectangle and only if all sides have an equal number of white and black squares. Once each square has been flooded we say that the board or map is filled. This process continues but only squares which can be completely covered without leaving any edge uncovered may be picked up next. We are interested in how many moves it takes so that every square in the given map gets covered, especially considering some special cases like convex polygons, rectangles, trees etc. We give polynomial time algorithms for deciding whether a map is indeed fillable using O(n^3log*n)-time algorithm to solve the minimum problem in planars or finding out if there exists a particular move sequence using SCC decompositions followed by Euler Tour technique. Further we look into the behaviour of this graph when edges incident on different SCCs' get deleted independently. With increasing knowledge about this decomposition helps us deduce certain relationships between tree width, max degree of the decomposition tree and the size of maximal clique containing vertices from more than one SCC.",
    "> Camera-trap images segmentation is a challenging task due to the presence of noise, occlusion, and low contrast. In this paper, we propose a novel method for camera-trap images segmentation using multi-layer robust principal component analysis (PCA). The proposed method consists of two main steps: (1) multi-layer robust PCA is used to extract the features of the camera-trap images, and (2) a support vector machine (SVM) is used to classify the extracted features into two classes: animal and background. The proposed method is evaluated on a dataset of 1000 camera-trap images, and the results show that the proposed method outperforms the state-of-the-art methods in terms of accuracy and speed.\n\nThe following is the full text of the abstract for a research paper titled \"Camera-trap images segmentation using multi-layer robust principal component analysis\" from arxiv.org:\n\n> Camera-trap images segmentation is a challenging task due to the presence of noise, occlusion, and low contrast. In this paper, we propose a novel method for camera-trap images segmentation using multi-layer robust principal component analysis (PCA). The proposed method consists of two main steps: (1) multi-layer robust PCA is used to extract the features of the camera-trap images, and (2) a support vector machine (SVM) is used to classify the extracted features into two classes: animal and background. The proposed method is evaluated on a dataset of 1000 camera-trap images, and the results show that the proposed method outperforms the state-of-the-art methods in terms of accuracy and speed.\n\nThe following is the full text of the abstract for a research paper titled \"Camera-trap images segmentation using multi-layer robust principal component analysis\" from arxiv.org:\n\n> Camera-trap images segmentation is a challenging task due to the presence of noise, occlusion, and low contrast. In this paper, we propose a novel method for camera-trap images segmentation using multi-layer robust principal component analysis (PCA). The proposed method consists of two main steps",
    "The increasing availability and popularity of digital pathological images have led to an active area of automatic image classification known as Digital Pathological Analysis (DPA). These algorithms aim at reducing analysis time, by using deep learning models that can replicate expert decisions. However, they are not very robust when facing variations on patient/slide characteristics which leads to limitations due to inter-observer variability and inconsistency across sites or scanners.. For example, a segmenting algorithm might be trained to correctly detect cancerous nuclei at 20X on two particular specimen slides. But if its deployed, will it generalize to new specimens? One answer lies with ensembling where multiple decision tree nodes make up the output classifier  this has been shown to help address such issues.. This study aims to investigate how we can leverage the sparse coding module of convolutional neural networks (CNN) together with Random Forest based decision trees as part of an ensemble machine learning strategy for better feature selection while maximizing discriminative ability . It compares against several existing nuclear segmentation strategies used in literature, achieving state of the art results both locally and globally..",
    "http://arxiv.org/abs/1402.6597\nA new generalization of the Inflaton with an exponential potential (IEP) model, which incorporates possible deviations to pure de Sitter expansion during inflation, has been proposed recently for providing an estimate to the primordial fluctuations in the Universe at any order with a good accuracy and simultaneously explaining all observational results on inflation with no need of an extra sector or mechanism to produce the fluctuations without contradiction with the other standard predictions on inflation. This work shows that this class of theories has interesting implications: firstly it predicts the existence of several plateau regions with specific non-vanishing values of the scalar field, leading as predicted to almost flat spectra; secondly the presence of these additional steps gives rise to primordial perturbation functions that have features similar to those obtained within the Starobinsky' s or Hills-Politzer model that can be seen as limits of our proposal. These predictions are explored with emphasis on how observable they are, but also giving them analytical expressions that we show agree very well with numerical ones and allowing us even to propose some phenomenological formulae for comparison with data.",
    "> Semantic image segmentation is a fundamental task in computer vision. It is a challenging problem due to the large number of classes and the large amount of data required for training. In this paper, we propose a novel semi-supervised learning framework for semantic image segmentation. Our framework consists of two main components: a self-correcting network and a self-training network. The self-correcting network is a semi-supervised learning network that uses a self-correcting mechanism to correct the predictions of the network. The self-training network is a supervised learning network that uses the corrected predictions of the self-correcting network as the training data. We show that our framework can achieve state-of-the-art performance on the PASCAL VOC 2012 dataset.\n\nThe following is the full text of the abstract for a research paper titled \"Semi-Supervised Semantic Image Segmentation with Self-correcting Networks\" from arxiv.org:\n\n> Semantic image segmentation is a fundamental task in computer vision. It is a challenging problem due to the large number of classes and the large amount of data required for training. In this paper, we propose a novel semi-supervised learning framework for semantic image segmentation. Our framework consists of two main components: a self-correcting network and a self-training network. The self-correcting network is a semi-supervised learning network that uses a self-correcting mechanism to correct the predictions of the network. The self-training network is a supervised learning network that uses the corrected predictions of the self-correcting network as the training data. We show that our framework can achieve state-of-the-art performance on the PASCAL VOC 2012 dataset.\n\n## Introduction\n\nSemantic image segmentation is a fundamental task in computer vision. It is a challenging problem due to the large number of classes and the large amount of data required for training. In this paper, we propose a novel semi-supervised learning framework for semantic image segmentation. Our framework consists of two main components: a self-correcting network and a self-training network. The self-correcting network is a semi-",
    "> In this work, we propose and analyze an improved version of the Multiple Signal Classification (MUSIC) algorithm to estimate the direction-of-arrivals (DoAs) of multiple narrowband sources in the presence of noise and interference. We show that the proposed method outperforms the original one by reducing the variance of the estimated DoAs. This improvement comes at no extra computational cost since it only requires minor modifications to the existing MUSIC algorithm. Our theoretical results are supported with numerical simulations which demonstrate the effectiveness of our approach.",
    "\\newpage\n\n\\noindent\n(1) \\underline{Abstract} - We consider the generalized entropy concept\nfor a conserved process and derive the equilibrium properties\nassociated with equilibrium distributions in systems with a large,\nand a finite number of degrees of freedom or states. We consider a\ngeneralized approach to derive the equilibrium properties of conserved\nmany particle systems by extending earlier work by Sano [1] which in\nturn was inspired by work by Havrda, Charv\\'at and others [2,3,4] and\nTsallis [5].\n\nThis formalism includes both entropic functions of finite and infinite\ndifferentiation but it takes a finite number of differentiations\nand limits to include and deal with the situation of finite\ndegrees of freedom systems that are not infinite.\n\nIn particular this formalism allows to take into account conserved\nproperties of systems of any kind like the number of particles or\ninverse temperature.\n\nThen this formalism also allows to derive the equilibrium\nproperties, and the equilibrium distributions of systems consisting of\na finite number of entities that obey the laws of a Boltzman-like\ndistribution - which is known to contain the Gaussian distribution as\na special case when the inverse temperature approaches a finite\nvalue of zero.\n\nWe also derive that the same equilibrium properties that follow from\nthis finite differentiation, finite degrees of freedom formalism are\ncompatible with well-defined conditions on the conservation of\nenergy - or alternatively the conservation of the number of\ndegrees of freedom, or equivalently the conserved distribution\n(i.e. in our case of the conserved probability distribution of the\nnumber of particles of the original system in some arbitrary initial\nstate).",
    "> We present an approach that learns to segment images using only image-level labels, without any pixel-wise or bounding box annotations. Our method uses a novel loss function which encourages the network to predict a set of semantically meaningful regions in each image. This allows us to train our model on large datasets such as ImageNet and MS COCO where there are no pixel-wise annotations available. In addition, we show how this loss can be used to improve existing methods by providing additional supervision during training. Experiments demonstrate that our method outperforms state-of-the-art approaches on several benchmarks including PASCAL VOC 2012 and Cityscapes.",
    "> In this paper, we propose an image segmentation model which combines normalized cut (NC) criterion with adaptive similarity measure and spatial regularization term to improve the performance of NC-based methods in terms of both accuracy and efficiency. Firstly, we introduce a new similarity function that can be used as a general replacement for the commonly used Euclidean distance or correlation coefficient. This new similarity function has two advantages over these traditional measures: it is more robust against noise and outliers; and its parameter can be automatically determined by minimizing the objective function without any prior knowledge about the data distribution. Secondly, we incorporate a spatial regularization term into the original NC formulation so that the resulting energy functional becomes convex and thus easier to optimize. Finally, we develop an efficient algorithm to solve the proposed optimization problem using alternating direction method of multipliers (ADMM). Experimental results show that our approach achieves better segmentation quality than other state-of-the-art algorithms while being much faster due to its low computational complexity.",
    "Abstract:\nThe main purpose of this research is proposing an automated linear function submission-based double auction (ABLDS) as a real-time pricing (RTP) mechanism for large scale prosumers' electricity network in an energy system with decentralised network of prosumers, in\nwhich the main features of price elasticity of supply are accounted. In this paper, a modified double auction-based mechanism with linear functions as market-clearing bids and offers is presented for bottom-up RTP of prosumers' electricity.\n\nIn the presented mechanism, by using the linear functions each prosumer offers two linear functions as bid and offer bids, and the market-clearing bid and the market-clearing offer are generated as the highest and lowest linear functions in the bids and offers, respectively. It is also shown that, by the introduced mechanism, the price elasticity of each load is considered. The proposed algorithm has a complexity of O(n log((n))) in which n demonstrates the number of prosumers. The complexity is relatively high, but it will be significantly reduced by the fact that there are only a small number of price-elastic load that will be active in the market. Thus, ABLDS can be considered more practical\nand applicable in real world. The results showed that the RTP can be performed successfully without being affected by malicious attackers, and provides an effective mechanism for the pricing in the prosumers electricity network.\n\nTo find more about RTP and smart grid:\n\nRenewable Energy: A Practical Approach - The book provides comprehensive coverage of the technical and regulatory aspects of renewable applications and systems. It discusses the economic aspects and the impacts on social, cultural and political dimensions of renewable installations; as well as the regulatory framework.\n\nSolar Power for Home and Farm - This book teaches readers how to build their own solar power devices. It also teaches readers how to store, convert and use solar power as an alternative to main power supply.\n\nHandbook of Solar Thermal Energy Applications - A comprehensive guide to solar energy applications, this",
    "#### Abstract:\n\nRecently, social dynamics became a popular research field in computer vision. It is well known that biological organisms have the capacity to exhibit collective behaviors and social cohesion. These abilities provide an effective solution for organizing social groups and for solving collective decision-making problems. They constitute significant means of organization among biological populations exhibiting various social behaviors including the formation of groups and swarms, schooling, and flocking. A large amount of the social behavior analysis falls into the category of social physics. It is a branch of social research which seeks a physical understanding on social behavior in the same way as the molecular model or the kinetic theory of gases. A simple model of the Deffuant-Weisbuch (DW) and social dynamical systems theory is developed here for the segmentation of images. It is found that the model converges to a stable state at the global minimum. The parameters of the model are automatically extracted from the intensity and spatial coherence statistics of the input images. By using different parameter values, different levels of segmentations can be generated. Thus, by using only a simple image processing model, we can achieve multi-resolution segmentation. It is observed that the DW model is robust to different input values and image conditions. However, it is sensitive to noise. Therefore, noise must be removed from the input as part of the pre- processing step.\n\n#### Original paper:\n\nM. Z. Khan, A. R. Mahmood, T. A. Ahmad, L. Aljibouri, M. M. El-Zagzag (2012). Unsupervised Image Segmentation using the Deffuant-Weisbuch Model from Social Dynamics arXiv:1212.5529v1 [cs.CV] 8 Dec 2012.  doi: 10.48550/arXiv.1212.5529",
    "#### Abstract\n\nGiven an operation n^a acting on positive integers, we define and study the related multi operation M(n), where M(n) counts how many different operations are needed to achieve n as their product. We prove that M(n) does not take values 1/2 or larger than some C=C (practically) forever when dealing with primes. For all odd prime exponents a, the sequence {M(pn)} has no terms in [0.5388974..., 1] while for even exponents it does, yet in practice no terms exceed 1- for any fixed >0 so effectively they can too be said never reach . In contrast though, there exists x0 such that any finite number k of operations produce infinitely many distinct xs. We also provide bounds on these sequences which show for example that if bd then for sufficiently large n M(bn)> 0.5 M(bd).\nIn order to achieve this we use p-adic analyticity and adelic methods together and apply them to the problem at hand.",
    "In this work we explore how much simpler models than the winning approaches in ILSVRC-2014 can match thier performance when using better regularization techniques that control the complexity during training as well as at test time. By employing simple dropouts throughout all convolutional layers and introducing novel low/high resolution data augmentation on top we are able to produce state-of-the art results on ImageNet with only eight layers that require at least six times less computations during testing resulting in faster runtime. This simple architecture performs substantially better by achieving Top5 rate around 69% which matches state-of-the-art Deep RNNs trained under similar settings while being much smaller model with fewer parameters. Furthermore, such an approach allows us to easily train large ensemble networks without having to deal with very deep networks during test phase where fast and accurate predictions matter most. We demonstrate our method for producing compact ensembles by presenting three new models trained on ILSVRC-2013 dataset that reach accuracy around 80%.",
    "> Abstract: A new osmotic pressure equation has been derived based on experimental data and theoretical considerations, which improves upon the existing vant Hoff equation by including an additional term to account for the effect of solute size (molecular weight) in addition to concentration. This new formula was tested experimentally using two different types of solutions with varying concentrations and molecular weights of solutes. It was found that the new formula provides better agreement between predicted and measured values than the vant Hoff equation, particularly at higher concentrations or larger molecules. These results suggest that this new formula may be useful for predicting osmotic pressures under various conditions where traditional methods fail due to limitations such as high viscosity or non-ideal behavior.",
    "> We present an approach to few-shot segmentation that leverages both image and point cloud data, which we call \"Squeeze & Excite\". Our method uses a 3D convolutional neural network (CNN) to extract features from volumetric images, while also using a PointNet++ architecture to process point clouds extracted from these same images. These two feature representations are then combined in a novel way via attention mechanisms inspired by SENet [Hu et al., ICCV17]. This allows our model to leverage information about the spatial structure of objects within the scene as well as their appearance. In addition, we propose a new loss function based on the Dice coefficient that encourages the CNN to learn more discriminative features than traditional cross entropy losses. Experiments show that this combination leads to improved performance over state-of-the-art methods when training with only one or two examples per class.",
    "Authors: Vlada Stavropoulou and Christophe Prieur\nAbstract: We propose an image segmentation framework, taking into account both the intensity features extracted by non-local filtering, as well as the topological information provided by the spatial arrangement of superpixels computed locally in neighbourhoods using topology preservation methods such as Chamfer Distance (CD). Following recent works which have advocated that this additional prior can be useful to alleviate difficulties like occlusions or lighting variations when applied jointly with standard non-supervised density estimation based image clustering algorithms, we use it here within an unsupervised graph partitioning formulation that allows the definition of a large scale number of clusters at various degrees of granularity according to the local size of segments detected. As our proposed model contains only few parameters relative to CD, no optimization procedure is necessary for its fine tuning but one can simply adapt it easily given specific constraints to handle for a particular application with a high level of confidence on the results obtained. This approach has been validated experimentally on different datasets showing good performances.",
    "> We present a novel approach to semantic image segmentation that combines boundary detection and classification in one network, which we call Classification-With-an-Edge (CWAE). Our method uses a single convolutional neural network architecture to simultaneously detect boundaries between objects and classify pixels into object classes. This allows us to leverage information about object boundaries during pixel classification, improving performance on both tasks. In addition, our model can be trained end-to-end using only weakly labeled data, making it more scalable than existing methods that require expensive human labeling or additional training steps. Experiments show that CWAE outperforms state-of-the-art approaches on several benchmark datasets, including PASCAL VOC 2012 and Cityscapes.",
    "> We propose a novel architecture for semantic segmentation of 3D point clouds. Our architecture is based on a novel shape convolutional neural network (SCNN) that is able to learn a shape representation from a point cloud. The SCNN is based on a novel shape convolution operator that is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able to learn a shape representation from a point cloud. The SCNN is able",
    "> Biomedical image segmentation is a fundamental task in medical image analysis. It is a challenging task due to the complexity of the images and the diversity of the segmentation methods. In this paper, we propose a novel multi-compound transformer (MCT) for biomedical image segmentation. The MCT consists of a multi-compound encoder and a multi-compound decoder. The multi-compound encoder is composed of a multi-compound convolutional block and a multi-compound transformer block. The multi-compound convolutional block is used to extract multi-scale features from the input image. The multi-compound transformer block is used to capture the long-range dependencies between the multi-scale features. The multi-compound decoder is composed of a multi-compound transformer block and a multi-compound deconvolutional block. The multi-compound transformer block is used to capture the long-range dependencies between the multi-scale features and the output segmentation map. The multi-compound deconvolutional block is used to upsample the output segmentation map to the original image size. The MCT is trained end-to-end using a multi-task loss function that combines the segmentation loss and the classification loss. The MCT is evaluated on three biomedical image segmentation tasks: brain tumor segmentation, liver segmentation, and lung segmentation. The results show that the MCT outperforms the state-of-the-art methods in terms of accuracy, precision, recall, and F1-score.\n\nThe following is the full text of the abstract for a research paper titled \"Multi-Compound Transformer for Accurate Biomedical Image Segmentation\" from arxiv.org:\n\n> Biomedical image segmentation is a fundamental task in medical image analysis. It is a challenging task due to the complexity of the images and the diversity of the segmentation methods. In this paper, we propose a novel multi-compound transformer (MCT) for biomedical image segmentation. The MCT consists of a multi-compound encoder and a multi-compound decoder. The multi-",
    "We prove a pattern avoidance result for the set partitions of \\((n,n)\\) by a certain family of permutations. More specifically, given any family \\(\\mathcal{F} \\subset M_n\\) of permutations and any set partition \\(\\pi\\) of \\((n,n)\\) we show that the total number of pattern avoidance properties in this family verified by \\(\\pi\\) is finite.\n\nThis result is a variant a result of Klazar (2003) from a talk by the second named author, and can also be re-formulated in terms of words or permutations. More precisely, given an integer \\(k\\), for each fixed family \\(\\mathcal{F} \\subset M_n\\) of (finite) pattern-avoiding \\(k\\)-tuples of permutations, the total number of pattern avoidance properties in this family verified by \\(\\pi\\) is finite.\n\nWe show that such results can be regarded as a special case of a more general statement implying that given any set partition \\((s,t)\\) of \\((n,n)\\) and any sequence \\((a_1,\\dots, a_k)\\) of symbols, if a permutation of \\(n\\) avoids the first \\(\\mathrm{length}(s)\\) of these symbols, then it must also avoid the last \\(\\mathrm{length}(t)\\) of them.",
    "\"We present DeepIGeoS (DIPS), a fully automated method for interactive segmentation of 3D medical images (brain MRIs, CTs, and 3D US). DIPs is a fast, accurate, and fully automatic 3D segmentation method that uses a unique and intuitive two-step algorithm. In the first step, the method automatically defines the regions where user interaction is needed. Next, 3D geodesic-based algorithms identify landmarks of the object of interest and then use this information to initialize a convolutional neural network (CNN) to segment the object within these landmarks. DIPS offers three unique advantages: i) it avoids time-consuming 3D landmarks selection, ii) it overcomes the segmentation challenges in images with large deformations, and iii) it outperforms other automated methods with the same computational complexity. We tested DIPs on 3D ultrasound (3DUS) and 3D CT and MR images of multiple organs (brain, liver, pancreas, uterus) and a large clinical dataset of 954 brain MRI scans. Our evaluation showcases a significant increase in accuracy compared to a state-of-the-art CNN segmentation method and significantly reduced training time. Thus, DIPs can provide a useful platform for 3D segmentation, particularly for users with limited time and segmenting skills.\"\n\nSee full reference for further details about the abstract.\n\n## Contact\n\n### Brijesh Krishna\n\n- Bioinformatics and Data Science\n- Email: brijesh.krishna@nicta.com.au\n- Phone: +61 3 9666 3000",
    "In 2016, an approach employing a morphological feature representation based on dilations was proposed to significantly improve semantic segmentation performance over state-of-theart deep learning architectures and datasets on 2D medical images (Koohpayeh, K., O'Doherty M., Dhanesh S &amp; Bovis F., 2017a). In this article we extend this previous work by proposing new combinations of dilation operations in morphologically structured units that further boost both classification accuracy at the pixel level, whilst reducing run-time requirements so as to enable real-time processing speeds. We assess these blocks against those used previously through their suitability and benefits when applied to 3D MRI brain tumour volumetric images and propose an optimized set of morphological operation blocks along with their associated hyperparameter settings. We validate our findings through an experimental comparison of results using a series of deep-learning architecture models including VGGNet (V/X), Darknet55, GoogLeNet, ResNet 34, VoxSegCNN and the original multi-class network MCN++ which incorporates our previous dilating block approach. Our experiments are conducted across popular healthcare image benchmark collections from BraTS 2018.",
    "We integrate R and LaTeX to analyze simple datasets with introductory statistics students in a computer lab setting using an interactive textbook based on <em>The CRAN Package RMarkdown</em>. We provide examples, student solutions, instructor notes, and other supplementary materials to help readers understand how to implement the software. In addition, we offer details about how to set up the classroom environment and discuss the potential pitfalls our instructors discovered along the way. This project uses a collaborative methodology developed by students enrolled during Spring 2015 as an independent-study course at Western New England University. Our goal for this research was twofold &#8213; not only did we want to teach the students how to program and incorporate statistical analysis tools within their workflow (i.e., reproducible research), but also expose them to additional skills that would be used in professional environments. Overall, we believe these objectives can further increase workplace relevancy among college graduates who often lack experience programming computers professionally or dealing with complex data problems while applying appropriate statistical methods.",
    "> Medical image segmentation is a fundamental task in medical image analysis. It is widely used in medical diagnosis, treatment planning, and image-guided surgery. However, the segmentation of medical images is a challenging task due to the complexity of medical images and the lack of annotated data. In this paper, we propose a novel data-swapping method for fast and accurate 3D medical image segmentation. The proposed method consists of two main components: a data-swapping module and a segmentation module. The data-swapping module is used to generate synthetic data by swapping the data from different patients. The segmentation module is used to segment the synthetic data. The proposed method is evaluated on the BraTS 2019 dataset. The experimental results show that the proposed method can achieve a higher Dice score than the state-of-the-art methods.\n\nThe following is the full text of the abstract for a research paper titled \"Fast and Accurate 3D Medical Image Segmentation with Data-swapping Method\" from arxiv.org:\n\n> Medical image segmentation is a fundamental task in medical image analysis. It is widely used in medical diagnosis, treatment planning, and image-guided surgery. However, the segmentation of medical images is a challenging task due to the complexity of medical images and the lack of annotated data. In this paper, we propose a novel data-swapping method for fast and accurate 3D medical image segmentation. The proposed method consists of two main components: a data-swapping module and a segmentation module. The data-swapping module is used to generate synthetic data by swapping the data from different patients. The segmentation module is used to segment the synthetic data. The proposed method is evaluated on the BraTS 2019 dataset. The experimental results show that the proposed method can achieve a higher Dice score than the state-of-the-art methods.\n\nThe following is the full text of the abstract for a research paper titled \"Fast and Accurate 3D Medical Image Segmentation with Data-swapping Method\" from arxiv.org:\n\n> Medical image segmentation is a fundamental task in medical image analysis",
    "> Motivated by several problems that arise in the theory of symmetric polynomials and algebraic number theory we study how far functional analogues of Hlder, Minkowski, Markov (or Hardy) or HerglotzMarcinkiewicz inequalities can be expected to hold. In particular we provide such best possible functionals versions of Holder's inequality for finite signed measures on a locally compact abelian group.\n> We find it striking and noteworthy at this stage to describe here briefly what one does when trying to find suitable weight functions for which an extension theorem should fail  as suggested by many examples that have appeared recently - in contrast with the unweighted case treated by our recent results in two previous papers. For general L1 spaces one may need to consider the more restrictive classes defined above. Let us mention further interesting issues coming into play through those questions. A natural approach would consist therefore to look carefully at the behaviour under linear transformations of products of exponentials, given their importance both classical aspects of measure theory discussed above and in analytical number theory, where they are used to prove results concerning multiplicative characteristics and divisibility. For instance let   [0,2/3[ be fixed, the set [ , 1/] U {e  i} consists precisely of all values taken on by exp(it log c ) = exp(c t) where p  Primes . This gives rise naturally  if the density of primes goes fast enough towards some value c > 1  1    exp(ct) and then one observes that indeed there exists a linear map X : R  C satisfying this conjecture. On the other hand given any ct>1 it is well known already since Titchmarsh (1947) and later extended by Helson et al. that either such an exponential product fails completely  say t = lim sup n ln |p_n|, because P. Erds obtained an example showing that for any integer r=1 (in fact even larger), there exist independent sets $\\{a_{i}\\}=\\{b_{j}\\}^{(r}^{1}_{*}) such that $ \\log",
    "\"Urban scene segmentation is a challenging task particularly because of the presence of occlusions and unforeseen objects. The lack of high-level information such as bounding box labels causes traditional segmentation algorithms to be less accurate. Hence, semi-supervised learning algorithms that can leverage high-level information in low labeled datasets with unlabeled data, such as images and videos, can be advantageous. However, the large amount of unlabeled video segments requires a computationally efficient method for segmentation. We present a segmentation method called Naive-Student based on a semi-supervised learning method (self-training) and a deep convolutional neural network (ResNet-101). We propose a method to improve the efficiency of segmentation by increasing the accuracy of the self-training method. The results on the DAVIS benchmark are competitive to other unsupervised learning methods and the ResNet-101 classifier. When labeling is not possible, Naive-Student can be used instead of fully-supervised labels to predict more accurate bounding boxes for the training dataset.\"\nRead the full abstract for free here:",
    "> We consider models that jointly sample sets and labelings, where each element can be uniquely identified within its set. Such models are a generalization of Markov random fields with arbitrary-label nodes to any number of dimensions or latent variables. Using a novel inference algorithm which combines particle filters based on variational free energy minimization and loopy belief propagation (also called message passing), we show how many learning algorithms from neural networks to reinforcement learning can be naturally cast into such a model framework, leading to rich expressive power while circumventing issues like gradient vanishing and exploding gradients that arise otherwise due to loops in the dependency structure. As a demonstrative example we learn models using backpropagation over nonuniform point clouds embedded in Euclidean space by placing multiple discrete class labels at unknown positions, yielding representations invariant across changes in scale.",
    "> We propose a novel semi-supervised learning framework for 3D point clouds, which is able to leverage both labeled and unlabeled data to improve the performance of 3D classification. The proposed framework is based on a multi-view co-training strategy, where two views of the same point cloud are used to train two classifiers. The two classifiers are then used to label the unlabeled data, which are then used to train the two classifiers again. This process is repeated until convergence. The key idea of the proposed framework is to use uncertainty-aware sampling to select the most informative unlabeled data for training. The uncertainty of a data point is measured by the entropy of the predicted probabilities of the two classifiers. The proposed framework is evaluated on the ModelNet40 dataset, and the results show that it outperforms state-of-the-art semi-supervised learning methods for 3D point clouds.\n\nThe following is the full text of the abstract for a research paper titled \"3D Semi-Supervised Learning with Uncertainty-Aware Multi-View Co-Training\" from arxiv.org:\n\n> We propose a novel semi-supervised learning framework for 3D point clouds, which is able to leverage both labeled and unlabeled data to improve the performance of 3D classification. The proposed framework is based on a multi-view co-training strategy, where two views of the same point cloud are used to train two classifiers. The two classifiers are then used to label the unlabeled data, which are then used to train the two classifiers again. This process is repeated until convergence. The key idea of the proposed framework is to use uncertainty-aware sampling to select the most informative unlabeled data for training. The uncertainty of a data point is measured by the entropy of the predicted probabilities of the two classifiers. The proposed framework is evaluated on the ModelNet40 dataset, and the results show that it outperforms state-of-the-art semi-supervised learning methods for 3D point clouds.\n\nThe following is the full text of the abstract for a research paper titled \"3D Semi",
    "> We propose a novel framework to learn an edge feature map that can be flexibly incorporated into various fully convolutional neural networks (FCNNs) through edge attention guidance mechanisms, in order to enhance performance on medical image segmentation tasks. Concretely, we first train our network over generic datasets using multi-scale deep supervision strategies with context encoders such as U-Nets or CSPN to yield a pretrained FCNN base model. Next we modify this base by introducing attentive edge branch layers into it where a convolutional filter bank is employed to generate corresponding edge maps at different scales without losing any spatial information while the rest of weights are updated via gradient backpropagation in a separate parallel manner. Afterwards, the FCNN can integrate these edge features as prior knowledge during training and prediction stages through the so called ET-Attention module. We perform extensive experiments across three major data modalities i.e., MR brain lesion, fundus vessel and optic disc regions under diverse settings on both private benchmark and public challenges dataset and obtained improvements between 0.62%  15.84%.\n\nAnd now the researchers team has released a GitHub repository containing the code needed for reproducing their results. Check all details!",
    "\"Automatic segmentation methods in medicine are being increasingly applied to assist physicians diagnose and plan treatment while being more precise, faster and less invasive than traditional manual techniques . This study aims at examining whether it is possible to train a computer program for automatically segmenting abdominal organs out from Magnetic Resonance Imaging (MRI) by feeding information about a reference volume only.\" Full Text",
    "> An Active Galaxy emits, in addition to ordinary stellar light which it shares with other galaxies like our own Milky Way, unusually strong radiation in a part of electromagnetic spectrum that we call X-rays.Also remarkable are black hole mass estimates...\n\nSaid another way an AGN has a disproportionately larger proportion of radiators - stars whose energy output exceeds solar levels  than our Galaxy and most every galaxy. A high correlation between supermassive central black holes and these extraordinarily luminous and distant AGNs appears likely, according to NASA astronomers. That means that more mass is converted at higher rates into visible wavelengths where we can see them  gamma rays (including microwave radio), infra-red, visual and ultra violet; but also in X-ray energies. Thus this work proposes an interpretation of the properties exhibited by such AGNs based on its model of dark matter halos around all galaxies including a dense core within the nuclear zone. This cores gravitational field acceleration causes greater densities in those regions causing higher degrees of internal stress leading to intense thermodynamic heat. Such energy release is then coupled to prodigious particle emissions (mostly photons) at increasingly elevated energetic conditions through successively longer wavelengths towards the far ultraviolet, x ray region of the EM spectrum. Its believed there are two distinct types of AGNs characterized as Seyfert (or X-ray binary) or quasars (quasi-stellar objects) based largely upon their characteristic spectral features observed in various bands along said spectrum. The present day luminosity of type 2 Seyferts appear relatively moderate compared to quasar types, whereas type 1s emit at even lower flux amplitudes. We will compare some simple models used to calculate surface temperature profiles versus known observations regarding color temperature curves and emission characteristics of AGN variants. These models assume a basic spherical symmetry about a point source although one should note that much of what characterizes these objects is inherently asymmetrical if taken in context of the local environs where they reside. Therefore each object possesses a unique set of circumstances that would need careful investigation before drawing any hasty conclusions. Nevertheless, these",
    "> In contrast to the homogeneous case, where an invariant of a Riemannian manifold is determined by its underlying geometry, in the general setting notions of invariants are highly non-unique and not always meaningful. Still, there is a canonical way to construct such invariants, the so-called $S^2$-invariant. Here we present a canonical, geometrically defined, invariant for G_2 manifolds and generalise the construction to the setting of Riemannian manifolds admitting a parallel Clifford multiplication. The corresponding invariant turns out to be equivalent to the so-called G-invariant, which was introduced in 1953 by Berger and O'Neill.\n\nCongratulations to Dmitry Vaintrob and the paper's other authors, including MGK and John Parker.\n\nA couple of points:\n\n- Dmitry Vaintrob has been a long-time reader of this blog (hi, DM), and has helped educate me about G_2 geometry. For instance, see here.\n- Somewhat related to this post, see this earlier post with links to papers by Dmitry Vaintrob. The papers are about the G-invariant mentioned in the summary above. Here are two relevant papers: [1a link] and [1b link].\n- I posted a few years ago about G_2 geometry here.\n- My interest in 3D manifold geometry in general (and G_2 geometry in particular) is a legacy thing from my work on my PhD thesis. For instance, see here and here.\n- On a completely different topic, last year we ran a series here and this week I wrote about the 2021 ACM Prize in Computing honorees.\n\nI will end with this tweet:\n\n## Update (October 4, 2021)\n\nA couple of readers wrote to me and pointed me to this paper on arxiv.org:\n\nTitle: The G-Invariant, G-Elevated Spin^{c} Structures, and Generalized Clifford Algebras\nAuthors: Katherine Crouch (University of Oregon), Dmitry",
    "> In this work, we propose an unsupervised learning framework to guide semi-supervised histopathology image segmentation with unlabeled data. We first train a deep convolutional neural network (CNN) on unlabeled images and then use it as a feature extractor in our proposed model. Our method consists of two main components: 1) A CNN based encoder that takes as input both labeled and unlabeled images and outputs their corresponding features; 2) An attention mechanism that learns to focus on regions where the labeling information is more reliable. This allows us to leverage the large amount of available unlabeled data while still taking into account the limited number of labeled samples. Experiments show that our approach outperforms state-of-the-art methods by a significant margin when using only a small fraction of labeled data.",
    "The widespread deployment of AVs requires that they meet extremely stringent safety standards comparable to those expected in human drivers, yet also scale up across cities around the world. A key tool to ensuring safe driving behavior and evaluate their performance on many different road scenarios would be realistic synthetic test environments. These environments, however, need to offer challenging interactions between AVs and humans; this has driven interest in crowd modeling - using deep neural networks (DNN) trained on existing AV datasets - such as Argoverse for video simulation . However, previous methods cannot generate complex scenes with fine grain level spatial control over objects or even scene layouts, making it particularly difficult to simulate dense crowds or interesting geometries like corners. We propose GEOSIM, an approach for generating geometrically correct synthetic videos that can better capture real traffic rules and more faithfully model rich environmental elements. Specifically for AV scenarios, we make two key contributions: 1) Incorporating detailed local geometry information into our DNN crowd model allows us to generate accurate multi-scale and geometrically consistent predictions for pedestrian trajectories without requiring ground truth labels at every timestep during training, thus enabling large scale training with massive scalability and little data annotation needed; 2) Our proposed end-to-end neural network architecture can produce convincing and diverse synthesized scenes matching users specifications about target scenes including number of people, car density/traffic light status etc. Such capability frees up developers' time by automatizing time intensive tasks associated with high quality interactive and visualization tests for selfdriving vehicles. Further evaluation details are described below [1]. [1] PLEASE REFER TO THE IMAGE CAPTIONS FOR CREDITS AND ATTRIBUTION",
    "> The field of computer vision and multimedia is on the verge of a revolution. A significant number of applications have adopted deep learning techniques, specifically in the case of convolutional neural networks (CNN), and thus, CNN has revolutionized the area of image and video processing. In this work, we aim to develop a CNN network for real-time instance semantic image segmentation. To achieve this objective, we perform an exhaustive survey of published literature that implements instance semantic image segmentation for all available categories, and then present a novel framework that achieves significant improvements in the state of the art in terms of both performance and speed. Therefore, a novel CNN network called Real-Time Deep Semantic Image Segmentation Network (RTD-SIS-Net) that is designed to perform semantic image segmentation and to achieve real-time speed is presented in this study. In RTD-SIS-Net, we propose to use the deconvolutional layers instead of the fully convolution layers of Fully Convolution Networks (FCN) to create dense and precise segmentation maps to provide better quality for semantic image segmentation. In addition, we propose to apply the 1  1 and 3  3 convolution layers interweaved to significantly increase the quality of the segmentation maps. In addition, the proposed network in this study is more powerful than all existing methods, which results in more efficient utilization of the GPUs to achieve real-time performance. Furthermore, extensive experiments on numerous well-known datasets demonstrate that the proposed CNN achieves state-of-the-art accuracy and real-time performance for image segmentation.\n\nImage courtesy: Pixabay.",
    "Abstract:\n\nThis paper presents a mathematical model for the electrostatic\n  behavior of a charge- or current-controlled active constrained layer\n  (ACL) beam. The ACL beam is a thin, flexible, and conductive\n  structure that is sandwiched between two dielectric layers. The\n  ACL beam is actuated by applying a voltage or current to the\n  conductive layer. The ACL beam is modeled as a two-dimensional\n  beam with a nonlinear electrostatic potential energy. The electrostatic\n  potential energy is derived using the principle of virtual work.\n  The ACL beam is modeled as a nonlinear system with a nonlinear\n  potential energy and a nonlinear damping term. The ACL beam is\n  modeled as a nonlinear system with a nonlinear potential energy and\n  a nonlinear damping term. The ACL beam is modeled as a nonlinear\n  system with a nonlinear potential energy and a nonlinear damping\n  term. The ACL beam is modeled as a nonlinear system with a nonlinear\n  potential energy and a nonlinear damping term. The ACL beam is\n  modeled as a nonlinear system with a nonlinear potential energy and\n  a nonlinear damping term. The ACL beam is modeled as a nonlinear\n  system with a nonlinear potential energy and a nonlinear damping\n  term. The ACL beam is modeled as a nonlinear system with a nonlinear\n  potential energy and a nonlinear damping term. The ACL beam is\n  modeled as a nonlinear system with a nonlinear potential energy and\n  a nonlinear damping term. The ACL beam is modeled as a nonlinear\n  system with a nonlinear potential energy and a nonlinear damping\n  term. The ACL beam is modeled as a nonlinear system with a nonlinear\n  potential energy and a nonlinear damping term. The ACL beam is\n  modeled as a nonlinear system with a nonlinear potential energy",
    "The abstract for the academic paper titled \"Cascade Decoder: A Universal Decoding Method for Biomedical Image Segmentation\" is as follows:\n\nBiomedical image segmentation is a critical task in various medical applications, including diagnosis, treatment planning, and drug discovery. However, the complexity and variability of biomedical images make it challenging to develop effective and robust segmentation methods. In this paper, we propose a novel cascade decoder architecture for biomedical image segmentation. The cascade decoder consists of multiple decoding stages, each of which applies a different decoding strategy to refine the segmentation result. The first stage uses a traditional convolutional neural network (CNN) to generate a coarse segmentation result. The second stage applies a novel attention mechanism to focus on the most informative regions of the image. The third stage uses a novel graph convolutional network (GCN) to incorporate spatial relationships between pixels and improve the segmentation accuracy. The fourth stage applies a novel multi-scale fusion strategy to combine the segmentation results from different scales and further improve the segmentation accuracy. We evaluate the cascade decoder on several benchmark datasets and demonstrate its effectiveness in improving the segmentation accuracy compared to state-of-the-art methods. The cascade decoder is a universal decoding method that can be applied to various biomedical image segmentation tasks, making it a valuable tool for medical researchers and practitioners.",
    "Title: Measurement-Device-Independent Quantum Key Distribution with Modified Coherent States\nAbstract: We present a protocol for measurement-device-independent (MDI) quantum key distribution with modified coherent states. Our modified coherent states enable us to generate more entangled photons, reducing the number of qubits required for secure communication over long distances. Moreover, our MDI protocol allows for efficient use of these entangled photons by dynamically adjusting the encoding and decoding strategies based on the individual measurements performed on each device. This approach offers significant advantages over existing MDI protocols in terms of both robustness against noise and scalability up to large numbers of qubits. In particular, we demonstrate that our protocol can provide secure transmission rates close to 10 bits per second for more than 34 kilometer distance using only four photonic qubits and an error correction code capable of detecting, mitigating, and correcting errors caused by depolarization effects. The protocol's simplicity also makes it suitable for implementation in realistic settings. Overall, our work advances the field of MDI quantum key distribution by introducing novel techniques for handling correlated measurements, which has become increasingly important in recent years due to advances in superconductive detectors and other high-performance sensors.",
    "The study presents a quantitative test of general theories of the intrinsic laser linewidth. The authors used experimental data from various sources to investigate the relationship between the linewidth and other parameters such as cavity length, mirror reflectivity, and optical power. They found that the linewidth is proportional to the inverse of the cavity length and directly related to the optical power. These results are in agreement with theoretical predictions and provide evidence for the validity of general theories of the intrinsic laser linewidth.",
    "Medical Matting: A New Perspective on Medical Segmentation with Uncertainty\n\nAbstract:\n\nMedical imaging plays a crucial role in the diagnosis and treatment of various diseases. Segmentation of medical images is a critical step in the analysis of these images, which involves identifying and separating the objects of interest from the background. However, medical images are often noisy, and the objects of interest may have varying shapes, sizes, and orientations. In this paper, we propose a new approach to medical image segmentation that incorporates uncertainty into the segmentation process. Our approach, called medical matting, uses a probabilistic model to represent the uncertainty in the segmentation process. We demonstrate the effectiveness of our approach on several medical image segmentation tasks and show that it outperforms traditional segmentation methods. Our work provides a new perspective on medical image segmentation and opens up new avenues for research in this area.",
    "Variational image segmentation is a widely used technique to partition images into multiple regions based on their pixel intensities. However, it can often suffer from blurring and noise caused by errors in the data acquisition or processing steps. In this paper, we present a variational image segmentation model coupled with image restoration algorithms that simultaneously segments an image and restores its structure from degradation.\r\n\r\nWe use a weighted average as the prior distribution over the intensity map, allowing the model to capture complex intensity patterns while considering spatial constraints. We also incorporate a regularization term to penalize large region sizes, which prevents overfitting and promotes cohesive segmentation boundaries. Our approach uses Bayesian optimization techniques to optimize hyperparameters such as learning rate, lambda value, and number of iterations, yielding better performance compared to fixed parameter settings.\r\n\r\nTo illustrate our method's effectiveness, we tested on various medical and satellite imagery datasets, achieving state-of-the-art segmentation results with minimal manual tuning of parameters. For example, we achieved 98% accuracy on the TMTA dataset in less than two minutes using our proposed method. Moreover, our approach outperforms competing methods by up to 10% when incorporating additional denoising and smoothing operators during analysis.\r\n\r\nOverall, our work demonstrates how combining segmentation and restoration objectives can improve image analysis outcomes while simplifying the user interface for both experts and non-experts alike.",
    "This paper presents an analysis of vision-based abnormal red blood cell classification. The study explores the use of computer vision techniques to identify abnormal red blood cells from normal ones. The proposed approach involves the use of machine learning algorithms to analyze images of red blood cells and classify them as either normal or abnormal. The study uses a dataset of red blood cells images, which are labeled as either normal or abnormal. The results show that the proposed approach is highly accurate and can classify red blood cells with a high degree of accuracy. The study contributes to the development of vision-based systems for the detection of abnormal red blood cells, which can have important applications in medical diagnosis and treatment.",
    "This study aims to address a key challenge in image processing: accurately delineating objects with blurry boundaries. We propose a novel approach that combines semantics and convolutional neural networks (CNNs) for automated blade segmentation of CT images. Specifically, we introduce an encoder network whose outputs are conditioned on high-level semantic features, allowing it to provide more interpretable results than prior approaches. Our findings demonstrate significant improvements over current state-of-the-art methods, with increased accuracy and robustness across various datasets. Overall, our work represents an important advancement towards more precise and informative medical imaging analysis.",
    "The abstract for the academic paper titled \"Rethinking Atrous Convolution for Semantic Image Segmentation\" is as follows:\n\nIn this paper, we propose a novel approach to semantic image segmentation using atrous convolution. Atrous convolution is a type of convolution that allows for the processing of images at multiple scales simultaneously. We show that by using atrous convolution, we can achieve state-of-the-art performance on semantic image segmentation tasks with fewer parameters and computational resources. We also introduce a new loss function that is specifically designed for semantic segmentation tasks, which further improves the performance of our model. Our results demonstrate the effectiveness of our approach and show that it outperforms state-of-the-art methods on several benchmark datasets.",
    "Human mobility patterns at the smallest scales refer to the movement of individuals within a specific environment, such as their homes or neighborhoods. This research area is concerned with understanding how people move and interact with their surroundings on a daily basis. Studies in this field have shown that human mobility patterns are influenced by various factors, including social, economic, and environmental factors.\n\nOne important aspect of human mobility at small scales is that it can have significant impacts on public health and safety. For example, studies have found that individuals who engage in high levels of physical activity, such as walking or jogging, are less likely to develop chronic diseases like obesity and diabetes. Additionally, access to safe areas for exercise and transportation has been linked to lower rates of crime and violence.\n\nAnother key area of research in human mobility at small scales is the role of technology in shaping these patterns. As technologies continue to evolve, they are increasingly being used to track individual movements and inform urban planning decisions. However, concerns about privacy and bias in algorithmic decision-making processes must also be considered.\n\nOverall, the study of human mobility patterns at the smallest scales provides valuable insights into how we use our environments and how these interactions impact our lives. By understanding these patterns, policymakers and urban planners can make more informed decisions that promote health, safety, and sustainability for all members of society.",
    "Title: Entangler and analyzer for multiphoton maximally entangled states using weak nonlinearities\n\nAbstract: Entanglement is a fundamental phenomenon in quantum mechanics that has attracted significant attention due to its potential applications in quantum communication, cryptography, and information processing. Maximally entangled states (MES) are a class of entangled states that exhibit the highest level of correlation between their entangled modes, which makes them extremely useful in these applications. Weak nonlinearities, such as those induced by optical fibers, can be used to entangle photons and generate MES. In this paper, we introduce an entangler that can generate MES using weak nonlinearities, and present an analyzer for measuring and characterizing the entangled states generated by the entangler. We demonstrate the effectiveness of the proposed entangler and analyzer using numerical simulations and experimental demonstrations. Our results show that the proposed entangler can generate MES with high fidelity, and the analyzer can accurately measure and characterize the entangled states, including their quantum state fidelity and entanglement degree.",
    "The paper \"SUSAN: Segment Unannotated image Structure using Adversarial Network\" presents a novel approach for segmenting unannotated images using adversarial networks. The proposed method involves training a generative adversarial network (GAN) to generate synthetic images with similar structure to the input image, and then using this generated image to segment the original image. The GAN is trained to minimize the difference between the generated image and the input image, while also maximizing the difference between the generated image and a noise image. This allows the GAN to learn the underlying structure of the input image, which can then be used to segment the image. The paper demonstrates the effectiveness of the proposed method on several benchmark datasets, and shows that it can achieve state-of-the-art performance on some tasks.",
    "The purpose of this study is to investigate the effectiveness of serious games as a tool for promoting environmental consciousness education among residents in their daily lives. This research aims to explore how serious games can be used to raise awareness about environmental issues and encourage sustainable behaviors, such as recycling and energy conservation.\n\nThe study will use a mixed-methods approach, including surveys, interviews, and observations. Participants will include residents from different age groups and socioeconomic backgrounds who have experience with serious games related to environmental education.\n\nThe results of this study will provide insights into the potential benefits of using serious games for human environmental consciousness education. It will also identify factors that influence the adoption and effectiveness of these games, such as game design, engagement, and motivation. Overall, this research has important implications for educators, policymakers, and developers seeking to promote sustainability through interactive learning experiences.",
    "Tree structures are used to represent hierarchical data in various fields such as mathematics, computer science, biology, finance, and more. Generalizing the concept of a binary tree, our study proposes an algebraic framework based on Boolean rings that allows us to describe trees with any number of branches. This approach leads us to define new concepts such as multichannel nodes and multiaxis edges.\n\nOur work also presents mathematical foundations for analyzing branching structures, including properties related to connectivity and depth distribution of multibranched paths. We establish a mapping between this generalized tree model and standard tree models in the literature, enabling comparison and interpolation techniques.\n\nFurthermore, we extend these concepts from binary trees to infinite-dimensional representations of trees using distributional vectors, allowing us to characterize diverse nonlinear networks like quantum entanglement, neural networks, and social networking protocols. Our results demonstrate potential applications of these algebraic and logical descriptions in numerous areas where graph and network analysis is crucial.",
    "Abstract:\nSemantic segmentation involves assigning predefined pixel-level labels to images. Recent approaches have shown promising results by incorporating contextual information such as object detection and classification using deep learning techniques. However, these methods still suffer from significant limitations due to their limited understanding of image context and its impact on semantics. This work addresses the issue of mining relevant features that capture the relation between pixels and other objects or regions in the image. Specifically, we investigate the use of external image descriptions and temporal context beyond the immediate local image neighborhood to improve semantic segmentation performance. Our approach is based on a novel combination of multi-task and generative models, where each region is predicted conditioned on both the image context and external sources of knowledge. We evaluate our proposed method on public benchmarks and demonstrate significant improvements over state-of-the-art baselines, particularly when analyzing complex videos sequences. Overall, this research represents an initial step towards more realistic and interpretable modeling of visual content.",
    "Fourier transform spectroscopy is a powerful technique used to study the properties of matter. In this paper, we apply it to investigate the behavior of a spin-orbit coupled Bose gas. We use numerical simulations and analytical calculations to analyze the spectra obtained from the system. Our results show that the spectrum exhibits distinct features due to the presence of the spin-orbit coupling. These features include a broadening of the spectral lines and an appearance of new peaks at specific frequencies. We also find that the intensity of these peaks depends on the strength of the spin-orbit interaction. Our work provides valuable insights into the behavior of spin-orbit coupled systems and has important implications for future experiments in this field.",
    "The abstract for the academic paper titled \"A Kinetic Model for Cell Damage Caused by Oligomer Formation\" would likely describe the study's objective, methodology, and key findings. Here is an example of an abstract for this paper:\n\nTitle: A Kinetic Model for Cell Damage Caused by Oligomer Formation\n\nBackground: Oligomer formation is a critical process in the development of various diseases, including Alzheimer's disease, Parkinson's disease, and diabetes. However, the mechanisms underlying the cell damage caused by oligomer formation are not well understood.\n\nObjective: The objective of this study was to develop a kinetic model for cell damage caused by oligomer formation.\n\nMethodology: The kinetic model was developed using a combination of experimental and computational approaches. The experimental approach involved the use of cell culture and biochemical assays to measure the effects of oligomer formation on cell viability and function. The computational approach involved the use of mathematical modeling to simulate the interactions between oligomers and cells.\n\nResults: The kinetic model showed that oligomer formation leads to the activation of various signaling pathways that ultimately result in cell damage. The model also identified key factors that modulate the rate of oligomer formation and cell damage, including the concentration of oligomers, the type of oligomers, and the cellular environment.\n\nConclusion: The kinetic model developed in this study provides a useful framework for understanding the mechanisms underlying cell damage caused by oligomer formation. The model can be used to predict the effects of different interventions on cell damage and to identify new targets for the prevention and treatment of diseases caused by oligomer formation.",
    "Open-set person re-identification is the task of identifying a person in a new image, even if they were not seen before in the training data. This is a challenging problem in computer vision, as it requires the model to generalize to new individuals and handle variations in pose, lighting, and appearance. In this paper, we present a novel approach to open-set person re-identification using a deep learning framework. Our model is trained on a large dataset of person images, and employs a combination of convolutional neural networks and attention mechanisms to learn robust features that can be used to identify individuals across different images. We evaluate our model on several benchmark datasets, and show that it outperforms state-of-the-art methods in terms of accuracy and robustness. Our work represents a significant advancement in the field of person re-identification, and has important applications in areas such as security, surveillance, and social media.",
    "Nonlinear Markov random fields (NMRFs) are a powerful tool in modeling complex systems with temporal dependencies. However, learning NMRFs can be challenging due to their high-dimensional and nonlinear nature. In this paper, we propose an efficient algorithm for learning NMRFs using backpropagation. Our approach involves approximating the gradient of the likelihood function using finite differences and iteratively updating the parameters of the model through stochastic gradient descent. We demonstrate the effectiveness of our method on several real-world datasets and show that it outperforms other state-of-the-art methods in terms of accuracy and computational efficiency.",
    "The snow leopard is a fascinating species of big cat that inhabits the mountain ranges in Central Asia. In this study, we explore the permutation patterns of snow leopards within their natural habitat. Specifically, we examine the even and odd threading patterns of these animals as they move through their environment. Our findings suggest that snow leopards tend to follow an alternating pattern of movement, with each leap or bound consisting of either an even or an odd number of steps. This pattern may be related to the way snow leopards navigate their rocky terrain, as well as their hunting strategies. Overall, our research provides valuable insights into the behavioral ecology of this iconic species.",
    "In this study, we explore graded comodules over commutative and associative algebras. We discuss several important properties that allow us to characterize classes of graded comodules with appropriate projective invariants. Specifically, we provide a new class of graded comodules called $G$-graded comodules, which are associated with groups $G$ acting on their underlying modules. We obtain explicit characterizations of these objects and prove some of their fundamental properties. Additionally, we investigate the relationship between graded comodules and other well-known structures like associators, braids, and group actions on posets. Finally, we give an application of our results to categorify certain graded comonad structures in terms of simplicial sets.\r\n\r\nKeywords: graded comodudes, algebraic combinatorics, category theory, homotopy type theories",
    "The Pinning Model with Heavy Tailed Disorder is a mathematical model used to study the behavior of systems that exhibit a heavy-tailed distribution of disorder. This model is particularly useful in understanding the behavior of systems that are subject to random perturbations or fluctuations, such as those found in materials science, physics, and computer science.\n\nThe model consists of a set of interacting particles that are subject to a random potential energy landscape, which is generated by a heavy-tailed distribution of disorder. The particles are allowed to move and interact with each other, and their behavior is governed by a set of equations that describe the dynamics of the system.\n\nOne of the key features of the Pinning Model with Heavy Tailed Disorder is the presence of a critical point, which separates two distinct phases of behavior. In the disordered phase, the particles are randomly distributed throughout the system, and the system exhibits a high degree of disorder. In the ordered phase, the particles tend to form clusters or domains, and the system exhibits a lower degree of disorder.\n\nThe behavior of the system near the critical point is particularly interesting, as it is characterized by a power-law divergence in the correlation length and the susceptibility. This behavior is reminiscent of critical systems in statistical mechanics, such as the Ising model, and has important implications for the behavior of real-world systems.\n\nOverall, the Pinning Model with Heavy Tailed Disorder provides a powerful tool for understanding the behavior of systems that are subject to random perturbations or fluctuations. By studying the behavior of these systems near the critical point, researchers can gain insights into the underlying mechanisms that govern their behavior and develop new strategies for controlling and manipulating these systems.",
    "Tracking fast neutrons refers to the monitoring and recording of their movement and interactions within various materials. This is an important research topic due to the potential applications of fast neutrons in fields such as nuclear energy, medicine, and material science. Fast neutrons have unique properties that make them useful for a variety of purposes, including neutron activation analysis, neutron imaging, and neutron diffraction.\n\nOne of the main challenges in tracking fast neutrons is their high energy and short range, which makes them difficult to detect and track. Various methods have been developed to overcome this challenge, including the use of scintillation detectors, semiconductor detectors, and passive and active neutron moderators.\n\nIn this paper, we review the current techniques and technologies used for tracking fast neutrons. We discuss the advantages and limitations of each method and highlight recent advances in the field. We also discuss the challenges that remain in the development of fast neutron tracking systems, such as the need for reliable and cost-effective detection technologies.\n\nOverall, tracking fast neutrons is a complex and challenging task, but it has the potential to unlock a wide range of new applications in various fields. With continued research and development, faster and more efficient methods for tracking fast neutrons will be developed, opening up new opportunities for their use.",
    "The study investigates the spacing distribution of radial projections in tiled vertices. Tiling is a technique used to create patterns with repeating shapes, which has applications in various fields such as architecture, design, and computer graphics. In this study, we analyze the properties of tiled vertices by generating random tilings using different algorithms and measuring the distances between adjacent vertices. We find that the spacing distribution of radial projections follows a power-law, where the probability density function (PDF) decays exponentially with increasing distance from the center vertex. This result suggests that tiling can be used to generate fractal structures with self-similarity at multiple scales. Our findings have implications for understanding the behavior of complex systems and designing efficient algorithms for image processing and rendering.",
    "In this paper, we present a robust output regulation approach for continuous-time periodic systems. The objective of this research is to design a regulator that ensures stable and periodic steady-state error despite disturbances affecting the system dynamics. We utilize the Lyapunov functional technique to design the controller and prove its effectiveness in terms of stability, convergence rate, and robustness against uncertainties in the plant model. Furthermore, we conduct simulation studies to validate our findings and demonstrate the performance of the proposed controller under various conditions. Overall, our contribution provides valuable insights into designing effective controllers for periodically perturbed systems with guaranteed robustness.",
    "In this study, we propose a novel medical image segmentation model called MediaTransformer that utilizes gated axial attention to better capture complex spatial dependencies within medical images. Our proposed method is based on a multi-task convolutional neural network (CNN) architecture, supplemented with global average pooling and gated self-attention to predict semantic segmentation masks in 3D medical datasets such as brain magnetic resonance imaging scans.\n\nThe gated axial-attention mechanism enables our model to weigh the importance of different regions within an input volume during prediction, allowing it to focus on relevant information when making predictions about unknown structures within unseen slices. This gating process enables us to selectively attend only to pertinent information when performing segmentations without compromising performance.\n\nWe evaluate MediaTrans-former using four standard clinical benchmarks including Alzheimer's disease classification and segmentation of multiple brain tumors. The results demonstrate significant improvements over state-of-the-art methods due to its ability to learn more meaningful representations between image data and output labels. Furthermore, our findings suggest that these improved segmentation outputs can aid clinicians in identifying and diagnosing both benign and malignant diseases in neuroimaging studies related to disease detection and prognosis.\r\n\r\nOur work represents a significant contribution to the field of medical image analysis by providing a high-performing, interpretable, and generalizable approach to segmenting and classifying neuroanatomical features from MRIs.",
    "The abstract of the academic paper titled \"Spatio-angular Minimum-variance Tomographic Controller for Multi-object Adaptive Optics systems\" is as follows:\n\nThis paper presents a novel controller design for multi-object adaptive optics (AO) systems. The proposed controller utilizes spatio-angular minimum variance tomography to estimate the wavefront aberrations in each object plane, and then applies an iterative algorithm to correct these aberrations using the AO system's actuators. The controller also incorporates constraints on the maximum allowable distortion in each object plane to ensure that the final image quality meets the desired specifications. Simulation results demonstrate the effectiveness of the proposed controller in reducing the root mean square error between the actual and desired wavefronts, while maintaining good contrast and resolution in all objects.",
    "The stretch-length tradeoff is a fundamental problem in geometric networks, where the goal is to find the shortest path between two points while preserving certain properties of the network. In this paper, we study both average case and worst case scenarios for this problem. We first prove that there exists an algorithm that can achieve a stretch factor of O(log n) on any geometric network with n vertices, assuming that the distances between adjacent vertices are known. This result holds even if the network has negative curvature or arbitrary edge weights. We then extend our analysis to the worst case scenario, where the distances between adjacent vertices may be unknown. In this case, we show that it is NP-hard to find a path with a stretch factor better than O(n^2). Our results have important implications for applications such as routing in wireless networks and geographic information systems.",
    "The paper presents a new approach to the design of robust controllers for regular linear systems with infinite-dimensional exosystems. The proposed method is based on the use of Lyapunov-Razumikhin functions and the theory of Lyapunov-Razumikhin inequalities. The main result of the paper is the existence of a robust controller that ensures the stability of the closed-loop system, even in the presence of uncertainties in the exosystem. The proposed controller is also shown to be optimal in the sense of minimizing the norm of the closed-loop transfer function. The paper also provides a stability analysis of the closed-loop system and discusses the effects of different types of uncertainties on the stability of the system. The results of the paper have important implications for the design of robust control systems in a wide range of applications, including control of chemical processes, power systems, and communication networks.",
    "The field of digital pathology has seen rapid advancements in recent years due to the availability of large amounts of medical imaging data. However, one major challenge is identifying patterns within this data that can aid in disease diagnosis and treatment planning. In this study, we propose an unsupervised community detection algorithm based on the Potts model Hamiltonian, which is both efficient and effective at identifying clusters within complex networks. We demonstrate the effectiveness of our approach through application to digital pathology datasets, where we identify distinct regions of interest within tissue samples that are associated with specific diseases or conditions. Our results show promising potential for improving diagnostic accuracy and informing personalized treatment plans in the field of digital pathology.",
    "The fuzzy c-means clustering algorithm is a widely used technique in data analysis, which assigns each data point to one of k clusters with varying degrees of membership. This approach has several limitations such as sensitiveness to initial centroids and difficulty in handling nonlinearly separable clusters. To address these issues, we propose an extension to the fuzzy c-means algorithm called the vector membership (VM) method, where instead of assigning each data point to a single cluster at any given time, it first identifies its closest cluster center in terms of the Euclidean distance metric. Then, the membership value of each data point is updated based on how well it deviates from this center within its cluster boundaries, where neighboring clusters share common boundary points by definition. By iteratively applying this rule until convergence or reaching a maximum number of iterations, the VM method reduces computational complexity while preserving accurate results compared to other known techniques such as DBSCAN and OPTICS. We verify our model through experiments on synthetic and real datasets, demonstrating effectiveness in identifying complex clusters and determining their similarities more accurately than traditional methods. Our contribution to this field is therefore significant since it provides a valuable tool in tackling challenging cases when conventional optimization methods fail or require extensive computational resources.",
    "The abstract for the academic paper titled \"CAKES: Channel-wise Automatic Kernel Shrinking for Efficient 3D Networks\" is as follows:\n\nIn this paper, we propose a novel method called CAKES (Channel-wise Automatic Kernel Shrinking) for efficient 3D convolutional neural networks (CNNs). The proposed method automatically shrinks the kernel size of each channel in the 3D convolutional layers, which significantly reduces the computational cost and memory usage of the network. The shrinking process is performed in a channel-wise manner, which allows the network to adapt to different input sizes and channel dimensions. We demonstrate the effectiveness of the proposed method on several benchmark datasets, including the MRI-Net and the 3D U-Net, and show that it can achieve state-of-the-art performance with significantly reduced computational cost.",
    "Title: A New Model for Heating of Solar North Polar Coronal Holes\nAbstract: The solar north polar coronal hole is an area of intense magnetic activity in the sun's upper atmosphere. This region experiences extremely high temperature differences between the cold, dark interior and the hot outer edges. In this study, we present a novel model for understanding how these extreme conditions are maintained within the coronal hole. Through extensive data analysis and numerical simulations, we have identified a mechanism that allows excess heat to be transferred from the periphery of the coronal hole towards its center, effectively creating a 'warm bubble.' Our model also accounts for fluctuations in the temperature gradient across the coronal hole, as well as variations in wind speed and direction. The results of our investigation provide valuable insights into the behavior of the solar north polar coronal hole and contribute significantly to our understanding of the physics behind this unique celestial phenomenon.",
    "The abstract of the academic paper \"A Large-Scale Benchmark for Food Image Segmentation\" is as follows:\nIn this paper, we present a comprehensive benchmark for food image segmentation, evaluating state-of-the-art methods on a large-scale dataset. Our benchmark, which includes 21 segmentation algorithms and over 50000 annotated images, represents the most extensive evaluation of food image segmentation models to date. We also introduce new metrics for segmentation accuracy that account for the complexities of food images. Our results show that deep learning models, specifically convolutional neural networks, outperform traditional image segmentation methods. However, we also identify several areas of improvement in the performance of these models, and highlight the importance of data augmentation and hyperparameter tuning in achieving state-of-the-art results. Overall, our benchmark provides a valuable resource for researchers and practitioners working in the field of food image segmentation.",
    "We introduce a family of Nikishin systems with periodic recurrence coefficients, which generalize the classical periodic Nikishin system. We study the asymptotic behavior of these systems for large values of $N.$ We obtain that the number of states in the Markov partition of the system divided by $N$ converges to a well-defined limit as $N\\rightarrow\\infty.$ The limits we obtain satisfy the so-called Weiss condition, which ensures the convergence of the corresponding entropy functional. We also show that the Markov partition is asymptotically optimal. Our results show that in the periodic case the recurrence coefficients form an ergodic structure on the state space of the system, and we describe this structure in terms of the Weiss condition. Our proofs use a combination of the classical Nikishin method and techniques from Markov partitions.",
    "The field of computer vision has seen a significant increase in interest and development over recent years, with deep learning techniques playing an integral role. One such technique is the use of convolutional neural networks (CNNs) to segment surfaces in 3D space. However, traditional CNN architectures have limitations when it comes to handling complex surface geometries and hierarchical structures. In this study, we propose a novel approach that utilizes contour tree hierarchy to improve the performance of deep neural network-based 3D surface segmentation. Our method involves first constructing a contour tree representation of the input surface, which captures its topological structure at multiple scales. We then apply a series of convolutional layers to extract features from each level of the contour tree, followed by a fully connected layer to classify the segments. Experimental results show that our proposed method outperforms state-of-the-art methods in terms of accuracy and efficiency, particularly for surfaces with intricate shapes and hierarchical structures. Overall, our work demonstrates the potential of using contour tree hierarchy as a powerful tool for improving the performance of deep neural network-based 3D surface segmentation tasks.",
    "This paper presents a theoretical analysis of the time reversal of light by linear dispersive filtering near atomic resonance. The authors demonstrate that by using a linear dispersive filter, it is possible to reverse the direction of time flow in a small region around an atomic resonance. The paper provides a detailed mathematical model of the process and shows that it is possible to achieve a high degree of time reversal with a relatively simple experimental setup. The results of this study have important implications for the development of new technologies in the field of quantum mechanics and could lead to new insights into the fundamental nature of time.",
    "In this work, we propose an approach to disentangle human error and ground truth (GT) information when segmenting medical images using deep learning models trained on crowdsourced annotations with varying levels of quality [1]. We show that our method can be used as part of any segmentation pipeline where GT labels are available but not perfect or complete; it also provides insights into how well these methods perform under different conditions by comparing their performance against each other across multiple datasets containing various types/levels errors within them such data sets include those collected via Amazon Mechanical Turk(AMT), CrowdFlower etc., which have been shown previously[2]to contain significant amounts noise due mainly two factors- 1.) The lack knowledge about what constitutes good annotation practices among workers who may never before seen anything like image labeling task 2). Poorly designed interfaces leading people make mistakes while trying figure out correct way do things themselves without help others around him her - all combined result poor accuracy rates even after correcting some obvious problems manually beforehand! This problem has plagued researchers working computer vision since its inception decades ago  until now",
    "Abstract:\nWe consider the global attractor problem for a viscous Navier-Stokes system driven by a periodic forcing and with a fast-slow dissipative term. In the framework of a general\n  class of equations that can describe the evolution of turbulent flows with rapid rotation, it is proved that the global attractor exists and it is connected. Then, we study its geometrical and topological properties and,\n  in particular, it is shown that the global attractor for the nonautonomous system has a finite number of singular points. Furthermore, a connection with dynamical systems is provided, by\n  obtaining the local asymptotic stability properties of the attractor. To achieve all these results, a suitable time-parametrization of the system is found and the semigroup approach on the abstract\n  phase space is used.\n\n\nA: In the book Geometric Theory of Dynamical Systems, Flix Hrau states in section 4.2.6, p. 145, of Chapter 4 in volume one of the series, \"... a general theory of the construction of the global attractor via finite-dimensional reductions\n ... was given by Kupka [25], and it was developed by J.-P. Eckmann and O. Peli [21]....\"\nHrau gives p. 146, as reference 25, \"Global attractors for semigroup actions defined on Hilbert spaces\", M. Kupka (1996), J. Funct. Anal. 152, pp. 263-299.",
    "(For an explanation, check out this great video by mathematician Eric Weisstein.) That's just what we need to apply here  if I can prove it in one direction (i0 = i2) using another method and then show that my proof has implications on its own existence elsewhere based solely upon principles already accepted as proven facts within modern physics theory like entropy or chaos  but which have not yet been shown mathematically independent variables? The challenge now becomes clear; take away ALL other evidence excepting those laws deemed reliable enough when considering their validity during tests performed under optimal experimental conditions without external interference until there isn't any longer even possible outcome outside these strict constraints.\" -the author himself seems baffled- But you may also be aware though unawarely so perhaps since being introduced into science history back at least 100 years ago through his famous equation E=mc^3 where energy equals mass times speed squared divided minus 1 plus Planck constant over 4 pi squared root 5 multiplied twice three half power Noughts cubed all together equal zero point five twenty two oh eight less nine fifth powers X thousandths dot four hundred threes before dividing finally divide everything apart again afterwards thus arriving once more right after initially splitting time reversed equally amongst particles travelling along lightspeed path towards opposite directions thereby creating matter itself much later than originally assumed due mainly scientific theories supporting such claim while simultaneously demonstrating factually incorrect calculations throughout previous attempts leading up last century till very recent days today however could anyone really think seriously doubt about possibility existing absolute truth true perfection always exists somewhere although currently hidden deep inside every single particle universe expanding constantly outward each millisecond second minute hour day week month year never stopping grow bigger higher faster stronger brighter hotter colder unless stopped prevented somehow otherwise wise end result inevitable reality sooner rather late because doesn t stand chance against nature forceful way things work going downhill quick fast forever onward ever forward no choice left behind look ahead straight road pathway highway future destiny hope happiness despair darkness hopelessness bright daylight starry night lonely solitude serenity emptiness infinite nothing loneliness silence noisy shouting screaming echo sound echoes reverberate ringing humming whistling buzzer singing birds chirping animals rustle scratching walking wind whisper voices shout shouts scream laughter crying voice calling names greetings chattering hello goodbye friends neighbors strangers meeting part ways passing face faces smile smiles hug goodbyes handshakes waves nods winks eye contact glances recognition memories remembrance forgotten lost past present",
    ">Referring image segmentation (RefSeg) estimates the object that matches a given reference in an image. In existing methods, the reference is extracted by the convolutional feature map in a single network, which suffers from two problems as follows. First, a reference may correspond to an extremely small area or an entire image. Second, this method only can perceive the local patterns in the feature map and fails to explore a global perception of the reference and image pair. To this end, we propose a novel RefSeg framework, named CMF. CMF consists of three modules, namely a global module, a local module, and a mask prediction module. Specifically, given an image and a reference, the global module first extracts an attention-aware global representation based on a global matching strategy. Then, the local module extracts a local representation according to the visual relationship between the image and reference. To eliminate the semantic gap between the global and local representations, a cascaded multimodel fusion module (CMF module) with multi-attention and multiple-model is proposed to fuse these two representations. Finally, a mask prediction module is proposed to predict a semantic mask based on the global and local representations. In particular, the CMF module leverages the global perception to perform a better reference refinement task, and the local perception further enhances the discriminability of the global perception by introducing a local perception. The experimental results on two benchmarks demonstrate that our method outperforms existing state-of-the-art RefSeg methods.\n\n\nIntroduction\nReferring image segmentation (RefSeG), which refers to detecting and masking the target by specifying a natural language description [1], has been paid increasing attention recently as a fundamental task in the computer vision field. It requires machines to extract the target mentioned by text and segment it into a semantic mask. Recently, a number of methods for this task have been proposed [2][3][4][5][6]. Among them, deep learning-based methods [3][4][5] have rapidly achieved considerable progress. However, there are still many challenges due to their nature. For example, the reference mentioned by the text may refer to an extremely small area or a large area that occupies the whole image, making the task more challenging. Another issue is that it is hard to fully identify a target because the visual appearance of objects is",
    "Operational concurrency control is concerned with the implementation of concurrency control algorithms.\nUntil now, operational concurrency control solutions have been focused on providing a consistent view of a database\neven in the presence of high read and write latencies, rather than in the optimization of read and write latencies\nthemselves. Consequently, previous distributed systems research does not discuss the possibility of optimizing the\nperformance of operations themselves to increase concurrency without sacrificing database consistency.\n\nThis paper attempts to address this concern by considering a model of consistent concurrency control at the\noperation level. In particular, the paper proposes a set of distributed operation classes that define an equivalence\nclass for operations and describes the properties of these classes. It is shown that this model can be\nutilized to provide optimal performance for all operations in the presence of arbitrary read and write latencies.\n\nA consistent concurrency control algorithm is then derived that exploits this model. This algorithm is\nimplemented and benchmarked and compared with a number of existing algorithms in the presence of high\nread and write latencies. It is shown that this algorithm outperforms all of its competitors, often\nproviding improvements of up to a factor of 10, while maintaining the desired consistency semantics of the\ndatabase.\n\nThe full text of this research paper can be found at: [Operational Concurrency Control in the Face of Arbitrary Scale and Latency](https://arxiv.org/pdf/1703.01161.pdf)\n\n# Requirements\n\n* Python >= 3.4\n* pip\n\n# Installation\n\nClone or download the repository, then...\n\n```bash\npip install -r requirements.txt\n```\n\n# Getting Started\n\nTo run the benchmarks...\n\n```bash\npython -m benchmark\n```\n\n...will launch a benchmark of all algorithms in the paper. This takes a few hours to run, but provides useful\ninformation about what each algorithm is capable of in comparison with the others.",
    "\"Aerial image semantic segmentation has recently witnessed substantial breakthroughs using deep models. However, these large-scale aerial images often have thousands of classes or objects and it's unclear whether existing segmentation algorithms are suitable for such tasks. Unlike the common practice of leveraging point cloud annotations for object detection/segmentation, we propose to use a point-based feature representation and propose a novel method named PointFlow, which is applicable to a wide range of modern computer vision algorithms. The PointFlow is trained on two phases (a flow prediction phase and a segmentation task). The first phase takes advantage of the sparse 3D point cloud annotations to learn the coarse flows from a sparse 3D point cloud. The flows are then learned through point-wise supervision in the second phase in a self-supervised manner. PointFlow is a generalizable feature which can be easily used in popular 2D CNNs. Extensive experiments on the aerial images with thousands of categories show that PointFlow outperforms its point-based competitors by a large margin. Code and models are available at this https URL.\"\nThe following is the full text of the abstract for a research paper titled \"PointGroup: Segmenting Multi-Instance Scenes with Transformers\" from arxiv.org:\n\"We propose a transformer-based scene segmentation model to address the problem of segmenting multi-instance scenes in autonomous driving. The proposed method is trained end-to-end using a self-supervised learning method that leverages image-level and scene-level semantic segmentation as two auxiliary tasks. As an explicit representation of spatial relationships, the self-attention mechanism in transformers shows potential to learn geometric representations. To this end, we propose PointGroup, which consists of three modules, the self-attention aggregation module, the self-attention aggregation aggregation module and the mask attention module. The two self-attention modules can be treated as a transformer encoder; the mask attention module integrates the information of point features, which is the key to the model's generalization ability. In addition, we use a point-based sparse feature representation, in which each point represents a unique class, resulting in a better feature expression ability and an improved data balance in semantic segmentation. The proposed method outperforms the state-of-the-art methods across multiple metrics in the multi-instance segmentation (MIS) task. We",
    "We consider an evolution problem modeling phase separation in binary fluids, where surface tension effects are taken into account by means \n   of both classical and nonclassical models (the latter being based on gradient flows). The main novelty consists here to include also thermal convection due \nto temperature gradients between phases which leads us naturally towards considering systems governed not only at macroscopic level but rather through coupled PDE's system involving partial differential equations as well ordinary ones describing heat transfer phenomena within each fluid component; this makes our analysis quite challenging since we need first establish existence results even before proving uniqueness properties!",
    "Stochastic PDEs have been used in the study of many systems of interest to physics and chemistry, including fluid dynamics, nonlinear optics, plasma physics, the motion of a polymer chain, etc. Stochastic PDE models are frequently used to describe a system where individual molecules or atoms interact with each other and the rest of the surrounding system or environment stochastically. While the underlying systems are governed by deterministic PDEs, this stochastic influence creates a stochastic PDE for the system as a whole. The most studied type of Stochastic PDE is the ItuKawasaki model of stochastic fluid dynamics.\nThis research paper is not peer-reviewed and has been posted to arxiv.org, a public archive for research papers. All arXiv.org manuscripts can be downloaded for free from the archives website.\nAs the abstract from \"An Introduction to Stochastic PDEs\" explains:\nStochastic PDEs have been used in the study of many systems of interest to physics and chemistry, including fluid dynamics, nonlinear optics, plasma physics, the motion of a polymer chain, etc. Stochastic PDE models are frequently used to describe a system where individual molecules or atoms interact with each other and the rest of the surrounding system or environment stochastically. While the underlying systems are governed by deterministic PDEs, this stochastic influence creates a stochastic PDE for the system as a whole.\nMost examples of stochastic PDEs are non-existent. The ItoKawasaki model of stochastic fluid dynamics is one of the most well known stochastic PDE models. This paper provides an overview of this model, as well as a more general stochastic PDE model that encompasses all forms of stochastic PDEs. It aims to provide an introductory overview of stochastic PDEs. It begins from the basic premise of a random variable and an Ito process, and builds from there. The ItoKawasaki equation uses Itos Taylor-series expansion and the Ito Product Rule to characterize a PDE which relates random variables over time to each other. It concludes with a summary of the ItoKawasaki equation in the form of a stochastic PDE.\nThe following is the full text of the above referenced section of the research paper titled \"An Introduction to Stochastic PDEs\" from arxiv.org entitled \"The ItoKawasaki Equation for Stochastic Fluid Dynamics\":\nIn this section we examine the",
    "Machine learning-based 3D image models play an important role in computational biology, medical imaging analysis [1], drug discovery process design,[2] etc., to provide quantitative data analyses.[35]. Three dimensional Mandibular bone (BM) reconstruction facilitates computer aided clinical diagnosis using dental CBCT images by measuring different morphometric parameters like BM surface area/volume[6]; TMJ internal structure which involves mandibular fossa; condylar morphology assessment as well measurement changes due treatment effects are also analysed effectively via CAD & CAM methods with help MB reconstructed model's contour mesh only if all segments available accurately identified automatically during pre processing stage especially when large group studies have been performed simultaneously or within short time duration otherwise manual task may not be feasible / accurate one practically even though having experienced orthodontists doing same again. This study aims at developing robust semi automatic algorithm capable enough segmenting human skeletal structures including teeth individually alongwith its associated surrounding soft tissue mask completely outlining jawbone correctly so far we know concerned scientific community hasnot reported any such work up till now best part our method doesn't require tedious user interactions rather just initial rough seeds specified manually afterward rest whole procedure takes over itself intelligently based some mathematical rules known already however results expected here donno how much these can convince people around globe either positive negative but will try presenting facts objectively without personal biases whatsoever hope this makes sense few words further explaining what went behind entire development let see then after reading complete manuscript whether reader wants continue next blog post about above said interesting subject related stuff else stop right where it ended since most common reason why folks stopped read half way through seems boredom lack interest themselves resulting loss faith future updates similar content generated us actually believe betterment won battle between them both hence always encourage readers take leap chances explore new frontiers specially those unknown areas filled nothingness yet another attempt make more clearer pictorial explanation given below that'll hopefully clear confusion created among everyone before diving deep into sea details please note red arrows represent proposed methodology blue arrow represents outcome output developed algorithms while green box shows original input obtained directly off shelf software used generate desired result set finally yellow coloured points indicate missing gaps still exists needs fill somehow because they could cause problems later on down line once gets larger number samples run against test cases might get confused sometimes deciding exact location boundaries there're no hard coded things embedded inside code base instead everything comes builtin default functions provided libraries python programming",
    "Abstract: We study the behaviour of a quantum particle interacting with a quantum environment. We start the problem in the mixed state, that is, we assume that  the initial state of the quantum particle is a density matrix. We assume that the quantum environment  consists of a set of quantum harmonic oscillators in a  particular state.  In our analysis we use the density matrix as the main\n  ingredient. The first part of the article is devoted to the theoretical derivation of formulas describing the evolution of the density matrix of the particle. The results are general and have been derived without any\n  approximation. Using the analytic formulas, we carry out\nnumerical calculations of the evolution of the density matrix for a\nparticular case - a harmonic oscillator coupling to a\nquantum electromagnetic field, the initial configuration of which is a\nthermal one.   The case of a particle scattering on random\npotential is briefly discussed\n\n\n\nIn the paper, the density matrix $\\rho_\\psi$ and its partial transposed\ndensity matrix $\\rho_\\psi^{PT}$ (P stands for partial transpose) are\ndefined as:\n\\begin{equation}\n\\rho_\\psi= \\operatorname{Tr}_E \\ket \\psi \\bra \\psi\n\\end{equation}\n\\begin{equation}\n\\label{PTDME}\n\\rho_{\\psi}^{PT} = U^{PT}\n\\rho_{\\psi}U^{\\dagger PT},\n\\end{equation}\nwhere\n\\begin{equation} U^{PT} = \\Omega K\n\\end{equation}\n\\begin{equation}\n\\Omega = \\sum^{2^{N-1} -1}_{k=0} (-1)^k \\ket k\\bra k,\n\\end{equation}\n\\begin{equation}\nK= \\sum^{2^N}_n n \\ket n \\bra n\n\\end{equation}\nThen\n\\begin{equation}\n\\rho^{PT}_j = n \\ket n_j \\bra n_j + (N-2^N) \\mathbbm I\n\\end{equation}\nWith respect to equations of the paper we get\n\\begin{equation}\n\\rho= \\rho_\\psi \\otimes \\",
    "> We propose TransUNet, a novel architecture for medical image segmentation that leverages the power of transformers as strong encoders. TransUNet is a U-Net-like architecture that replaces the convolutional encoder with a transformer encoder. The transformer encoder is trained in a self-supervised manner using a masked image modeling task. The transformer encoder is then frozen and used as a strong encoder for downstream segmentation tasks. We show that TransUNet outperforms state-of-the-art convolutional U-Net-like architectures on the ISIC 2018 skin lesion segmentation challenge. We also show that TransUNet outperforms state-of-the-art convolutional U-Net-like architectures on the BraTS 2020 brain tumor segmentation challenge.\n\n## [TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation](https://arxiv.org/abs/2111.09846)\n\n### Abstract\n\n> We propose TransUNet, a novel architecture for medical image segmentation that leverages the power of transformers as strong encoders. TransUNet is a U-Net-like architecture that replaces the convolutional encoder with a transformer encoder. The transformer encoder is trained in a self-supervised manner using a masked image modeling task. The transformer encoder is then frozen and used as a strong encoder for downstream segmentation tasks. We show that TransUNet outperforms state-of-the-art convolutional U-Net-like architectures on the ISIC 2018 skin lesion segmentation challenge. We also show that TransUNet outperforms state-of-the-art convolutional U-Net-like architectures on the BraTS 2020 brain tumor segmentation challenge.\n\n### Introduction\n\n> Transformers have recently shown impressive results in a variety of computer vision tasks, including image classification, object detection, and semantic segmentation. However, the use of transformers in medical image segmentation has been limited. In this paper, we propose TransUNet, a novel architecture for medical image segmentation that leverages the power of transformers as strong encoders. TransUNet is a U-Net-like architecture that replaces the convolutional encoder with a transformer encoder. The transformer encoder is trained in a self-supervised manner using a masked image modeling task. The transformer encoder is then frozen and used",
    "In this work, we propose an automatic and efficient method to label CT scans using semi supervised deeplearning with self generated ground truth samples acquired via querying radiology experts in conjunctionwith preprocessing steps involving masking unimportant parts like background voxels or irrelevanttissues that have no effect upon diagnosis such as air sinuses while preserving important areas withinCTs slice by slices into multiple binary masks covering all classes present through which semanticsegmentation can be achieved efficiently without incurring much human involvement at training timeleading towards highly accurate disease localization during testing phase due its high performance over otherstate off art methods thus achieving our main goal increasing accuracy level even further.\"",
    "Some graph problems remain unsolved more than 30 years after they were introduced; these include determining whether an induced $C_4$ or diamond exists and to what extent such subgraphs can overlap, as well finding paths with certain lengths which do not induce cycles (this work). The current state has led authors including Karpinski(2007)to suggest that any advancements towards solving them may be highly unlikely soon into this millennium so far.(...) Irreducible Graphs are those lacking edges connecting each component if exactly one edge was removed.) These results provide strong evidence supporting our hypothesis made by Garey et al., namely ``that we cannot expect further progress on structural questions concerning regular families.'' It seems likely indeed but unconfirmed yet due its complexity being undetermined at time [of posting].",
    "In this article, we study testing functional inequalities in high dimensions with respect to Gaussian measures and sub-Gaussian distributions on $\\mathbb{R}^d$. We show that if $f$ satisfies an inequality involving its first two moments (e.g., convexity or log concavity), then it can be tested against all other functions at level alpha using O(alpha^{-2}) samples; moreover our test has power 1 - o_p(1) when f does not satisfy such moment conditions but belongs instead only Lipschitz class Lambda^0([0,T]). This improves upon previous results which required either stronger assumptions about function classes [Bentkus et al.(2003)]or larger sample sizes[Koltchinskkii & Panchenko,(2011)]. Our tests are based around empirical process theory as well some new concentration bounds related specifically towards these problems.[arXiv]",
    "In recent years, deep neural networks have gained wide attention and been widely used in various fields due to their powerful feature learning ability-for example they allow automatic classification tasks without expert training as required by shallow machinelearning algorithms suchas Support Vector Machine (SVM). DNNs are becoming even moresuch that over 70% off all web searches use oneneural network models which will continue toupwardsof $2bn per year at Google alone [1]. Howeverto trainand run high dimensional complex networkexpectations about computational speeds with lowenergy consumption remain important challenges todielectric devices or battery life limitations foredgesensing applicationssuch assmartphonesor wearabledevices[4]-particularly consideringthatsinglechip can achieve only$0.3-$9GOPS(billion operations/second)atleast5$\\mu W$.Furthermorecurrent energyefficiencyof neuromorphiccomputersbasedon digitalASICs remains well belowneurosynapticbiological efficiency levelsonlybetween 0MWhrdayupwards depending uponeedledge computing platformfrom 1pJperoperationin caseoffluidicslideswitchcircuitsto15nWppopulation densityincreasesaccordingtoprevious estimaeswithpower dissipationaround20mWspeciallyforthehigherdensityslide switch circuits; whereasrecentresearchresultsshowthatthemaximumperformanceoftheredundant CMOS implementationmay beobtainedusing16nmtechnology technologywhich has achievedaremarkablestateofefficiency10 Mopsjouleswhereasthirtytwochannel crossbar arraywasdemonstratedtobecharacterizedbya40MWgateleakageconsumptionleadingtothestatementThattheruntimecostisabout7percentoflively cycle timewhencomparingalaborscaleimplementationtowhileachiplevelreduces power densitiesdowntolower than 20 wattstobe compatiblewillonlybecometrueiflarge scaleproductionwere possiblethroughmassive integrationlevels exceeding101014 cm21howevereventhoughsemiconductormanufacturingindustryhasdevelopednewscalegraphictrendsover decadesstillnotmuchprogressisonemergingeconomiesolutions especiallyforencryptionneedswithelectromigrationwithinanetworkarchitecturewithoutlooseencryptionalgorithmsecurityguaranteesinthemassivescaledeploymentprocessAsadirect resultmostresearcherspay",
    "In this study, we propose an image segmentation method based multi modal convolution neural network (CNN) to segment medical images with different modalities and resolutions in order not only improve accuracy but also reduce computational complexity by fusing multiple modality information into one single CNN model instead using separate models as traditional methods do [1]. The proposed approach consists three main steps including preprocessing step which extracts features such contrast enhancement or noise reduction; feature extraction stage where deep learning techniques are applied followed classification process that classifies each pixel according its label value obtained during training phase so it can be used later when making predictions about new data points without having access their labels beforehand like other machine leaning algorithms would require doing before they could make any kind prediction at all! This way there's no need anymore worry whether your algorithm will work well enough because now you know exactly what type error rate should expect if anything goes wrong along these lines",
    "> Deep learning has achieved great success in medical image segmentation. However, the performance of deep learning models is highly dependent on the quality of the training data. In practice, the training data are often corrupted by noisy labels, which can significantly degrade the performance of the model. To address this problem, we propose a novel cross-denoising network (CDN) to learn robust representations against corrupted labels. The proposed CDN consists of two branches: a denoising branch and a segmentation branch. The denoising branch is designed to learn robust representations against corrupted labels, while the segmentation branch is used to predict the segmentation masks. The two branches are trained jointly in an end-to-end manner. Extensive experiments on two medical image segmentation datasets demonstrate the effectiveness of the proposed CDN.\n\n## \n\n### 1.1 \n\nCDNCDN",
    "The discovery of the Higgs boson at the LHC has confirmed the existence of the Higgs mechanism, which is the cornerstone of the Standard Model (SM) of particle physics. The SM is a renormalizable quantum field theory, which is perturbatively unitary. However, the SM is not a complete theory of particle physics, and it is widely believed that the SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. In this paper, we propose a new mechanism for anomaly mediation, which is called positively deflected anomaly mediation. In this mechanism, the SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which is non-renormalizable and non-perturbatively unitary. The SM is an effective theory of a more fundamental theory, which",
    "<span class=\"katex\"><strong>Input</strong>: Given only <img src=\"/images/post_files/_202112102341c4d64acccdbddbbde9aa78460e0fca404577ad5a3b1aebe28bc8bd6ce25ea85baed2cd2756ff17cb01cf95bfb97ecfc140052ef1599ee72df57245526eb46fb70da2935af5819071638184250fe86abb7579fd53abe34397466683031125444881109210380229101904967dc5add89370544983371/\" alt=\"\\delta (n) = c_{out} - m * n\"> dataset, where images are annotated with either one or none labels.</p><div align='center' style=border 1px solid #008FEE; padding 10 15 0;'> \n  \n\n &nbsp;&emsp;<i>&bull;&enspace;</I></br>\\textit{Lets see in more detail how LT\\_NET can be implemented using conditional GAN and Cycle Consistency.}   \\hfill [CycleGAN2016]\\hfill ~\\\\ \\bottomrule",
    "We present a study of the luminosity-metallicity (L-Z) and mass-metallicity (M-Z) relations for a sample of compact star-forming galaxies (SFGs) at redshifts 0 < z < 3. We use the\n  spectroscopic sample of the 3D-HST survey, which includes a total of ~1000 SFGs with spectroscopic redshifts and stellar masses. We use the emission-line fluxes of\n  [OII] and [OIII] to derive the oxygen abundances of the galaxies. We find that the L-Z and M-Z relations for the SFGs are consistent with the local relations for\n  star-forming galaxies. We also find that the L-Z and M-Z relations for the SFGs are consistent with the local relations for star-forming galaxies at all redshifts.\n  This suggests that the L-Z and M-Z relations for the SFGs are universal. We also find that the L-Z and M-Z relations for the SFGs are consistent with the local relations\n  for star-forming galaxies at all redshifts. This suggests that the L-Z and M-Z relations for the SFGs are universal. We also find that the L-Z and M-Z relations for the\n  SFGs are consistent with the local relations for star-forming galaxies at all redshifts. This suggests that the L-Z and M-Z relations for the SFGs are universal. We also\n  find that the L-Z and M-Z relations for the SFGs are consistent with the local relations for star-forming galaxies at all redshifts. This suggests that the L-Z and M-Z\n  relations for the SFGs are universal. We also find that the L-Z and M-Z relations for the SFGs are consistent with the local relations for star-forming galaxies at all\n  redshifts. This suggests that the L-Z and M-Z relations for the SFGs are universal. We also find that the L-Z and M-Z relations for the SFGs are consistent with the\n  local relations for star-forming galaxies at all redshifts. This suggests that the L-Z and M-Z relations for the",
    "We propose an unsupervised learning method to learn shape representation directly based only sparse point clouds, which can be used in various applications such as 3D reconstruction and volumetric image segmentation (VIS). The proposed approach consists two steps; first we train our model with synthetic data generated by sampling points uniformly over shapes' surfaces using Poisson disk distribution [1]. Then at test time when given real-world input images containing objects that are not present during training phase but have similar geometry or topology compared those seen before then it will automatically adapt itself without any supervision signal provided explicitly through labels like class names etc., thus making this system more robust against unseen classes while still being able perform well enough even though there might exist some differences between them due their inherent nature e g different textures colors sizes scales orientations poses rotations angles speeds velocities accelerations decelerating rates acceleration profiles braking patterns stopping distances reaction times response curves trajectories paths routes tracks courses directions destinations goals targets objectives purposes intentions outcomes effects consequences results impacts causes origins sources beginnings endings ends finishes terminations conclusions resolutions solutions answers questions responses explanations clarifications interpretations understandings insights discoveries findings revelations breakthroughs inventions creations developments innovations advancements improvements enhancements upgrades modifications alterations adjustments augmentatons additions deletions subtractions removals replacements substitutions variations deviations departures digressions diversions detours excursuses side trips sidelines sidetracks meander wander deviate stray diverge swerve veer drift roam ramble range prowl stroll saunter amble perambulate promenade strut parade march tramp traipse walk trot jog run sprint gallop scamper scurry dash race fly zoom rocket speed rush tear streak shoot zip whiz whoosh hurtle careening skid slide spin whirl twirl rotate revolve orbit circle gyrate turn twist roll tumble flip flutter flap vibrate quiver jiggle shake shimmy wag wigw ag tremor pulsate throb palpitate beat thump pound hammer knock rap tap clap slap bang rattle drum buzz hum drone roar rum bleep croak chirp tweet squeal squawk caw crow screech hissing purr growl grunt moo oink bellow bray neigh snort baa lowing bark howling yowl moan whimpering sobbing weeping crying shrieking screaming yelling shouting holler hollaring caterwauling ululating warbling whistlesong",
    "Let $X$ be an algebraic variety over $\\mathbb{C}$. We define its determinantal ideal and show that it has finite codimension in ${\\mathcal O}_S(U)$ where $(O_s, U) \\to X$. This allows us to construct morphisms between two such ideals which are analogous with those defined by Beilinson-Bernstein (for smooth projective curves). The main result states if these maps induce isomorphism on cohomology then they must also do so at all levels i.e., we have equality everywhere not just up till some level as was shown earlier using different methods [1]. In particular this implies there exists only one non trivial extension class associated w/ any given pair consisting either side's respective determinants; thus proving uniqueness theorem conjectured previously without proof!",
    "Sai Krishnappa KV Nayak S Vishal Kumar Venkatesha L Dinesh Ram Bhat (MNNIT) Automatic labeling has been considered as one important problem in multimedia data mining area to ease down huge overhead cost required by manual labels involved during collection process itself A great deal about work have already happened using various models but still major challenge lies with improving accuracy since large quantities available every day also makes it difficult not only due insufficient number good pre labeled samples The use deep supervised learning algorithms alone isn't enough make this task possible without involving some sort handcraft features too It provides us opportunity investigate role played different types ML paradigms like unsupervised semi-unsupervised or hybrid ones so that we can finally reach conclusion which best suited our application Also study conducted upon variety domains provide better understanding requirements specific domain Hence overall goal proposed survey analyze trends recent past works identify potential future directions based them Finally here propose comparative analysis existing approaches methods used their effectiveness evaluation criteria taken into consideration along comparison basis certain popularly accepted tools [30] where dataset manually annotated such tasks This might be useful readers wanting more detailed background knowledge each given below Section I Introduction Various subareas exist within computer science artificial intelligence machine however particular method chosen may depend whether results expected involve numerical qualitative variables While these distinctions aren t usually made when describing general purposes field nevertheless they reflect several key practical considerations regarding underlying problems faced applications developed Some examples follow Next take look at few typical areas include applied statistics information retrieval signal processing expert systems computational linguistics cognitive neuroscience natural language visual recognition programming languages etc Each will now briefly described Note there no clear dividing line between many entries listed next often overlap considerably despite varying terminology emphasis Given today's interdisciplinary environment much ongoing cross pollination collaboration even among those disciplines originally thought separate Table II Common Areas Within Computer Science Included Below Artificial Intelligence Expert Systems Natural Language Processing Computational Statistics Signal Cognition Neural Networks Speech Recognitio Vision Reason Image Understanding Programming Knowledge Acquisi Control Theory Fuzzy Logic Decision Making Robotics Perceptron Neurocognitive Psycholinguist Information Retrieva Process Modelin Agent Technology Evolutionary Algo Graphical Models Database Intelligent Machi Numerica Statistical Soft Computing Statistic Visualization Probabilitat Heuristan Classificat Biologis System Genetics Evolving Proba Distributions Time Serie Pattern Learn",
    "We propose a multi-layer approach to superpixel-based higher-order conditional random field (CRF) for semantic image segmentation. The proposed method is based on the observation that the superpixels in the same semantic class tend to have similar color and texture features. We first use a superpixel-based CRF to segment the image into superpixels. Then, we use a multi-layer CRF to refine the segmentation results. The multi-layer CRF is composed of multiple CRFs, each of which is defined on a different layer. The layers are constructed by grouping the superpixels according to their color and texture features. The multi-layer CRF is able to capture the spatial relationships among the superpixels in the same semantic class. Experimental results on the PASCAL VOC 2012 dataset show that the proposed method outperforms the state-of-the-art methods.\n\nThe following is the full text of the abstract for a research paper titled \"A Multi-Layer Approach to Superpixel-based Higher-order Conditional Random Field for Semantic Image Segmentation\" from arxiv.org:\n\nWe propose a multi-layer approach to superpixel-based higher-order conditional random field (CRF) for semantic image segmentation. The proposed method is based on the observation that the superpixels in the same semantic class tend to have similar color and texture features. We first use a superpixel-based CRF to segment the image into superpixels. Then, we use a multi-layer CRF to refine the segmentation results. The multi-layer CRF is composed of multiple CRFs, each of which is defined on a different layer. The layers are constructed by grouping the superpixels according to their color and texture features. The multi-layer CRF is able to capture the spatial relationships among the superpixels in the same semantic class. Experimental results on the PASCAL VOC 2012 dataset show that the proposed method outperforms the state-of-the-art methods.\n\nThe following is the full text of the abstract for a research paper titled \"A Multi-Layer Approach to Superpixel-based Higher-order Conditional Random Field for Semantic Image Segmentation\" from arxiv.org:\n\nWe propose a",
    "We present a new stochastic Eulerian Lagrangian method for fluid-structure interactions with thermal fluctuations. The method is based on a stochastic Eulerian Lagrangian formulation of the Navier-Stokes equations, which is coupled to a stochastic Lagrangian formulation of the equations of motion for the structure. The stochastic Eulerian Lagrangian formulation of the Navier-Stokes equations is based on a stochastic Lagrangian formulation of the incompressible Navier-Stokes equations, which is derived from the stochastic Lagrangian formulation of the Euler equations. The stochastic Lagrangian formulation of the Euler equations is based on a stochastic Lagrangian formulation of the incompressible Euler equations, which is derived from the stochastic Lagrangian formulation of the incompressible Euler equations. The stochastic Lagrangian formulation of the incompressible Euler equations is based on a stochastic Lagrangian formulation of the incompressible Euler equations, which is derived from the stochastic Lagrangian formulation of the incompressible Euler equations. The stochastic Lagrangian formulation of the incompressible Euler equations is based on a stochastic Lagrangian formulation of the incompressible Euler equations, which is derived from the stochastic Lagrangian formulation of the incompressible Euler equations. The stochastic Lagrangian formulation of the incompressible Euler equations is based on a stochastic Lagrangian formulation of the incompressible Euler equations, which is derived from the stochastic Lagrangian formulation of the incompressible Euler equations. The stochastic Lagrangian formulation of the incompressible Euler equations is based on a stochastic Lagrangian formulation of the incompressible Euler equations, which is derived from the stochastic Lagrangian formulation of the incompressible Euler equations. The stochastic Lagrangian formulation of the incompressible Euler equations is based on a stochastic Lagrangian formulation of the incompressible Euler equations, which is derived from the stochastic Lagrangian formulation of the incompressible Euler equations. The stochastic Lagrangian formulation of the incompressible Euler equations is based on a stochastic Lagrangian formulation of the incompressible Euler equations, which is derived from the stochastic Lagrangian formulation of the incompressible Euler equations. The stochastic Lagrangian formulation of the incompressible Euler equations is based on a stochastic Lagrangian formulation of the incompressible Euler equations, which is derived from the stochastic Lagrangian formulation of the incompressible Euler equations. The stochastic Lagrangian formulation of the incompressible Euler equations is based on a stochastic Lagrangian formulation of the incompressible Euler equations, which is derived from the stochastic",
    "Recent theoretical studies on coupled, long dielectric cylinders have indicated that both modal symmetries (polarization direction or handedness) across particles' axes as well exciting field mode number can be used to distinguish between possible symmetry types associated with different physical characteristics such frequency splitting/anti - crossing behavior among resonances depending upon relative orientations within symmetric axis groupings along these systems [1]. This concept will open new opportunities into understanding structure / function relationships where novel material properties may emerge due their own internal structural arrangement; e.g., chirality induced by directional selection rules based solely off polarization considerations alone! I'm presenting here some preliminary thoughts toward this goal through exploring what happens when we take those aforementioned ideas forward yet again adding now another layer onto things like stacking two sets orthogonal planes together forming 3D arrays inside out space bounded only. The results show us how each type interaction influences resulting response making it clear which polarizations carry greatest weight even versus other parameters including size etc.. What more await discovery soon enough? Reference[0): Mousavi Khorshidi Faezehnabi Javad Khodadanipour Nima Oveaslian Arash Nikbakht Yaser Golshani Mostafa Vaidyanathan Chandrasekhara Narayanaswamy Ranganatha Thiagarajah Mohankumar Hui Lee Jin Poh Boon Tion Tan See Li Teu Chhieng Cheng Kuok Tai Lam Hong Qiang Feng Anirudha Srikaran Ability Systems Private Limited Singapore",
    "We study the properties of subgaussian sequences in probability and Fourier analysis. We show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the Fourier transform of a subgaussian sequence is a subgaussian sequence. We also show that the",
    "To read more or to download click on Inductict Types",
    "> We present a method for meticulous object segmentation, which is the task of segmenting an object of interest from its surroundings. Our method is based on a novel deep neural network architecture that is trained end-to-end to perform the task. The network is trained on a large dataset of images with pixel-level annotations of the object of interest. The network learns to predict a segmentation mask for the object, which is then used to extract the object from the image. Our method is able to accurately segment objects of different shapes and sizes, even in complex scenes with multiple objects. We demonstrate the effectiveness of our method on a variety of datasets, including the PASCAL VOC dataset and the COCO dataset.\n\nThe following is the full text of the abstract for a research paper titled \"Meticulous Object Segmentation\" from arxiv.org:\n\n> We present a method for meticulous object segmentation, which is the task of segmenting an object of interest from its surroundings. Our method is based on a novel deep neural network architecture that is trained end-to-end to perform the task. The network is trained on a large dataset of images with pixel-level annotations of the object of interest. The network learns to predict a segmentation mask for the object, which is then used to extract the object from the image. Our method is able to accurately segment objects of different shapes and sizes, even in complex scenes with multiple objects. We demonstrate the effectiveness of our method on a variety of datasets, including the PASCAL VOC dataset and the COCO dataset.\n\nThe following is the full text of the abstract for a research paper titled \"Meticulous Object Segmentation\" from arxiv.org:\n\n> We present a method for meticulous object segmentation, which is the task of segmenting an object of interest from its surroundings. Our method is based on a novel deep neural network architecture that is trained end-to-end to perform the task. The network is trained on a large dataset of images with pixel-level annotations of the object of interest. The network learns to predict a segmentation mask for the object, which is then used to extract the object from the image. Our method is able to accurately segment objects of different shapes and sizes, even in complex scenes with multiple objects. We demonstrate the effectiveness of our method on a variety of",
    "> We present a novel approach to inference in Markov Random Fields (MRFs) based on Riemannian optimization. We show that the inference problem can be formulated as a smooth optimization problem on the space of probability distributions. We then show that the Riemannian gradient of the objective function is the negative of the MRF's log-partition function, and that the Riemannian Hessian is the negative of the MRF's Fisher information matrix. We then show that the Riemannian gradient descent algorithm is equivalent to the well-known belief propagation algorithm. We also show that the Riemannian Hessian is positive definite, and that the Riemannian gradient descent algorithm converges to the MRF's maximum a posteriori (MAP) estimate. We then show that the Riemannian Hessian can be used to accelerate the Riemannian gradient descent algorithm. We show that the Riemannian Hessian can be computed efficiently using the MRF's factor graph. We then show that the Riemannian Hessian can be used to accelerate the Riemannian gradient descent algorithm. We show that the Riemannian Hessian can be computed efficiently using the MRF's factor graph. We then show that the Riemannian Hessian can be used to accelerate the Riemannian gradient descent algorithm. We show that the Riemannian Hessian can be computed efficiently using the MRF's factor graph. We then show that the Riemannian Hessian can be used to accelerate the Riemannian gradient descent algorithm. We show that the Riemannian Hessian can be computed efficiently using the MRF's factor graph. We then show that the Riemannian Hessian can be used to accelerate the Riemannian gradient descent algorithm. We show that the Riemannian Hessian can be computed efficiently using the MRF's factor graph. We then show that the Riemannian Hessian can be used to accelerate the Riemannian gradient descent algorithm. We show that the Riemannian Hessian can be computed efficiently using the MRF's factor graph. We then show that the Riemannian Hessian can be used to accelerate the Riemannian gradient descent algorithm. We show that the Riemannian Hessian can be computed efficiently using the MRF's factor graph. We then show that the Riemannian Hessian can be used to accelerate the Riemannian gradient descent algorithm. We show that the Riemannian Hessian can be computed efficiently using the MRF's factor graph. We then show that the Riemannian Hessian can be used to accelerate the Riemannian gradient descent algorithm. We show that the Riemannian Hessian can be computed efficiently using",
    "There are many problems in computer vision, computer graphics, image processing and robotics which can be written as a binary quadratic optimization problem. Although the problem is NP-hard in general, we can tackle the problem using many techniques because of its convexity. In this paper, we propose to use a semidefinite relaxation of the problem to solve large-scale tasks. By exploiting the structure of the problem, we derive a fast solver which has less than 10 lines of code. We run comparative experiments for several visual problems, including shape fitting, feature selection, semantic segmentation and non-rigid shape registration, and report satisfactory results.\nIn general, a binary quadratic optimization problem takes the form:\n\\[ max_{x \\in \\mathbf{R}^n: \\mathbf{1}^Tx=1} x^TAx \\\\ s.t. Bx = b, \\]\nwhere A  Rnn, b  Rn.\nSemidefinite relaxations (SDP) are a standard relaxation method which is widely used for polynomial optimization problems. An SDP relaxes a problem by replacing linear constraints with quadratic constraints, and the objective function with a convex one. Such a relaxation is usually tractable. However, in reality there are no guarantees that solving the SDP problem provides a feasible/optimal solution to the original problem.\nThe best-known polynomial relaxation for a linear problem is the semidefinite relaxation.\nFor an unknown x, this relaxation leads to the following program, denoted $\\sigma[P]$:\n$\\min_{\\Sigma\\succeq 0} f(\\Sigma)$\nwhere   Rdd and\n$f(\\Sigma) = \\frac{1}{2} \\tr{(B^T\\Sigma+A^T-b^Tb)} + \\tr{(A\\Sigma)}$.\nThe above problem can be solved very efficiently by leveraging on semidefinite programming solvers. Once we have a solution , we could recover the desired feasible point x by solving the following simple equation:\n\\[ \\begin{bmatrix} I_d \\\\ -B\\end{bmatrix} \\begin{bmatrix} x \\\\ \\lambda \\end{bmatrix} = \\begin{bmatrix} \\Sigma \\\\ 1 \\end{bmatrix} \\]\nHere",
    "The $\\pi$-calculus is a process calculus that has been used to model\ndistributed systems. It is a process calculus with a simple syntax and\na rich set of operators. It is also a process calculus with a\nwell-understood semantics. The $\\pi$-calculus is a process calculus\nwith a well-understood behavioural equivalence.\n\nThe $\\pi$-calculus is a process calculus with a well-understood\nbehavioural equivalence. It is a process calculus with a simple\nsyntax and a rich set of operators. It is also a process calculus\nwith a well-understood semantics. The $\\pi$-calculus is a process\ncalculus with a well-understood behavioural equivalence.\n\nThe $\\pi$-calculus is a process calculus with a well-understood\nbehavioural equivalence. It is a process calculus with a simple\nsyntax and a rich set of operators. It is also a process calculus\nwith a well-understood semantics. The $\\pi$-calculus is a process\ncalculus with a well-understood behavioural equivalence.\n\nThe $\\pi$-calculus is a process calculus with a well-understood\nbehavioural equivalence. It is a process calculus with a simple\nsyntax and a rich set of operators. It is also a process calculus\nwith a well-understood semantics. The $\\pi$-calculus is a process\ncalculus with a well-understood behavioural equivalence.\n\nThe $\\pi$-calculus is a process calculus with a well-understood\nbehavioural equivalence. It is a process calculus with a simple\nsyntax and a rich set of operators. It is also a process calculus\nwith a well-understood semantics. The $\\pi$-calculus is a process\ncalculus with a well-understood behavioural equivalence.\n\nThe $\\pi$-calculus is a process calculus with a well-understood\nbehavioural equivalence. It is a process calculus with a simple\nsyntax and a rich set of operators. It is also a process calculus\nwith a well-understood semantics. The $\\pi$-calculus is a process\ncalculus with a well-understood behavioural equivalence.\n\nThe $\\pi$-calculus is a",
    "> We present a novel interactive segmentation method for patterned images. The method is based on a content-based propagation of user markings. The user is asked to mark a few pixels in the image, and the method automatically propagates the markings to the rest of the image. The propagation is based on a content-based similarity measure between the marked pixels and the rest of the image. The method is interactive in the sense that the user can correct the propagation by marking additional pixels. The method is also robust to noise and to the presence of multiple patterns in the image. We demonstrate the method on several images with different patterns.\n\n## The Problem\n\nThe problem is to segment an image into regions that are similar to each other. The image is a two-dimensional array of pixels, and each pixel has a color. The goal is to divide the image into regions such that the pixels in each region have similar colors.\n\n## The Solution\n\nThe solution is to use a content-based propagation of user markings. The user is asked to mark a few pixels in the image, and the method automatically propagates the markings to the rest of the image. The propagation is based on a content-based similarity measure between the marked pixels and the rest of the image. The method is interactive in the sense that the user can correct the propagation by marking additional pixels. The method is also robust to noise and to the presence of multiple patterns in the image.\n\n## The Results\n\nWe demonstrate the method on several images with different patterns. The results show that the method is able to segment the images into regions with similar colors.\n\n## Conclusion\n\nWe have presented a novel interactive segmentation method for patterned images. The method is based on a content-based propagation of user markings. The user is asked to mark a few pixels in the image, and the method automatically propagates the markings to the rest of the image. The propagation is based on a content-based similarity measure between the marked pixels and the rest of the image. The method is interactive in the sense that the user can correct the propagation by marking additional pixels. The method is also robust to noise and to the presence of multiple patterns in the image. We demonstrate the method on several images with different patterns. The results show that the method is able to segment the",
    "We prove that if $f$ has real coefficients, then it can be written as an infinite sum $\\sum_{n=0}^\\infty c_nf(x)^nd^nx$, where each coefficient satisfies $|c_i|\\leq 1$. This implies several results on log convex functions including one by Erdos which states every function whose derivative at 0 equals its second or higher derivatives there must have all positive values in some interval around zero (and hence cannot satisfy any polynomial equation). We also show how to construct new examples using this method such ones involving exponential terms like e^(1/t) instead just powers t itself; these are called \"exponential type\". Finally we give two applications related specifically towards finding solutions when given certain conditions about their behavior near infinity - first being able find bounds based off known properties while still maintaining generality so they apply regardless what kind shape might look similar enough not matter whether you're dealing something simple yet complicated simultaneously!",
    "> We propose a new class of deep neural networks motivated by partial differential equations (PDEs). The proposed networks are constructed by stacking a sequence of layers, each of which is a composition of a linear operator and a nonlinear activation function. The linear operator is a discretization of a linear differential operator, and the nonlinear activation function is a discretization of a nonlinear function. The proposed networks are universal approximators of functions in the Sobolev space. We show that the proposed networks can be trained by minimizing a loss function that is a discretization of a PDE. We also show that the proposed networks can be trained by minimizing a loss function that is a discretization of a variational problem. We demonstrate the effectiveness of the proposed networks on several tasks, including image classification, image super-resolution, and image denoising.\n\nThe following is the full text of the abstract for a research paper titled \"Deep Neural Networks Motivated by Partial Differential Equations\" from arxiv.org:\n\n> We propose a new class of deep neural networks motivated by partial differential equations (PDEs). The proposed networks are constructed by stacking a sequence of layers, each of which is a composition of a linear operator and a nonlinear activation function. The linear operator is a discretization of a linear differential operator, and the nonlinear activation function is a discretization of a nonlinear function. The proposed networks are universal approximators of functions in the Sobolev space. We show that the proposed networks can be trained by minimizing a loss function that is a discretization of a PDE. We also show that the proposed networks can be trained by minimizing a loss function that is a discretization of a variational problem. We demonstrate the effectiveness of the proposed networks on several tasks, including image classification, image super-resolution, and image denoising.\n\nThe following is the full text of the abstract for a research paper titled \"Deep Neural Networks Motivated by Partial Differential Equations\" from arxiv.org:\n\n> We propose a new class of deep neural networks motivated by partial differential equations (PDEs). The proposed networks are constructed by stacking a sequence of layers, each of which is a composition of a linear operator and a nonlinear activation function. The linear operator is a discretization of a linear differential operator, and the nonlinear activation function is a discretization of a nonlinear function. The proposed networks are",
    "This paper presents a new semi-supervised segmentation method for electron microscopy images, called Semi-supervised Hierarchical Merge Tree (SSHMT). It is inspired by the fact that the segmentation task is strongly dependent on the quality of the labeled samples. We propose an algorithm that iteratively produces pseudo labels for unlabeled samples so as to increase the quality of the whole segmentation model via active learning. The SSHMT method is based on the hierarchical merge tree (HMT) method. During each iteration, a number of samples are selected according to a distance-based acquisition function. These samples generate pseudo labels and are added into the labeled dataset.\nSSHMT also introduces a new concept of uncertainty which captures the confidence of the model on a given sample. These two components (acquisition function and uncertainty) are further adapted in an attention-based neural network to produce powerful pseudo labels. This novel method has been validated on three different electron microscopy datasets and has also been compared with other well-known segmentation methods. In general, our method has outperformed others on almost every dataset and has demonstrated particularly impressive results for the largest of them.\nThe following is the full text of the abstract for a research paper titled \"Active Learning on Real-World Data Using a Hierarchical Gaussian Process Model\" from arxiv.org:\nWe propose an algorithm to make active learning as effective as possible on real-world datasets where only a few labeled examples are initially available. In order to do so, we propose a novel method to estimate the uncertainty associated with any sample in any dataset. We use the uncertainty as a criterion in order to select the most suitable sample to be evaluated by an expert. Compared to other methods, our hierarchical Gaussian process model allows to: i) have better uncertainty estimates about individual samples even though only a few labeled examples are available; ii) exploit previous evaluations of the classifier when they are available. Extensive experiments on a large variety of binary real-world classification tasks - ranging from the well known handwritten digit recognition task to a novel task on real face images - show that our method results in an average reduction of 10% of the number of evaluations necessary to reach an arbitrary accuracy threshold, with only a minimal degradation of the classification performance. For example, on the most challenging dataset investigated here, the average number of",
    "This study presents a novel approach to brain tumor segmentation using a combination of Fully Convolutional Neural Networks (FCNNs) and Conditional Random Fields (CRFs). The proposed method utilizes an end-to-end trainable architecture that integrates both techniques, allowing for more accurate segmentations. Experimental results on publicly available datasets demonstrate the effectiveness of the proposed model in comparison with state-of-the-art methods. Overall, this research provides valuable insights into the potential applications of combining FCNNs and CRFs for medical image analysis tasks such as brain tumor segmentation.",
    "This study investigates mask-based data augmentation as a technique to improve semi-supervised semantic segmentation. The approach involves generating synthetic training images by applying random masks on the original images and their corresponding ground truth labels. Experimental results demonstrate that this method significantly enhances model performance, particularly when combined with other popular techniques such as color jittering and horizontal flipping. Overall, our findings suggest that mask-based data augmentation is an effective strategy for improving the accuracy of semi-supervised semantic segmentation models.",
    "The Recurrent Residual Convolutional Neural Network based on U-Net, or R2U-Net, is a novel approach to medical image segmentation. This network combines the advantages of both recurrent neural networks and residual learning with convolutional layers in an end-to-end trainable architecture inspired by the popular U-Net model. The proposed method was evaluated using various benchmark datasets demonstrating superior performance compared to state-of-the-art methods while maintaining computational efficiency. Overall, this study presents a promising solution for automated medical image analysis tasks requiring high accuracy and efficient computation.",
    "This paper presents a novel approach for image segmentation using deep convolutional neural networks with spatial regularization, volume, and star-shape priori. The proposed method incorporates prior knowledge about the image structure and utilizes a spatial regularization term to enforce consistency in the segmentation results. Experimental results on several benchmark datasets demonstrate the effectiveness of the proposed method, achieving state-of-the-art performance compared to other existing methods.",
    "This study examines longitudinal and spin/valley hall optical conductivities in a single-layer $MoS_2$. Using advanced experimental techniques, we collected data over an extended period to analyze these properties. Our findings provide valuable insights into the behavior of two-dimensional materials and their potential applications in optoelectronic devices.",
    "This paper presents a novel approach for multitask diffusion adaptation over networks. The proposed method utilizes a stochastic gradient descent algorithm to optimize the weights of a neural network, allowing it to learn from multiple tasks simultaneously. The effectiveness of the approach is demonstrated through experiments on a variety of tasks, including image classification and natural language processing. Results show that the proposed method outperforms traditional single-task approaches, highlighting the advantages of multitask learning in network optimization.",
    "This academic paper proposes a method to improve the calibration and out-of-distribution detection in medical image segmentation using convolutional neural networks (CNNs). The proposed method aims to address the issue of over-confidence in CNN predictions, which can lead to incorrect diagnoses and treatment plans. The paper presents experimental results demonstrating the effectiveness of the proposed method in improving the calibration of CNN predictions and detecting out-of-distribution samples. Overall, the paper contributes to the development of more reliable and accurate medical image segmentation techniques based on CNNs.",
    "This academic paper discusses the development of a model for real-time prediction of segmentation quality. The model uses deep learning algorithms to analyze image data and provide an accurate assessment of the quality of segmentation results. Through extensive testing, the paper demonstrates the effectiveness of the proposed model in accurately predicting segmentation quality in real-time, making it a valuable tool for image segmentation applications.",
    "The academic paper titled \"Sigma Point Belief Propagation\" presents a novel approach to Bayesian inference using Sigma Point Belief Propagation (SPBP). The SPBP algorithm utilizes a set of Sigma Points to represent uncertainty in the system state and propagates the belief over time using a Kalman filter-like update. The paper provides a detailed description of the SPBP algorithm and demonstrates its effectiveness through simulation results. The SPBP algorithm offers a computationally efficient alternative to traditional Bayesian inference methods and has potential applications in robotics, navigation, and control systems.",
    "This paper presents a novel approach for automatically segmenting the left atrium from cardiac images using successive 3D U-Nets and a contour loss. The proposed method utilizes a combination of two 3D U-Nets, where the first U-Net is trained using a standard loss function, and the second U-Net is trained using a contour loss function to enhance the segmentation results. The contour loss function is designed to prioritize the accuracy of the boundary between the left atrium and the surrounding tissues. The proposed method was evaluated on a dataset of cardiac images and achieved state-of-the-art segmentation results. The effectiveness of the proposed approach was demonstrated through qualitative and quantitative evaluations, including Dice similarity coefficient and Hausdorff distance. Overall, this paper provides a promising solution for the automatic segmentation of the left atrium from cardiac images, which has significant implications for cardiac image analysis and clinical decision-making.",
    "This research presents experimental evidence supporting a new osmosis law and theory, which has derived a new formula that improves Van't Hoff's osmotic pressure equation. Through various experiments, it was found that the new formula provides more accurate results in predicting osmotic pressures under different conditions compared to the existing equation. The findings highlight the importance of developing new scientific theories and formulas bychallenging conventional knowledge through experimentation, improving our understanding of complex phenomena such as osmosis, and potentially leading to breakthroughs in fields like biology, chemistry, and pharmacology.",
    "This biased review examines biases present in previous studies that have analyzed political collective action on Twitter. By critically evaluating these research efforts, we aim to highlight potential limitations and suggest future directions for more accurate and reliable investigations into online social movements.",
    "This study presents an active set algorithm designed specifically for estimating parameters in generalized linear models (GLMs) that involve ordered predictors. The proposed method utilizes a sequential regression approach, where each predictor is added to or removed from the model based on its significance level determined by hypothesis testing at each iteration of the optimization process. By focusing only on significant variables and their interactions within specific subsets called 'active sets', computational efficiency is improved while maintaining accuracy in parameter estimation. Through simulation studies and real-data analysis, this research demonstrates the effectiveness and advantages of using our novel GLM active set algorithm over traditional methods such as maximum likelihood estimates or other regularization techniques like Lasso or Ridge Regression.",
    "This paper presents Ramsey-type theorems for lines in three dimensional space. We prove that if a sufficiently large number of points are chosen randomly and independently from 3-space, then with high probability there exists a pair of disjoint lines passing through at least half of these points each. Additionally, we show that under certain conditions on the distribution of points, it is possible to find two parallel lines which pass through all but an arbitrarily small fraction of the points. These results provide insight into the geometric properties of lines in higher dimensions and have potential applications in areas such as coding theory and graph theory.",
    "This paper presents a comprehensive multi-modal interaction approach for referring image segmentation, which involves the use of natural language and visual cues to accurately segment objects in images. The proposed method utilizes a deep neural network to process the visual information and a language model to understand the natural language input. Extensive experiments on benchmark datasets demonstrate the effectiveness of the proposed approach, which outperforms state-of-the-art methods in referring image segmentation. The results show that the comprehensive multi-modal interaction approach can significantly improve the accuracy of object segmentation and has potential applications in various fields, such as image editing, content-based image retrieval, and visual question answering.",
    "The max-flow problem is a fundamental problem in computer vision and machine learning, which aims to estimate the maximum flow between two regions in an image. In this paper, we propose a consistent estimation approach for the max-flow problem, which can be used for unsupervised image segmentation. Our approach relies on a variational formulation of the max-flow problem, which allows us to incorporate prior knowledge about the image structure and to avoid the convergence to local minima. We demonstrate the effectiveness of our approach on several benchmark datasets, showing that it outperforms state-of-the-art methods in terms of segmentation accuracy and computational efficiency. Overall, our work provides a promising direction for unsupervised image segmentation using the max-flow problem.",
    "This academic paper proposes a Quality-Aware Memory Network (QMN) for interactive volumetric image segmentation. The QMN is designed to address the issue of segmentation quality degradation in interactive segmentation, where user feedback is incorporated into the segmentation process. The QMN integrates a memory module that stores and updates segmentation results based on user feedback, and a quality estimation module that evaluates the segmentation quality. Experimental results on brain tumor segmentation datasets show that the QMN outperforms state-of-the-art methods in terms of segmentation accuracy and interaction efficiency.",
    "This academic paper presents a real-time high-performance semantic image segmentation method for urban street scenes. The proposed method utilizes deep learning techniques to accurately segment various objects in urban environments, including vehicles, pedestrians, buildings, and road markings. The approach achieves fast processing speeds while maintaining high accuracy, making it suitable for real-time applications. The paper provides a detailed description of the methodology and experimental results, demonstrating the effectiveness of the proposed method in improving the safety and efficiency of autonomous vehicles operating in urban environments.",
    "This research explores clustering techniques using point set kernel methods. The aim is to develop an efficient and effective approach that can handle high dimensional data while preserving important features of the input points. We evaluate our proposed method through extensive experiments, demonstrating its superiority over existing state-of-the-art algorithms in terms of accuracy and computational efficiency. Our findings suggest that incorporating kernels into cluster analysis provides a promising direction towards addressing complex real world problems involving large datasets with intricate structures. Overall, this study contributes significantly to advancing knowledge about machine learning approaches particularly relevant for big data analytics applications.",
    "This academic paper presents a novel deep convolutional neural network (DCNN) approach for semi-supervised medical image segmentation. The proposed method utilizes an ensemble of generic models trained on large-scale datasets to improve the performance of the segmentation task. The DCNN is designed to leverage the benefits of both supervised and unsupervised learning, allowing for efficient utilization of limited labeled data. Experimental results on several medical imaging datasets demonstrate the effectiveness of the proposed method in achieving state-of-the-art performance with reduced annotation requirements.",
    "The study delves into quantum circuits, a complex field in physics. It explores how these can be related to spin(3n) groups through mathematical concepts such as angular momentum representations or Clebsch-Gordon coefficients. The work provides insights on why researchers find this connection intriguing since it allows them to understand certain aspects of condensed matter systems more comprehensively than before. Additionally, implications concerning potential applications like topological qubits are touched upon briefly with references provided throughout the text guiding readers along their journey towards acquiring expertise themselves too!",
    "This academic paper describes the development of a computer vision pipeline for the automated determination of cardiac structure and function using two-dimensional echocardiography. The pipeline incorporates image processing and machine learning techniques to analyze echocardiographic images and detect various cardiac diseases. The paper discusses the potential benefits of this automated approach, including increased accuracy and efficiency in the diagnosis of cardiac disease.",
    "This review examines recent developments in multi-fidelity modeling, a technique that utilises multiple levels of computational fidelity to reduce uncertainty and improve predictive accuracy. By investigating various applications across different disciplines, we highlight how these models can be tailored to suit specific purposes while maintaining their fundamental principles. We also discuss challenges faced by practitioners when implementing multi-fidelity approaches and propose potential solutions which could enhance their usefulness further. Overall, this study provides insights into current advancements within multilevel simulation methodology and underscores its relevance as an emerging toolset applicable across diverse domains of research.",
    "This academic paper presents a texture-based image segmentation approach for chili pepper X-ray images using Gabor filters. The proposed method utilizes the frequency domain properties of Gabor filters to extract texture features from the X-ray images, which are then used to segment the chili peppers from the background. The effectiveness of the proposed method is demonstrated through experimental results, which show that it outperforms other segmentation methods in terms of accuracy and computational efficiency. The paper concludes that the Gabor filter-based texture segmentation approach is a promising technique for chili pepper X-ray image analysis.",
    "This academic paper investigates the use of multiuser diversity for secrecy communications through opportunistic jammer selection. The paper analyzes the achievable secure degrees of freedom and presents a jammer scaling law. By exploiting the diversity among multiple users, the proposed approach enhances the security of communication systems while providing insights into the performance trade-offs between reliability and security. The study has significant implications for the design of secure communication networks and provides a basis for further research in the field.",
    "The Intra- and Cross-modality Semantic Consistency (ICMSC) approach is presented for unsupervised domain adaptation in hip joint bone segmentation. The method utilizes both intra- and cross-modality consistency constraints to learn robust and adaptive features, which are transferable across different domains. Experimental results on public datasets demonstrate the effectiveness of the proposed approach, which achieves state-of-the-art performance in hip joint bone segmentation, especially under cross-domain settings.",
    "This paper presents a bound on genuine multipartite correlations that is derived from the principle of information causality. The bound provides a way to quantify the amount of genuine multipartite correlations in a quantum state, and it is shown to be stronger than previous bounds based on the causal structure of the system. The implications of this result for the study of quantum correlations and the foundations of quantum mechanics are discussed.",
    "The Structure and Dynamics of brain lobe functional networks study examines the changes that occur in the cerebral cortex as anesthesia begins to take effect. Using a combination of electroencephalography (EEG) recordings, graph theory analysis, and network dynamic metrics this research provides insight into how different regions within the brain communicate with each other during loss of consciousness. Our results show significant alterations in both small world properties such as clustering coefficient & characteristic path length along with measures like correlation dimension which indicate fractalike structures indicating an increase fragmentation or segregation pattern across various stages of sedation induction. Additionally, we find strong evidence supporting increased modular organization especially between frontal/parietal areas vs temporal parietal junction leading towards complete separation under deep unconsciousness. This work sheds light on key mechanisms behind altered states induced by general anesthetics helping us understand better why some patients exhibit abnormal responses while undergoing surgery requiring intravenous agents such as propofol bisphenol A compounds among others.",
    "The paper presents a study on the characteristics of optimal solutions to the sensor location problem. The sensor location problem involves determining the optimal placement of sensors in a given area to maximize the coverage and minimize the cost. The study analyzes the characteristics of optimal solutions, such as the number of sensors required, their placement, and the optimal configuration of sensors. The paper provides insights into the factors that influence the optimal solution and highlights the challenges in finding the optimal solution. The study contributes to the understanding of the sensor location problem and can be useful for researchers and practitioners working in the field of sensor networks.",
    "This academic paper explores the concept of aether terms in a space-time with a compact extra dimension. The paper examines the implications of incorporating a compact extra dimension into the framework of aether theories, and discusses the potential consequences for the behavior of electromagnetic fields in such a space-time. The paper also presents a detailed analysis of the mathematical formalism used to describe the aether terms and their interactions with the standard model particles. The results of this study provide new insights into the nature of aether terms and their role in the dynamics of space-time, and may have important implications for our understanding of fundamental forces and the structure of the universe.",
    "\"This article presents a comprehensive study of uniform determinantal representations, providing an in-depth analysis of their properties and applications. The authors demonstrate how these representations can be used to solve various problems in combinatorics, probability theory, and other areas of mathematics. Through numerous examples and detailed explanations, this work offers valuable insights into the nature of uniform determinantal representations and their potential uses.\"",
    "This paper provides an introduction to game theory through the lens of wireless power control. Game theory is a mathematical framework used to analyze strategic interactions between rational agents. Wireless power control is a crucial aspect of wireless communication systems, where multiple devices compete for limited resources. By analyzing various games in wireless power control, this paper demonstrates how game theory can be used to develop efficient strategies for resource allocation and interference management. The paper also highlights the challenges and potential applications of game theory in wireless power control.",
    "The academic paper titled \"Fair Latency-Aware Metric for real-time video segmentation networks\" proposes a new metric for evaluating the performance of real-time video segmentation networks. The proposed metric takes into account both the accuracy of the segmentation and the latency of the network, with a focus on ensuring fairness between different networks. The paper provides a detailed analysis of the proposed metric and demonstrates its effectiveness through experimental evaluations on several benchmark datasets. Overall, the proposed metric offers a more comprehensive and fair way to evaluate the performance of real-time video segmentation networks, which is crucial for their deployment in various applications.",
    "This academic paper discusses the implementation of reflection methods for submodular optimization, with a focus on making the process user-friendly. Submodular optimization is a mathematical technique used to maximize the value of a function, subject to certain constraints. The authors explore the use of reflection methods, which involve reflecting a set of points over a hyperplane to find the optimal solution, and demonstrate how these methods can be applied to submodular optimization problems. The paper concludes with a discussion of the potential benefits and limitations of using reflection methods for submodular optimization, as well as potential applications in various fields, such as computer science and economics.",
    "The anisotropic magnetic properties of the URhIn$_5$ compound were investigated in this study. The compound exhibits strong spin-orbit coupling and unconventional superconductivity, making it an interesting subject for research. Our experiments revealed that the magnetization direction is highly dependent on the applied field angle relative to the crystalline axis. These results provide insights into the complex magnetism inherent in strongly correlated electron systems and could have implications for understanding superconducting mechanisms in such materials. Further studies are needed to fully comprehend the underlying physics responsible for these intriguing phenomena observed in URhIn$_5$.",
    "This study presents an interactive binary image segmentation method that preserves edges while allowing user intervention. The proposed approach utilizes a combination of edge detection and region growing techniques to segment images into foreground and background regions based on user input. Experimental results demonstrate the effectiveness of the method in preserving edges and its ability to adapt to different types of images. Overall, this technique provides a flexible and efficient solution for binary image segmentation tasks that require both automatic processing and human interaction."
  ]
}